<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 3]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [When Agents are Powerful: Black Hole Search in Time-Varying Graphs](https://arxiv.org/abs/2510.22309)
*Tanvir Kaur,Ashish Saxena*

Main category: cs.DC

TL;DR: 本文研究动态图中的黑洞搜索问题，通过赋予智能体全局通信能力和1跳可见性，提升了搜索效率，减少了所需智能体数量。


<details>
  <summary>Details</summary>
Motivation: 在动态图中识别黑洞节点至关重要，而传统面对面通信模式限制了效率，需要更多智能体。因此，提升智能体能力以提高黑洞搜索效率是本文的动机。

Challenges: 主要挑战包括在动态变化的图结构中定位黑洞边，确保至少一个智能体存活并准确报告黑洞位置，同时减少所需智能体数量。

Contributions: 本文的主要贡献是引入全局通信和1跳可见性两种增强机制，显著提高了黑洞搜索的效率，并降低了对智能体数量的需求。

Results: 结果表明，具备全局通信和1跳可见性的智能体能在更少数量下高效解决动态图中的黑洞搜索问题，优于仅依赖面对面通信的方案。

Conclusion: 通过增强智能体的通信与感知能力，可以显著优化动态图中黑洞搜索问题的解决方案，为后续研究提供了新的方向。

Related Work: 相关工作主要集中在任意动态图中基于面对面通信的黑洞搜索问题，已有研究探讨了不同图结构下的最小智能体数量需求。

Abstract: A black hole is a harmful node in a graph that destroys any resource entering
it, making its identification a critical task. In the \emph{Black Hole Search
(BHS)} problem, a team of agents operates on a graph $G$ with the objective
that at least one agent must survive and correctly identify an edge incident to
the black hole. Prior work has addressed BHS in arbitrary dynamic graphs under
the restrictive \emph{face-to-face} communication, where agents can exchange
information only when co-located. This constraint significantly increases the
number of agents required to solve the problem. In this work, we strengthen the
capabilities of agents in two ways: (i) granting them \emph{global
communication}, enabling interaction regardless of location, and (ii) equipping
them with \emph{1-hop visibility}, allowing each agent to observe its immediate
neighborhood. These enhancements lead to more efficient solutions for the BHS
problem in dynamic graphs.

</details>


### [2] [Separation of Unconscious Robots with Obstructed Visibility](https://arxiv.org/abs/2510.22434)
*Prajyot Pyati,Navjot Kaur,Saswata Jana,Adri Bhattacharya,Partha Sarathi Mandal*

Main category: cs.DC

TL;DR: 本文研究了不透明的无意识移动机器人模型下的分离问题，提出了一种在半同步调度器下可在O(n)轮内无碰撞地将机器人分离成同心半圆的算法。


<details>
  <summary>Details</summary>
Motivation: 传统研究假设机器人是透明的，能够看到所有其他机器人的位置和颜色；但现实中机器人可能遮挡彼此视线。本文旨在研究在遮挡可见性（opaque）条件下，如何解决无意识机器人系统的分离问题。

Challenges: 由于机器人不透明，视线可能被其他机器人遮挡，导致信息获取不完整；同时机器人无自我意识（无法感知自身颜色）、匿名、无记忆且无通信，增加了协调与避免碰撞的难度。

Contributions: 首次在不透明机器人模型下研究分离问题；提出了一种可在半同步调度下在O(n)轮内完成分离到同心半圆的无碰撞分布式算法；算法不依赖机器人总数n的先验知识，仅需共享一个坐标轴。

Results: 算法能够在任意初始配置下，使机器人成功分离为同心半圆；整个过程无碰撞，时间复杂度为O(n)个epoch；仿真验证了算法的有效性与鲁棒性。

Conclusion: 本文证明了即使在视线受遮挡、机器人无自我感知能力的极端受限条件下，仍可通过合理设计实现高效的几何分离任务，拓展了无意识机器人模型的应用边界。

Related Work: 相关工作主要集中在透明无意识机器人模型下的分离问题，如形成点、线或整圆等结构；已有研究未考虑视线遮挡的影响，本文首次引入不透明性并提出相应解决方案。

Abstract: We study a recently introduced \textit{unconscious} mobile robot model, where
each robot is associated with a \textit{color}, which is visible to other
robots but not to itself. The robots are autonomous, anonymous, oblivious and
silent, operating in the Euclidean plane under the conventional
\textit{Look-Compute-Move} cycle. A primary task in this model is the
\textit{separation problem}, where unconscious robots sharing the same color
must separate from others, forming recognizable geometric shapes such as
circles, points, or lines. All prior works model the robots as
\textit{transparent}, enabling each to know the positions and colors of all
other robots. In contrast, we model the robots as \textit{opaque}, where a
robot can obstruct the visibility of two other robots, if it lies on the line
segment between them. Under this obstructed visibility, we consider a variant
of the separation problem in which robots, starting from any arbitrary initial
configuration, are required to separate into concentric semicircles. We present
a collision-free algorithm that solves the separation problem under a
semi-synchronous scheduler in $O(n)$ epochs, where $n$ is the number of robots.
The robots agree on one coordinate axis but have no knowledge of $n$.

</details>


### [3] [Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions](https://arxiv.org/abs/2510.22909)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.DC

TL;DR: 本文综述了面向边缘智能应用的深度学习模型卸载与适应技术，探讨了在延迟、隐私和成本之间的多目标优化问题。


<details>
  <summary>Details</summary>
Motivation: 由于边缘设备资源受限，难以运行日益复杂的深度学习模型，因此需要将模型分割并卸载到设备、边缘和云端协同推理。

Challenges: 模型分区间通信可能引入传输瓶颈和数据泄露风险，同时需平衡推理精度、计算延迟、传输延迟与隐私保护。

Contributions: 系统梳理了当前先进的模型卸载方法与模型适应技术，并从多目标优化角度（延迟、隐私、成本）进行了归纳与分析。

Results: 总结了模型压缩、知识蒸馏、传输压缩和内部分类器等关键技术在边缘智能中的应用效果与权衡。

Conclusion: 有效的模型卸载与结构适应策略能够显著提升边缘智能系统的综合性能，未来需进一步优化多目标间的权衡。

Related Work: 已有研究集中在模型分割策略、卸载决策算法、边缘-云协同推理框架以及隐私保护机制等方面。

Abstract: Edge intelligent applications like VR/AR and language model based chatbots
have become widespread with the rapid expansion of IoT and mobile devices.
However, constrained edge devices often cannot serve the increasingly large and
complex deep learning (DL) models. To mitigate these challenges, researchers
have proposed optimizing and offloading partitions of DL models among user
devices, edge servers, and the cloud. In this setting, users can take advantage
of different services to support their intelligent applications. For example,
edge resources offer low response latency. In contrast, cloud platforms provide
low monetary cost computation resources for computation-intensive workloads.
However, communication between DL model partitions can introduce transmission
bottlenecks and pose risks of data leakage. Recent research aims to balance
accuracy, computation delay, transmission delay, and privacy concerns. They
address these issues with model compression, model distillation, transmission
compression, and model architecture adaptations, including internal
classifiers. This survey contextualizes the state-of-the-art model offloading
methods and model adaptation techniques by studying their implication to a
multi-objective optimization comprising inference latency, data privacy, and
resource monetary cost.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [4] [HandPass: A Wi-Fi CSI Palm Authentication Approach for Access Control](https://arxiv.org/abs/2510.22133)
*Eduardo Fabricio Gomes Trindade,Felipe Silveira de Almeida,Gioliano de Oliveira Braga,Rafael Pimenta de Mattos Paixão,Pedro Henrique dos Santos Rocha,Lourenco Alves Pereira Jr*

Main category: cs.NI

TL;DR: 本研究提出了一种基于Wi-Fi信道状态信息（CSI）的掌纹生物特征认证新方法，利用树莓派采集20名用户的手部CSI数据，结合手部生物特征对电磁信号的影响，实现了高达99.82% F1分数的精准用户识别。


<details>
  <summary>Details</summary>
Motivation: 探索Wi-Fi CSI在用户身份认证中的实际应用潜力，弥补其在生物特征识别领域尤其是掌纹识别中研究不足的问题。

Challenges: 如何从微弱的Wi-Fi CSI信号中提取稳定且具有区分性的掌部生物特征；降低设备发射功率至1dBm后仍保持识别准确性；消除环境噪声和个体差异带来的干扰。

Contributions: 提出一种基于低功率Wi-Fi CSI的掌纹识别系统；构建包含20名用户的手部CSI数据集；验证了多种分类算法在该任务上的性能，其中随机森林达到99.82%的F1-score；证明了手部几何特征（如指节长度、手指张角等）可有效影响CSI并用于身份认证。

Results: 随机森林分类器在10折交叉验证下取得了平均99.82%的F1-score；系统每秒采集约1000个数据包，每次用户采集五个5秒时间段的数据；使用幅度和相位信息进行分类，显示出高稳定性和准确性。

Conclusion: Wi-Fi CSI能够有效捕捉掌部生物特征差异，具备实现非接触式、高精度用户身份认证的潜力，尤其适用于低功耗、隐私保护场景。

Related Work: 先前研究主要集中于Wi-Fi CSI在人体活动识别或步态识别中的应用，而在掌纹或手部生物特征识别方面的研究较少；已有工作多依赖高功率信号或专用硬件，本研究则采用低成本树莓派与低发射功率（1dBm），更具实用性和可部署性。

Abstract: Wi-Fi Channel State Information (CSI) has been extensively studied for
sensing activities. However, its practical application in user authentication
still needs to be explored. This study presents a novel approach to biometric
authentication using Wi-Fi Channel State Information (CSI) data for palm
recognition. The research delves into utilizing a Raspberry Pi encased in a
custom-built box with antenna power reduced to 1dBm, which was used to capture
CSI data from the right hands of 20 participants (10 men and 10 women). The
dataset was normalized using MinMax scaling to ensure uniformity and accuracy.
By focusing on biophysical aspects such as hand size, shape, angular spread
between fingers, and finger phalanx lengths, among other characteristics, the
study explores how these features affect electromagnetic signals, which are
then reflected in Wi-Fi CSI, allowing for precise user identification. Five
classification algorithms were evaluated, with the Random Forest classifier
achieving an average F1-Score of 99.82\% using 10-fold cross-validation.
Amplitude and Phase data were used, with each capture session recording
approximately 1000 packets per second in five 5-second intervals for each User.
This high accuracy highlights the potential of Wi-Fi CSI in developing robust
and reliable user authentication systems based on palm biometric data.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [5] [RAMAN: Resource-efficient ApproxiMate Posit Processing for Algorithm-Hardware Co-desigN](https://arxiv.org/abs/2510.22627)
*Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: 本文提出了一种资源高效且基于近似posit(8,2)的乘累加（MAC）架构RAMAN，核心为REAP MAC引擎，通过在乘法器中引入近似计算显著降低面积和功耗，并结合可扩展向量执行单元（VEU）和近似感知训练框架，在FPGA和ASIC平台上实现了显著的硬件效率提升，同时保持了高精度，适用于下一代边缘智能应用。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘环境中，提升计算效率是Edge-AI面临的关键挑战。传统浮点或定点运算在精度与资源消耗之间难以平衡，而posit作为一种新兴的数值格式具有动态范围大、精度高的优势，但其硬件开销仍较高。本文旨在设计一种资源高效且支持近似的posit-based MAC架构，以在保证AI应用性能的前提下显著降低硬件成本。

Challenges: 主要挑战包括：如何在保持足够计算精度的同时，有效降低posit运算单元的硬件开销（面积、功耗）；如何将近似计算引入posit MAC而不显著影响AI任务的最终准确率；以及如何实现算法与硬件的协同优化，以适应多样化的边缘AI工作负载。

Contributions: 1) 提出了REAP（Resource-Efficient Approximate Posit）MAC引擎，首次将近似计算应用于posit(8,2)乘法器，显著降低硬件开销；2) 设计了基于REAP的可扩展向量执行单元（VEU），支持硬件复用和DNN层间的并行性；3) 提出了一种算法-硬件协同设计框架，包含近似感知训练，以评估硬件近似对应用性能的影响；4) 在FPGA和ASIC平台实现了原型验证，展示了优越的能效比。

Results: 实验结果表明，与基线Posit点积单元（PDPU）相比，所提出的REAP MAC在FPGA上最多节省46%的LUT资源，在ASIC上实现35.66%的面积缩减和31.28%的功耗降低，同时在手写数字识别任务中保持了98.45%的高准确率。

Conclusion: RAMAN架构在硬件效率与学习性能之间实现了良好的权衡，通过近似posit MAC、可扩展VEU和协同训练框架，有效提升了边缘AI设备的能效，验证了其在下一代边缘智能应用中的潜力。

Related Work: 相关工作主要包括：1) 近似计算在定点和浮点MAC中的应用；2) posit数制在深度学习推理中的探索；3) 面向边缘AI的低功耗MAC设计；4) 算法-硬件协同优化框架。本文工作结合了posit的高动态范围优势与近似计算的低开销特性，并针对posit格式设计了专用的近似乘法方案，区别于已有工作。

Abstract: Edge-AI applications still face considerable challenges in enhancing
computational efficiency in resource-constrained environments. This work
presents RAMAN, a resource-efficient and approximate posit(8,2)-based
Multiply-Accumulate (MAC) architecture designed to improve hardware efficiency
within bandwidth limitations. The proposed REAP (Resource-Efficient Approximate
Posit) MAC engine, which is at the core of RAMAN, uses approximation in the
posit multiplier to achieve significant area and power reductions with an
impact on accuracy. To support diverse AI workloads, this MAC unit is
incorporated in a scalable Vector Execution Unit (VEU), which permits hardware
reuse and parallelism among deep neural network layers. Furthermore, we propose
an algorithm-hardware co-design framework incorporating approximation-aware
training to evaluate the impact of hardware-level approximation on
application-level performance. Empirical validation on FPGA and ASIC platforms
shows that the proposed REAP MAC achieves up to 46% in LUT savings and 35.66%
area, 31.28% power reduction, respectively, over the baseline Posit Dot-Product
Unit (PDPU) design, while maintaining high accuracy (98.45%) for handwritten
digit recognition. RAMAN demonstrates a promising trade-off between hardware
efficiency and learning performance, making it suitable for next-generation
edge intelligence.

</details>


### [6] [Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications](https://arxiv.org/abs/2510.22674)
*L. Hemanth Krishna,Srinivasu Bodapati,Sreehari Veeramachaneni,BhaskaraRao Jammu,Noor Mahammad Sk*

Main category: cs.AR

TL;DR: 本文提出了一种用于机器学习和信号处理中边缘检测的近似有符号乘法器架构，采用专门设计的符号聚焦压缩器，并结合截断与误差补偿机制，在8位乘法器上显著降低了功耗和延迟，实验验证了其在实际卷积层中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高在边缘检测等应用中有符号乘法运算的能效，设计一种能够高效处理符号位和常数项的近似乘法器。

Challenges: 如何在保持计算精度的同时，有效处理有符号乘法中的负部分积和常数项'1'，并降低硬件开销和功耗。

Contributions: 提出了两种符号聚焦压缩器结构（A+B+C+1 和 A+B+C+D+1），结合精确与近似设计，并引入部分积矩阵低N-1列截断与误差补偿机制，显著优化了PDP和功耗。

Results: 所提出的8位近似乘法器相比现有最佳乘法器降低了29.21%的功率延迟积（PDP）和14.39%的功耗，并在定制卷积层中成功应用于边缘检测。

Conclusion: 该近似有符号乘法器在保证实用性的同时显著提升了能效，适用于机器学习和信号处理中的边缘检测任务。

Related Work: 现有的近似乘法器研究主要集中在无符号运算和低功耗设计，而针对有符号运算中符号位和常数项的专门优化较少。

Abstract: This paper presents an approximate signed multiplier architecture that
incorporates a sign-focused compressor, specifically designed for edge
detection applications in machine learning and signal processing. The
multiplier incorporates two types of sign-focused compressors: A + B + C + 1
and A + B + C + D + 1. Both exact and approximate compressor designs are
utilized, with a focus on efficiently handling constant value "1" and negative
partial products, which frequently appear in the partial product matrices of
signed multipliers. To further enhance efficiency, the lower N - 1 columns of
the partial product matrix are truncated, followed by an error compensation
mechanism. Experimental results show that the proposed 8-bit approximate
multiplier achieves a 29.21% reduction in power delay product (PDP) and a
14.39% reduction in power compared to the best of existing multipliers. The
proposed multiplier is integrated into a custom convolution layer and performs
edge detection, demonstrating its practical utility in real-world applications.

</details>
