<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 4]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives](https://arxiv.org/abs/2510.24943)
*Alfonso Ladino-Rincon,Stephen W. Nesbitt*

Main category: cs.DC

TL;DR: Radar DataTree 是一个基于 WMO FM-301 标准的、可扩展的开源框架，将天气雷达数据组织为符合 FAIR 原则的云优化数据集，支持高效的大规模分析与可重复研究。


<details>
  <summary>Details</summary>
Motivation: 天气雷达数据虽具有重要科学价值，但现有归档方式碎片化、厂商依赖性强，且不符合 FAIR 原则，限制了其在大规模研究和云原生计算中的应用。

Challenges: 雷达数据格式不统一、元数据管理薄弱、缺乏时间连续性支持，导致数据难以发现、访问和高效处理。

Contributions: 提出 Radar DataTree 框架，首次将 FM-301 标准扩展到数据集级别；结合 xarray DataTree 和 Zarr 实现层次化、元数据丰富的存储结构；集成 Icechunk 实现 ACID 兼容的版本控制与存储；提供开源工具链 Raw2Zarr，支持从原始数据到分析就绪数据的转换。

Results: 在 QVP 和降水累积等案例中展示了显著的性能提升，能够高效并行处理数千次雷达扫描，且预处理需求极低。

Conclusion: Radar DataTree 为雷达数据管理提供了可复用、可扩展的基础架构，推动了高性能地球科学研究和面向 AI 的气象基础设施发展。

Related Work: 相关工作包括 WMO FM-301/CfRadial 2.1 标准、xarray 和 Zarr 在地球科学中的应用、以及 Icechunk 提供的云存储版本控制技术。

Abstract: We introduce Radar DataTree, the first dataset-level framework that extends
the WMO FM-301 standard from individual radar volume scans to time-resolved,
analysis-ready archives. Weather radar data are among the most scientifically
valuable yet structurally underutilized Earth observation datasets. Despite
widespread public availability, radar archives remain fragmented,
vendor-specific, and poorly aligned with FAIR (Findable, Accessible,
Interoperable, Reusable) principles, hindering large-scale research,
reproducibility, and cloud-native computation. Radar DataTree addresses these
limitations with a scalable, open-source architecture that transforms
operational radar archives into FAIR-compliant, cloud-optimized datasets. Built
on the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,
Radar DataTree organizes radar volume scans as hierarchical, metadata-rich
structures and serializes them to Zarr for scalable analysis. Coupled with
Icechunk for ACID-compliant storage and versioning, this architecture enables
efficient, parallel computation across thousands of radar scans with minimal
preprocessing. We demonstrate significant performance gains in case studies
including Quasi-Vertical Profile (QVP) and precipitation accumulation
workflows, and release all tools and datasets openly via the Raw2Zarr
repository. This work contributes a reproducible and extensible foundation for
radar data stewardship, high-performance geoscience, and AI-ready weather
infrastructure.

</details>


### [2] [A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon](https://arxiv.org/abs/2510.25277)
*Simon Süwer,Mai Khanh Mai,Christoph Klein,Nicola Götzenberger,Denis Dalić,Andreas Maier,Jan Baumbach*

Main category: cs.DC

TL;DR: 提出了一种基于模拟临床知识图谱和联邦学习框架的多阶段安全AI训练方法，用于在保护患者隐私的前提下开发医疗AI模型。


<details>
  <summary>Details</summary>
Motivation: 在遵守GDPR等数据保护法规的同时，利用小样本罕见病临床数据开发高质量的个性化医疗AI模型。

Challenges: 临床数据隐私保护严格，尤其是罕见病小样本数据难以共享；缺乏高质量结构化数据支持AI训练。

Contributions: 提出一种结合模拟临床知识图谱（cKG）与联邦学习（FeatureCloud框架）的新型多阶段安全AI训练方法，实现无需访问真实患者数据的模型开发与验证。

Results: 该方法在TUM.ai Makeathon 2024竞赛中成功验证，50名学生在无真实数据访问权限的情况下完成了患者分类与诊断模型的开发，且仅返回聚合性能指标，确保隐私安全。

Conclusion: 通过模拟cKG和联邦学习框架结合的方式，可在不泄露敏感数据的前提下实现隐私保护的医疗AI训练，具有临床应用前景。

Related Work: 相关工作包括联邦学习在医疗AI中的应用、临床知识图谱构建以及隐私保护计算技术，但本研究创新性地将模拟cKG引入模型预训练阶段并与FC框架集成。

Abstract: The integration of clinical data offers significant potential for the
development of personalized medicine. However, its use is severely restricted
by the General Data Protection Regulation (GDPR), especially for small cohorts
with rare diseases. High-quality, structured data is essential for the
development of predictive medical AI. In this case study, we propose a novel,
multi-stage approach to secure AI training: (1) The model is designed on a
simulated clinical knowledge graph (cKG). This graph is used exclusively to
represent the structural characteristics of the real cKG without revealing any
sensitive content. (2) The model is then integrated into the FeatureCloud (FC)
federated learning framework, where it is prepared in a single-client
configuration within a protected execution environment. (3) Training then takes
place within the hospital environment on the real cKG, either under the direct
supervision of hospital staff or via a fully automated pipeline controlled by
the hospital. (4) Finally, verified evaluation scripts are executed, which only
return aggregated performance metrics. This enables immediate performance
feedback without sensitive patient data or individual predictions, leaving the
clinic. A fundamental element of this approach involves the incorporation of a
cKG, which serves to organize multi-omics and patient data within the context
of real-world hospital environments. This approach was successfully validated
during the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner
Children's Hospital (HCH-LMU): 50 students developed models for patient
classification and diagnosis without access to real data. Deploying secure
algorithms via federated frameworks, such as the FC framework, could be a
practical way of achieving privacy-preserving AI in healthcare.

</details>


### [3] [Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges](https://arxiv.org/abs/2510.25362)
*Georgios L. Stavrinides,Helen D. Karatza*

Main category: cs.DC

TL;DR: 本文讨论了大数据背景下数据密集型工作负载的调度挑战，提出了一种工作负载分类方法，并综述了大规模分布式系统中常用的调度策略，同时探讨了新提出的调度策略及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大数据的快速增长，工作负载变得更加复杂和计算密集，需要在大规模分布式系统中高效调度以满足服务质量、数据局部性、容错和能效等多方面需求。

Challenges: 数据密集型应用具有不同的并行度，需有效利用数据局部性；同时面临时间约束、容错性、能源效率等多目标优化挑战；资源规模扩大也增加了调度复杂性。

Contributions: 提出了一种针对数据密集型工作负载的分类方法，综述了现有调度策略，并总结了近年来提出的新型调度方法。

Results: 系统梳理了当前主流调度方法及其适用场景，明确了各类策略的优势与局限。

Conclusion: 有效的调度技术对提升数据密集型应用性能至关重要，未来需进一步研究多目标优化、动态环境适应性和可扩展性等问题。

Related Work: 相关工作主要集中在分布式系统中的任务调度、数据局部性优化、能耗感知调度以及满足QoS的实时调度算法等方面。

Abstract: With the explosive growth of big data, workloads tend to get more complex and
computationally demanding. Such applications are processed on distributed
interconnected resources that are becoming larger in scale and computational
capacity. Data-intensive applications may have different degrees of parallelism
and must effectively exploit data locality. Furthermore, they may impose
several Quality of Service requirements, such as time constraints and
resilience against failures, as well as other objectives, like energy
efficiency. These features of the workloads, as well as the inherent
characteristics of the computing resources required to process them, present
major challenges that require the employment of effective scheduling
techniques. In this chapter, a classification of data-intensive workloads is
proposed and an overview of the most commonly used approaches for their
scheduling in large-scale distributed systems is given. We present novel
strategies that have been proposed in the literature and shed light on open
challenges and future directions.

</details>


### [4] [Holon Streaming: Global Aggregations with Windowed CRDTs](https://arxiv.org/abs/2510.25757)
*Jonas Spenger,Kolya Krafeld,Ruben van Gemeren,Philipp Haller,Paris Carbone*

Main category: cs.DC

TL;DR: Holon Streaming 是一种用于全局聚合的精确一次流处理系统，通过引入窗口化无冲突复制数据类型（Windowed CRDTs）实现可扩展性和低延迟，采用去中心化协调机制提升容错效率，在性能和故障恢复方面显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有的流处理系统在执行全局聚合时面临可扩展性差、延迟高以及故障恢复慢的问题，主要由于依赖单任务实例或静态聚合树结构，并存在集中式协调带来的瓶颈。

Challenges: 如何在保证恰好一次语义的前提下，实现可扩展的全局聚合；降低由最慢路径决定的端到端延迟；避免因故障和重配置导致的延迟尖峰；减少对中心化协调的依赖以提高系统弹性。

Contributions: 提出了 Holon Streaming 系统，引入了 Windowed CRDTs 作为支持全局聚合的新型共享复制状态抽象；实现了基于去中心化协调的高效故障恢复机制；展示了确定性编程模型在提升流处理系统性能和可靠性方面的优势。

Results: 实验表明，Holon Streaming 在全局聚合负载下比现有系统延迟降低 5 倍，吞吐量提高 2 倍；在故障场景下延迟减少达 11 倍。

Conclusion: Holon Streaming 利用 Windowed CRDTs 和去中心化协调机制，有效解决了全局聚合中的可扩展性与容错难题，验证了确定性模型在流处理系统中的实用性和优越性。

Related Work: 相关工作包括基于单一聚合节点或静态树结构的流处理系统，如 Apache Flink 和 Spark Streaming 中的聚合机制，以及使用 CRDTs 进行状态复制的分布式系统研究。

Abstract: Scaling global aggregations is a challenge for exactly-once stream processing
systems. Current systems implement these either by computing the aggregation in
a single task instance, or by static aggregation trees, which limits
scalability and may become a bottleneck. Moreover, the end-to-end latency is
determined by the slowest path in the tree, and failures and reconfiguration
cause large latency spikes due to the centralized coordination. Towards these
issues, we present Holon Streaming, an exactly-once stream processing system
for global aggregations. Its deterministic programming model uses windowed
conflict-free replicated data types (Windowed CRDTs), a novel abstraction for
shared replicated state. Windowed CRDTs make computing global aggregations
scalable. Furthermore, their guarantees such as determinism and convergence
enable the design of efficient failure recovery algorithms by decentralized
coordination. Our evaluation shows a 5x lower latency and 2x higher throughput
than an existing stream processing system on global aggregation workloads, with
an 11x latency reduction under failure scenarios. The paper demonstrates the
effectiveness of decentralized coordination with determinism, and the utility
of Windowed CRDTs for global aggregations.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [5] [MetaLore: Learning to Orchestrate Communication and Computation for Metaverse Synchronization](https://arxiv.org/abs/2510.25705)
*Elif Ebru Ohri,Qi Liao,Anastasios Giovanidis,Francesca Fossati,Nour-El-Houda Yellas*

Main category: cs.NI

TL;DR: 本文提出了一种基于深度强化学习（DRL）的框架MetaLore，用于元宇宙或数字孪生环境中通信与计算资源的联合分配，通过引入新的信息年龄指标AoRI和AoSI优化同步性能，并在保证端到端延迟的前提下实现接近穷举法的性能。


<details>
  <summary>Details</summary>
Motivation: 在增强现实和虚拟现实应用中，物理世界与数字世界的实时同步至关重要，但现有方法难以在动态环境中有效保证低延迟和高吞吐量。

Challenges: 如何在动态流量条件下联合优化通信带宽与计算资源分配，同时满足严格的端到端延迟要求，并提升同步质量。

Contributions: 1) 提出了MetaLore框架，实现通信与计算资源的动态分配；2) 引入两个新的信息年龄指标AoRI和AoSI用于衡量同步质量；3) 设计了轻量化的DRL模型，仅依赖两个队列长度即可实现高效决策；4) 扩展了开源仿真平台以验证方法有效性。

Results: 实验结果表明，MetaLore在性能上接近全枚举暴力求解方法，同时具备良好的自适应能力，能够在动态环境中保持高吞吐量和低同步延迟。

Conclusion: MetaLore通过引入新型AoI指标和轻量级DRL架构，有效提升了元宇宙等实时应用中的同步性能，具备良好的实用性与可扩展性。

Related Work: 相关工作主要集中在资源分配、信息年龄（AoI）优化以及DRL在边缘计算中的应用，但较少同时考虑通信与计算资源的联合调度及端到端延迟约束。

Abstract: As augmented and virtual reality evolve, achieving seamless synchronization
between physical and digital realms remains a critical challenge, especially
for real-time applications where delays affect the user experience. This paper
presents MetaLore, a Deep Reinforcement Learning (DRL) based framework for
joint communication and computational resource allocation in Metaverse or
digital twin environments. MetaLore dynamically shares the communication
bandwidth and computational resources among sensors and mobile devices to
optimize synchronization, while offering high throughput performance. Special
treatment is given in satisfying end-to-end delay guarantees. A key
contribution is the introduction of two novel Age of Information (AoI) metrics:
Age of Request Information (AoRI) and Age of Sensor Information (AoSI),
integrated into the reward function to enhance synchronization quality. An open
source simulator has been extended to incorporate and evaluate the approach.
The DRL solution is shown to achieve the performance of full-enumeration
brute-force solutions by making use of a small, task-oriented observation space
of two queue lengths at the network side. This allows the DRL approach the
flexibility to effectively and autonomously adapt to dynamic traffic
conditions.

</details>
