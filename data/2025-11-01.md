<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出了一种联合计算资源分配与任务卸载方法（JCRATOA），以解决车载雾计算中由于信息不对称和资源异构带来的延迟最小化问题，通过分层架构、凸优化、契约理论和双边匹配算法实现了高效的资源利用和任务调度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统车载边缘计算在延迟敏感和计算密集型任务中的局限性，利用附近雾车辆的空闲计算资源，但面临路边单元资源有限、信息不对称以及任务与资源异构等挑战。

Challenges: 1. 路边单元（RSU）资源有限，难以满足车辆多样化需求；2. 控制器与雾车辆之间存在信息不对称，影响资源分配效率；3. 任务需求与RSU/FV能力异构，导致任务卸载复杂化，资源利用率低。

Contributions: 1. 提出了一种融合RSU与FV计算能力的分层VFC架构；2. 建立了一个延迟最小化的NP难混合整数非线性优化模型（DMOP）；3. 设计了基于凸优化的RSU资源分配方法；4. 引入基于契约理论的FV激励机制；5. 采用双边匹配博弈实现任务卸载。

Results: 仿真结果表明，所提JCRATOA方法在任务完成延迟、任务完成率、系统吞吐量和资源利用公平性方面均优于对比方案，同时有效满足约束条件。

Conclusion: JCRATOA通过分层架构与多策略协同，有效应对了车载雾计算中的资源分配与任务卸载挑战，显著提升了系统性能与资源利用效率。

Related Work: 相关工作主要集中在车载边缘计算、雾计算资源分配、激励机制设计（如博弈论、拍卖模型）以及任务卸载策略，但较少同时考虑信息不对称与资源异构下的联合优化问题。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [2] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 提出两种新型无线内存管理方法（无线内存激活和无线内存近似），以降低物联网设备中DRAM因周期刷新导致的待机能耗，同时满足机器学习模型的检索精度要求。


<details>
  <summary>Details</summary>
Motivation: DRAM在机器学习模型存储中起重要作用，但其周期性刷新在待机期间造成显著能耗，尤其影响资源受限的物联网设备。

Challenges: 如何在保证机器学习模型检索精度的前提下，减少DRAM待机期间的能耗。

Contributions: 提出了两种新方法：无线内存激活和无线内存近似，通过考虑模型使用的时机和相关性来高效管理内存，降低整体能耗。

Results: 数值结果表明，所提方案相比始终开启的方法能实现更低的能耗，同时满足检索精度约束。

Conclusion: 所提出的无线内存管理策略有效降低了物联网设备中ML模型存储的能耗，具有良好的应用前景。

Related Work: 现有研究主要关注DRAM刷新机制优化或低功耗设计，但较少结合无线通信场景下的内存使用特性进行能耗管理。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [3] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 本文提出了一种基于低空无人机的可移动天线增强型传输系统，结合无线能量传输和隐蔽通信，在为物联网节点补充能量的同时，利用无线能量信号作为自然掩护与隐蔽用户建立通信链路，并通过改进的MoE-SAC算法优化多目标性能。


<details>
  <summary>Details</summary>
Motivation: 针对物联网节点能源受限且通信易受窃听的问题，探索无人机辅助下的安全高效能量与信息协同传输方案。

Challenges: 如何在保证隐蔽通信安全性的同时最大化能量收集效率，并降低无人机自身能耗；优化问题具有非凸性和时序耦合特性。

Contributions: 1) 提出新型无人机携可移动天线的联合无线传能与隐蔽通信系统；2) 构建多目标优化模型，兼顾能量收集、通信速率与无人机能耗；3) 设计MoE-SAC强化学习算法，引入稀疏专家混合结构和动作投影模块以处理复杂约束与多目标冲突。

Results: 仿真结果表明，所提MoE-SAC算法在总收集能量、隐蔽用户可达速率和无人机能耗方面均显著优于基线方法和其他先进深度强化学习算法。

Conclusion: 该方案有效实现了能量传输与隐蔽通信的协同优化，所提出的算法在处理多目标、非凸、带约束的时序决策问题上具有优越性能。

Related Work: 现有研究多集中于单独的无人机无线能量传输或隐蔽通信，缺乏对两者联合设计及实际物理约束（如天线位置、功率预算）的综合考虑。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference](https://arxiv.org/abs/2510.26730)
*Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang*

Main category: cs.DC

TL;DR: ExpertFlow是一种用于Mixture-of-Experts（MoE）推理的运行时系统，通过自适应专家预取和缓存感知路由，显著降低模型停顿时间，提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展受限于现代GPU的内存容量，传统MoE推理方法因频繁的主机与GPU间参数传输导致高延迟，且现有跨层预测策略缺乏跨平台和负载的适应性。

Challenges: 1. 传统MoE在每层独立选择激活专家，导致频繁参数传输和高延迟；2. 固定步长的跨层预测策略难以适应不同硬件和负载，鲁棒性差。

Contributions: 1. 提出ExpertFlow，一种结合自适应专家预取和缓存感知路由的运行时系统；2. 设计基于运行时统计（如带宽、参数维度、模型反馈）动态调整预测窗口的机制；3. 引入融合预门控信息与中间计算状态的混合跨层预测方案。

Results: 实验表明，ExpertFlow将模型停顿时间降至基线的0.1%以下，显著减少了缓存未命中和专家加载延迟。

Conclusion: ExpertFlow通过自适应和混合预测机制，有效优化了MoE模型在内存受限环境下的推理性能，具备良好的实际部署潜力。

Related Work: 相关工作包括传统的MoE架构、基于固定步长的跨层专家预测方法以及GPU内存管理与预取技术。

Abstract: The expansion of large language models is increasingly limited by the
constrained memory capacity of modern GPUs. To mitigate this,
Mixture-of-Experts (MoE) architectures activate only a small portion of
parameters during inference, significantly lowering both memory demand and
computational overhead. However, conventional MoE inference approaches, which
select active experts independently at each layer, often introduce considerable
latency because of frequent parameter transfers between host and GPU memory. In
addition, current cross-layer prediction strategies, which are typically based
on fixed steps, lack adaptability across different hardware platforms and
workloads, thereby reducing their robustness and effectiveness.
  To address these challenges, we present ExpertFlow, a runtime system for MoE
inference that combines adaptive expert prefetching and cache-aware routing.
ExpertFlow continuously adjusts its prediction horizon for expert activation by
leveraging runtime statistics such as transfer bandwidth, parameter
dimensionality, and model feedback signals. Furthermore, it incorporates a
hybrid cross-layer prediction scheme that fuses pregating information with
intermediate computational states to anticipate future expert needs. By
adaptively refining prefetching decisions and aligning them with actual usage
behavior, ExpertFlow effectively decreases cache misses and removes latency
caused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces
model stall time to less than 0.1% of the baseline, highlighting its capability
to optimize MoE inference under stringent memory constraints.

</details>
