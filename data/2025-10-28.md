<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 3]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.DC](#cs.DC) [Total: 8]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [FIFOAdvisor: A DSE Framework for Automated FIFO Sizing of High-Level Synthesis Designs](https://arxiv.org/abs/2510.20981)
*Stefan Abi-Karam,Rishov Sarkar,Suhail Basalama,Jason Cong,Callie Hao*

Main category: cs.AR

TL;DR: 本文提出了FIFOAdvisor，一个用于自动确定高层次综合（HLS）设计中FIFO通道缓冲区大小的框架。该框架结合高精度快速仿真与优化方法，在保证无死锁的同时实现延迟与资源使用的权衡，显著降低内存开销并加速设计空间探索。


<details>
  <summary>Details</summary>
Motivation: 在基于数据流的FLS设计中，FIFO缓冲区大小需由用户手动设置，过大浪费资源，过小则导致阻塞甚至死锁。现有方法依赖强假设、保守分配或耗时的RTL仿真，难以高效准确地确定最优FIFO大小。因此，需要一种可靠且高效的自动化FIFO sizing方案。

Challenges: 主要挑战包括：1）FIFO大小直接影响性能与资源使用，但其最优值难以静态分析确定；2）数据依赖型设计的控制流复杂，易引发死锁；3）传统仿真方法速度慢，不适用于大规模设计空间探索；4）需在延迟和资源之间进行有效权衡。

Contributions: 1）提出FIFOAdvisor框架，支持自动化的FIFO大小优化；2）集成LightningSim，实现99.9%周期精度的毫秒级增量仿真；3）将FIFO sizing建模为双目标黑盒优化问题，并采用启发式与搜索方法求解；4）与Stream-HLS集成，支持从C++、MLIR或PyTorch降低的仿射数据流设计；5）在多种线性代数与深度学习工作负载上验证有效性。

Results: 在Stream-HLS基准测试上的实验表明，FIFOAdvisor能够生成帕累托最优的延迟-内存权衡曲线。相比基线设计，在几乎不增加延迟的情况下显著减少了内存使用。相较于传统HLS/RTL协同仿真，运行时加速显著，支持快速设计探索。并在具有数据依赖控制流的复杂加速器上展示了实用性。

Conclusion: FIFOAdvisor通过结合高精度快速仿真与多目标优化策略，有效解决了HLS设计中FIFO缓冲区大小自动配置的难题。它不仅提升了资源利用率，还避免了死锁风险，适用于复杂的实际应用场景，推动了高效FPGA设计自动化的发展。

Related Work: 相关工作主要包括基于静态分析的FIFO bound推导、保守缓冲区分配、RTL级仿真驱动优化以及针对数据流模型的形式化验证方法。然而，这些方法通常依赖于对数据流模式的强假设或计算成本高昂，缺乏对数据依赖型设计的通用性和效率。

Abstract: Dataflow hardware designs enable efficient FPGA implementations via
high-level synthesis (HLS), but correctly sizing first-in-first-out (FIFO)
channel buffers remains challenging. FIFO sizes are user-defined and balance
latency and area-undersized FIFOs cause stalls and potential deadlocks, while
oversized ones waste memory. Determining optimal sizes is non-trivial: existing
methods rely on restrictive assumptions, conservative over-allocation, or slow
RTL simulations. We emphasize that runtime-based analyses (i.e., simulation)
are the only reliable way to ensure deadlock-free FIFO optimization for
data-dependent designs.
  We present FIFOAdvisor, a framework that automatically determines FIFO sizes
in HLS designs. It leverages LightningSim, a 99.9\% cycle-accurate simulator
supporting millisecond-scale incremental runs with new FIFO configurations.
FIFO sizing is formulated as a dual-objective black-box optimization problem,
and we explore heuristic and search-based methods to characterize the
latency-resource trade-off. FIFOAdvisor also integrates with Stream-HLS, a
framework for optimizing affine dataflow designs lowered from C++, MLIR, or
PyTorch, enabling deeper optimization of FIFOs in these workloads.
  We evaluate FIFOAdvisor on Stream-HLS design benchmarks spanning linear
algebra and deep learning workloads. Our results reveal Pareto-optimal
latency-memory frontiers across optimization strategies. Compared to baseline
designs, FIFOAdvisor achieves much lower memory usage with minimal delay
overhead. Additionally, it delivers significant runtime speedups over
traditional HLS/RTL co-simulation, making it practical for rapid design space
exploration. We further demonstrate its capability on a complex accelerator
with data-dependent control flow.
  Code and results: https://github.com/sharc-lab/fifo-advisor

</details>


### [2] [Hardware-Efficient Accurate 4-bit Multiplier for Xilinx 7 Series FPGAs](https://arxiv.org/abs/2510.21533)
*Misaki Kida,Shimpei Sato*

Main category: cs.AR

TL;DR: 本文提出了一种针对AMD Xilinx 7系列FPGA的硬件高效4位乘法器设计，仅使用11个LUT和两个CARRY4模块，在减少资源消耗的同时缩短了关键路径延迟。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和边缘推理的普及，需要在基于查找表（LUT）的乘法器中同时优化面积和延迟，以支持大量低比特宽度操作的并行执行。

Challenges: 在FPGA上实现低资源占用和短关键路径延迟的高效4位乘法器设计，同时保持准确性。

Contributions: 提出了一种仅需11个LUT和两个CARRY4块的4位乘法器设计，相比之前的12-LUT设计减少了资源使用，并优化了逻辑功能布局以缩短关键路径。

Results: 该电路实现了最小的资源占用，关键路径延迟为2.750 ns。

Conclusion: 所提出的4位乘法器设计在资源效率和性能方面均优于现有方案，适用于高并行、低比特宽度计算场景。

Related Work: 此前的研究提出了基于12个LUT的4位乘法器设计，本文在此基础上通过逻辑重组进一步优化了LUT数量和延迟。

Abstract: As IoT and edge inference proliferate,there is a growing need to
simultaneously optimize area and delay in lookup-table (LUT)-based multipliers
that implement large numbers of low-bitwidth operations in parallel. This paper
proposes a hardwareefficientaccurate 4-bit multiplier design for AMD Xilinx
7-series FPGAs using only 11 LUTs and two CARRY4 blocks. By reorganizing the
logic functions mapped to the LUTs, the proposed method reduces the LUT count
by one compared with the prior 12-LUT design while also shortening the critical
path. Evaluation confirms that the circuit attains minimal resource usage and a
critical-path delay of 2.750 ns.

</details>


### [3] [Accelerating Electrostatics-based Global Placement with Enhanced FFT Computation](https://arxiv.org/abs/2510.21547)
*Hangyu Zhang,Sachin S. Sapatnekar*

Main category: cs.AR

TL;DR: 本文提出使用加速的FFT技术（AccFFT）来加速基于静电场的解析布局中的电场计算，显著减少了运行时间，并在标准基准测试中实现了比ePlace-MS更快的速度和更优的线长结果。


<details>
  <summary>Details</summary>
Motivation: 为了提升现代VLSI设计中全局布局的效率和质量，尤其是在大规模电路布局中减少电场计算带来的高计算开销。

Challenges: 在基于静电场的解析布局中，电场计算的高时间复杂度限制了算法的可扩展性和整体运行效率。

Contributions: 引入AccFFT技术加速电场计算，将其集成到ePlace-MS和Pplace-MS算法中，显著提升了FFT计算速度和整体运行效率。

Results: 在标准基准上实验显示，FFT计算速度提升5.78倍，整体运行时间比ePlace-MS减少32%，详细布局后的缩放半周长线长减少1.0%。

Conclusion: AccFFT能有效加速基于静电场的布局算法，显著提升性能而不牺牲布局质量，具有良好的应用前景。

Related Work: 相关工作包括ePlace-MS和Pplace-MS等基于静电场模型的解析布局方法，以及传统FFT在电场计算中的应用。

Abstract: Global placement is essential for high-quality and efficient circuit
placement for complex modern VLSI designs. Recent advancements, such as
electrostatics-based analytic placement, have improved scalability and solution
quality. This work demonstrates that using an accelerated FFT technique,
AccFFT, for electric field computation significantly reduces runtime.
Experimental results on standard benchmarks show significant improvements when
incorporated into the ePlace-MS and Pplace-MS algorithms, e.g., a 5.78x speedup
in FFT computation and a 32% total runtime improvement against ePlace-MS, with
1.0% reduction of scaled half-perimeter wirelength after detailed placement.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [4] [A Confidence-Constrained Cloud-Edge Collaborative Framework for Autism Spectrum Disorder Diagnosis](https://arxiv.org/abs/2510.21130)
*Qi Deng,Yinghao Zhang,Yalin Liu,Bishenghui Tao*

Main category: cs.NI

TL;DR: 提出了一种名为C3EKD的云-边协同知识蒸馏框架，用于在保证隐私和低延迟的同时提升自闭症谱系障碍（ASD）诊断系统的准确性，通过边缘初步推断并仅上传低置信度样本至云端进行知识回传，实现了87.4%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决现有ASD诊断系统在纯云端处理时存在的隐私和延迟问题，以及纯边缘推理精度不足的挑战。

Challenges: 如何在保护学生隐私、降低延迟的同时，提升边缘设备上的模型推理准确率，并实现跨学校的模型泛化能力。

Contributions: 提出了C3EKD框架，引入置信度驱动的云边协同机制，采用温度缩放软标签与跨学校聚合损失进行知识蒸馏，实现了数据去中心化下的高效模型更新。

Results: 在两个公开ASD面部图像数据集上，该框架达到了87.4%的准确率，优于传统边缘或云端单独处理的方法。

Conclusion: C3EKD框架能够在不集中原始数据的前提下，有效提升ASD诊断系统的准确性和可扩展性，适合在真实校园环境中部署。

Related Work: 相关工作包括基于物联网的医疗辅助诊断、边缘智能中的知识蒸馏方法，以及隐私保护下的联邦学习与分布式模型训练技术。

Abstract: Autism Spectrum Disorder (ASD) diagnosis systems in school environments
increasingly relies on IoT-enabled cameras, yet pure cloud processing raises
privacy and latency concerns while pure edge inference suffers from limited
accuracy. We propose Confidence-Constrained Cloud-Edge Knowledge Distillation
(C3EKD), a hierarchical framework that performs most inference at the edge and
selectively uploads only low-confidence samples to the cloud. The cloud
produces temperature-scaled soft labels and distils them back to edge models
via a global loss aggregated across participating schools, improving
generalization without centralizing raw data. On two public ASD facial-image
datasets, the proposed framework achieves a superior accuracy of 87.4\%,
demonstrating its potential for scalable deployment in real-world applications.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [Lincoln AI Computing Survey (LAICS) and Trends](https://arxiv.org/abs/2510.20931)
*Albert Reuther,Peter Michaleas,Michael Jones,Vijay Gadepally,Jeremy Kepner*

Main category: cs.DC

TL;DR: 本文是对过去七年AI加速器和处理器的更新调查，称为林肯AI计算调查（LAICS），总结了已公开宣布的商用加速器的峰值性能和功耗数据，并通过散点图分析趋势，新增了计算架构分类。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI（GenAI）模型在过去一年受到广泛关注，推动了对AI训练和推理计算系统的关注，因此需要更新此前的AI加速器调查。

Challenges: 收集和整理近年来不断涌现的商用AI加速器的性能与功耗数据，并对不同市场细分进行有效分类和趋势分析。

Contributions: 更新了LAICS调查，提供了最新的AI加速器数据；通过散点图展示性能与功耗趋势；新增市场细分的详细图表；提出了新的计算架构分类方法。

Results: 调查总结了当前主流AI加速器的峰值性能和功耗；识别出不同市场 segment 的发展趋势；通过可视化手段揭示了技术演进路径。

Conclusion: AI加速器在性能和能效方面持续进步，不同市场 segment 呈现差异化发展，新的架构分类有助于理解技术方向。

Related Work: 此前的LAICS系列年度调查，以及其他关于AI硬件加速器的综述工作。

Abstract: In the past year, generative AI (GenAI) models have received a tremendous
amount of attention, which in turn has increased attention to computing systems
for training and inference for GenAI. Hence, an update to this survey is due.
This paper is an update of the survey of AI accelerators and processors from
past seven years, which is called the Lincoln AI Computing Survey -- LAICS
(pronounced "lace"). This multi-year survey collects and summarizes the current
commercial accelerators that have been publicly announced with peak performance
and peak power consumption numbers. In the same tradition of past papers of
this survey, the performance and power values are plotted on a scatter graph,
and a number of dimensions and observations from the trends on this plot are
again discussed and analyzed. Market segments are highlighted on the scatter
plot, and zoomed plots of each segment are also included. A brief description
of each of the new accelerators that have been added in the survey this year is
included, and this update features a new categorization of computing
architectures that implement each of the accelerators.

</details>


### [6] [Towards Straggler-Resilient Split Federated Learning: An Unbalanced Update Approach](https://arxiv.org/abs/2510.21155)
*Dandan Liang,Jianing Zhang,Evan Chen,Zhe Li,Rui Li,Haibo Yang*

Main category: cs.DC

TL;DR: 提出MU-SplitFed，一种基于零阶优化的抗拖尾SFL算法，通过非平衡更新机制解耦训练进度与拖尾延迟，在非凸目标下实现通信轮次的线性加速。


<details>
  <summary>Details</summary>
Motivation: SFL因Split Server与客户端之间的依赖关系而严重受制于分布式学习系统中的拖尾问题，导致同步延迟，影响系统可扩展性和效率。

Challenges: 拖尾设备导致的同步延迟问题在SFL中尤为突出，因为服务器端模型更新依赖于客户端传来的激活值，造成训练效率下降。

Contributions: 提出MU-SplitFed算法，引入每客户端轮次进行τ次本地更新的机制，实现训练解耦；理论证明其在非凸情形下的收敛速率为O(√(d/(τT)))，并展示通信轮次的线性加速；通过实验验证其在存在拖尾情况下的优越性能。

Results: MU-SplitFed在多种拖尾场景下 consistently 优于基线方法，通过自适应调整τ有效缓解拖尾影响，显著提升训练效率和系统可扩展性。

Conclusion: MU-SplitFed通过非平衡更新机制有效解决了SFL中的拖尾问题，提升了系统训练效率和鲁棒性，具有良好的实际应用前景。

Related Work: 相关工作包括联邦学习（FL）、Split Learning（SL）及其组合SFL，以及零阶优化和抗拖尾策略在分布式学习中的应用。

Abstract: Split Federated Learning (SFL) enables scalable training on edge devices by
combining the parallelism of Federated Learning (FL) with the computational
offloading of Split Learning (SL). Despite its great success, SFL suffers
significantly from the well-known straggler issue in distributed learning
systems. This problem is exacerbated by the dependency between Split Server and
clients: the Split Server side model update relies on receiving activations
from clients. Such synchronization requirement introduces significant time
latency, making straggler a critical bottleneck to the scalability and
efficiency of the system. To mitigate this problem, we propose MU-SplitFed, a
straggler-resilient SFL algorithm in zeroth-order optimization that decouples
training progress from straggler delays via a simple yet effective unbalanced
update mechanism.
  By enabling the server to perform $\tau$ local updates per client round,
MU-SplitFed achieves a convergence rate of $O(\sqrt{d/(\tau T)})$ for
non-convex objectives, demonstrating a linear speedup of $\tau$ in
communication rounds. Experiments demonstrate that MU-SplitFed consistently
outperforms baseline methods with the presence of stragglers and effectively
mitigates their impact through adaptive tuning of $\tau$. The code for this
project is available at https://github.com/Johnny-Zip/MU-SplitFed.

</details>


### [7] [From SLA to vendor-neutral metrics: An intelligent knowledge-based approach for multi-cloud SLA-based broker](https://arxiv.org/abs/2510.21173)
*Víctor Rampérez,Javier Soriano,David Lizcano,Shadi Aljawarneh,Juan A. Lara*

Main category: cs.DC

TL;DR: 本文提出了一种智能知识系统，能够将用户定义的高级服务级别协议（SLA）自动转换为跨多个云提供商可测量的、与供应商无关的指标，从而帮助缺乏专业知识的用户在多云环境中实现SLA合规，并避免供应商锁定问题。


<details>
  <summary>Details</summary>
Motivation: 当前主要云服务提供商将确保SLA合规的机制实施责任转移给用户，而用户往往缺乏相应专业知识；同时各提供商的指标体系不统一，导致策略绑定特定供应商，限制了多云环境的优势发挥。

Challenges: 不同云提供商提供不同的低级指标，使得SLA实现策略难以通用；用户缺乏技术能力来制定有效的SLA保障机制；跨云平台的标准化度量体系缺失导致供应商锁定。

Contributions: 1）提出一个基于知识的智能系统，可自动将高级SLA转换为供应商中立的度量条件，并向用户提供反馈；2）定义了一组可在多个云平台上测量的供应商中立指标；3）在IaaS和PaaS的多云环境中通过两个用例验证了方案的有效性。

Results: 实验结果表明，所提出的解决方案能够在多云环境下实现SLA到可测量指标的自动转换，且得益于两种方案的互补性，用户可以透明、自动地利用多云优势，得到云专家的认可。

Conclusion: 该研究通过智能翻译和标准化度量方法，有效降低了用户在多云环境中保障SLA合规的技术门槛，促进了多云环境的灵活利用，减少了对单一供应商的依赖。

Related Work: 相关工作主要集中在SLA建模、云服务监控和自动化管理等方面，但多数方案依赖特定提供商的指标体系，缺乏跨平台通用性，而本文通过构建知识系统和统一指标体系解决了这一局限。

Abstract: Cloud computing has been consolidated as a support for the vast majority of
current and emerging technologies. However, there are some barriers that
prevent the exploitation of the full potential of this technology. First, the
major cloud providers currently put the onus of implementing the mechanisms
that ensure compliance with the desired service levels on cloud consumers.
However, consumers do not have the required expertise. Since each cloud
provider exports a different set of low-level metrics, the strategies defined
to ensure compliance with the established service-level agreement (SLA) are
bound to a particular cloud provider. This fosters provider lock-in and
prevents consumers from benefiting from the advantages of multi-cloud
environments. This paper presents a solution to the problem of automatically
translating SLAs into objectives expressed as metrics that can be measured
across multiple cloud providers. First, we propose an intelligent
knowledge-based system capable of automatically translating high-level SLAs
defined by cloud consumers into a set of conditions expressed as vendor-neutral
metrics, providing feedback to cloud consumers (intelligent tutoring system).
Secondly, we present the set of vendor-neutral metrics and explain how they can
be measured for the different cloud providers. Finally, we report a validation
based on two use cases (IaaS and PaaS) in a multi-cloud environment formed by
leading cloud providers. This evaluation has demonstrated that, thanks to the
complementarity of the two solutions, cloud consumers can automatically and
transparently exploit the multi-cloud in many application domains, as endorsed
by the cloud experts consulted in the course of this study.

</details>


### [8] [Arbitration-Free Consistency is Available (and Vice Versa)](https://arxiv.org/abs/2510.21304)
*Hagit Attiya,Constantin Enea,Enrique Román-Calvo*

Main category: cs.DC

TL;DR: 本文提出了一种通用的语义框架，用于分析分布式存储系统中对象语义与一致性模型的组合，并提出了“无仲裁一致性”（AFC）定理，指出一个对象在某种一致性模型下可实现高可用的充要条件是其具有“无仲裁性”，即无需全局仲裁顺序来解决可见性或读取依赖，从而统一并推广了CAP和因果一致性等经典结果。


<details>
  <summary>Details</summary>
Motivation: 为了精确解释在分布式存储系统中哪些对象语义与一致性模型的组合可以实现高可用性，弥补传统理论（如CAP定理）仅适用于简单读写接口的局限。

Challenges: 如何形式化地统一不同类型的存储对象（如键值存储、计数器、集合、CRDT、事务数据库）和多种一致性模型（从因果一致性到快照隔离等），并识别出决定是否需要协调操作的根本属性。

Contributions: 1）提出一个统一的语义框架，整合多种存储对象和一致性模型；2）定义“无仲裁一致性”（AFC）概念；3）证明AFC定理，揭示高可用实现的充要条件；4）统一并推广了CAP定理和相关一致性理论。

Results: 证明了在所提出的通用框架下，一个对象规格在某一致性模型中可实现高可用当且仅当它是仲裁自由的，即不依赖全局顺序仲裁来解决操作间的可见性或依赖关系。

Conclusion: 仲裁自由性是决定分布式对象是否可协调无关（即高可用）实现的本质属性，AFC定理为设计高可用分布式系统提供了理论指导和判断依据。

Related Work: CAP定理指出强一致性与分区可用性不可兼得；因果一致性等弱一致性模型可在无协调下实现；之前的工作未能系统解释不同对象与一致性组合下的可用性边界，本文在此基础上进行了推广。

Abstract: The fundamental tension between \emph{availability} and \emph{consistency}
shapes the design of distributed storage systems. Classical results capture
extreme points of this trade-off: the CAP theorem shows that strong models like
linearizability preclude availability under partitions, while weak models like
causal consistency remain implementable without coordination. These theorems
apply to simple read-write interfaces, leaving open a precise explanation of
the combinations of object semantics and consistency models that admit
available implementations.
  This paper develops a general semantic framework in which storage
specifications combine operation semantics and consistency models. The
framework encompasses a broad range of objects (key-value stores, counters,
sets, CRDTs, and transactional databases) and consistency models (from causal
consistency and sequential consistency to snapshot isolation and transactional
and non-transactional SQL).
  Within this framework, we prove the \emph{Arbitration-Free Consistency} (AFC)
theorem, showing that an object specification within a consistency model admits
an available implementation if and only if it is \emph{arbitration-free}, that
is, it does not require a total arbitration order to resolve visibility or read
dependencies.
  The AFC theorem unifies and generalizes previous results, revealing
arbitration-freedom as the fundamental property that delineates
coordination-free consistency from inherently synchronized behavior.

</details>


### [9] [Parsley's Group Size Study](https://arxiv.org/abs/2510.21348)
*João A. Silva,Hervé Paulino,João M. Lourenço*

Main category: cs.DC

TL;DR: Parsley是一种基于组的弹性分布式哈希表，通过主动的节点重定位和动态数据分片机制提升系统鲁棒性和负载均衡，并通过软硬双重界限优化组大小管理，增强系统在高动态环境下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了提高分布式哈希表在高动态环境（如频繁节点加入和离开）下的稳定性和可扩展性，Parsley旨在通过更智能的组大小管理和数据分布机制来减少系统性能波动。

Challenges: 主要挑战包括如何在节点频繁变化（churn）的情况下维持组大小在合理范围内，避免硬性限制被突破，同时确保负载均衡和系统高效运行。

Contributions: 提出了一种带有软硬双重界限的组大小管理机制；引入了预判性的节点重定位策略和动态数据分片机制；并通过系统化的拓扑分析为参数选择提供了理论依据。

Results: 实验结果表明，Parsley能有效预防组大小越界，提升系统稳定性，并在大规模动态环境中展现出良好的性能与可扩展性。

Conclusion: Parsley通过引入软界限和系统化参数分析，显著增强了分布式哈希表在高动态环境下的鲁棒性和可维护性，为类似系统的设计提供了实践指导。

Related Work: 与以往仅设定组大小硬限制而缺乏参数依据的DHT系统不同，Parsley借鉴了分片与组管理相关研究，并首次系统化分析了参数选择对性能的影响。

Abstract: Parsley is a resilient group-based Distributed Hash Table that incorporates a
preemptive peer relocation technique and a dynamic data sharding mechanism to
enhance robustness and balance. In addition to the hard limits on group size,
defined by minimum and maximum thresholds, Parsley introduces two soft limits
that define a target interval for maintaining stable group sizes. These soft
boundaries allow the overlay to take proactive measures to prevent violations
of the hard limits, improving system stability under churn. This work provides
an in-depth analysis of the rationale behind the parameter values adopted for
Parsley's evaluation. Unlike related systems, which specify group size limits
without justification, we conduct a systematic overlay characterization study
to understand the effects of these parameters on performance and scalability.
The study examines topology operations, the behavior of large groups, and the
overall trade-offs observed, offering a grounded explanation for the chosen
configuration values.

</details>


### [10] [LIDC: A Location Independent Multi-Cluster Computing Framework for Data Intensive Science](https://arxiv.org/abs/2510.21373)
*Sankalpa Timilsina,Susmit Shannigrahi*

Main category: cs.DC

TL;DR: 本文提出了一种基于语义命名的去中心化控制平面，用于在地理上分散的计算集群中动态分配计算任务，克服了传统集中式方法在多组织协作中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算任务分配方法依赖于逻辑上的集中式控制器（如Kubernetes），在多组织协作环境中不适用，且工作流需要手动配置，难以适应基础设施的动态变化。

Challenges: 如何在多组织、地理分布的计算环境中实现无需预先配置、不依赖集中式控制器的动态计算任务分配。

Contributions: 提出了一种基于语义命名的去中心化控制平面，使计算任务的分配与位置无关，支持跨集群的动态调度，无需预先知道集群位置或进行平台特定配置。

Results: 该方法实现了位置无关的任务调度，支持动态适应基础设施变化，提升了跨组织协作中计算资源的利用率和灵活性。

Conclusion: 基于语义命名的去中心化控制平面有效解决了地理分布和多组织环境下的计算任务分配问题，为科学计算协作提供了更灵活、可扩展的解决方案。

Related Work: 相关工作包括Kubernetes等集中式编排系统，以及面向分布式计算的资源调度框架，但这些方法通常依赖中心化控制和静态配置。

Abstract: Scientific communities are increasingly using geographically distributed
computing platforms. The current methods of compute placement predominantly use
logically centralized controllers such as Kubernetes (K8s) to match tasks to
available resources. However, this centralized approach is unsuitable in
multi-organizational collaborations. Furthermore, workflows often need to use
manual configurations tailored for a single platform and cannot adapt to
dynamic changes across infrastructure. Our work introduces a decentralized
control plane for placing computations on geographically dispersed compute
clusters using semantic names. We assign semantic names to computations to
match requests with named Kubernetes (K8s) service endpoints. We show that this
approach provides multiple benefits. First, it allows placement of
computational jobs to be independent of location, enabling any cluster with
sufficient resources to execute the computation. Second, it facilitates dynamic
compute placement without requiring prior knowledge of cluster locations or
predefined configurations.

</details>


### [11] [On Reduction and Synthesis of Petri's Cycloids](https://arxiv.org/abs/2510.21493)
*Rüdiger Valk,Daniel Moldt*

Main category: cs.DC

TL;DR: 本文研究了循环体（cycloids）这一特殊类型的Petri网，提出了一种基于重写系统的约简方法，并推导了从Petri网结构合成循环体参数的方法，从而实现了高效的循环体同构判定算法。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解循环体的结构特性，并提供有效的分析与判定工具，特别是在建模强同步顺序过程时的应用需求。

Challenges: 如何从Petri网结构中合成循环体的四个参数；如何定义有效的约简系统以识别不可约循环体；以及如何高效判定两个循环体是否同构。

Contributions: 定义了类似重写系统的循环体约简系统；证明了不可约循环体的性质；提出了从Petri网结构推导循环体参数的方法；并基于此提出了一种高效的循环体同构判定算法。

Results: 成功建立了循环体参数与其Petri网结构之间的映射关系，获得了不可约循环体的关键性质，并实现了对循环体同构问题的有效判定。

Conclusion: 循环体的代数结构可通过约简系统进行分析，其参数可由结构推导，从而为循环体的理论研究和应用提供了有力的数学工具和算法支持。

Related Work: 本文基于Petri网理论和Petri的一般系统理论，与关于代数结构建模、Petri网约简方法以及形式化验证中过程同构判定的相关工作密切相关。

Abstract: Cycloids are particular Petri nets for modelling processes of actions and
events, belonging to the fundaments of Petri's general systems theory. Defined
by four parameters they provide an algebraic formalism to describe strongly
synchronized sequential processes. To further investigate their structure,
reduction systems of cycloids are defined in the style of rewriting systems and
properties of irreducible cycloids are proved. In particular the synthesis of
cycloid parameters from their Petri net structure is derived, leading to an
efficient method for a decision procedure for cycloid isomorphism.

</details>


### [12] [Distributed $(Δ+1)$-Coloring in Graphs of Bounded Neighborhood Independence](https://arxiv.org/abs/2510.21549)
*Marc Fuchs,Fabian Kuhn*

Main category: cs.DC

TL;DR: 本文研究了在邻域独立数受限的图中，分布式$(\Delta+1)$-着色问题的确定性复杂度，提出了一种新的算法，可在拟多对数时间内求解，并指出已有方法在高阶超图边着色中的局限性。


<details>
  <summary>Details</summary>
Motivation: 旨在理解$(\Delta+1)$-着色在分布式环境下的确定性复杂度，特别是在邻域独立数$\theta$较小的图中是否存在更高效的算法。

Challenges: 确定$(\Delta+1)$-着色在标准消息传递模型中的最优确定性时间复杂度仍是一个开放问题，尤其是在一般图中如何突破当前复杂度瓶颈。

Contributions: 1. 在邻域独立数为$\theta$的图中，将$(\Delta+1)$-着色的复杂度改进至$(\theta\cdot\log\Delta)^{O(\log\log\Delta / \log\log\log\Delta)}+O(\log^* n)$轮；2. 证明当$\theta$在$\Delta$的多对数范围内时，可在拟多对数时间内求解；3. 指出现有适用于$(2\Delta-1)$-边着色的方法在秩至少为3的超图中失效。

Results: 提出了新的分布式着色算法，在$\theta=O(\text{polylog}(\Delta))$时实现了$(\Delta+1)$-着色的拟多对数轮复杂度，并揭示了现有边着色技术在高阶超图中的局限性。

Conclusion: $(\Delta+1)$-着色在特定结构图中可显著加速，但向更一般情形或高阶结构推广仍面临挑战。

Related Work: 已有工作表明在$\theta=O(1)$的图中$(\Delta+1)$-着色可在$2^{O(\sqrt{\log\Delta})}+O(\log^* n)$轮内解决；此外，$(2\Delta-1)$-边着色在普通图中已有基于匹配的多对数时间算法。

Abstract: The distributed coloring problem is arguably one of the key problems studied
in the area of distributed graph algorithms. The most standard variant of the
problem asks for a proper vertex coloring of a graph with $\Delta+1$ colors,
where $\Delta$ is the maximum degree of the graph. Despite an immense amount of
work on distributed coloring problems in the distributed setting, determining
the deterministic complexity of $(\Delta+1)$-coloring in the standard message
passing model remains one of the most important open questions of the area. In
this paper, we aim to improve our understanding of the deterministic complexity
of $(\Delta+1)$-coloring as a function of $\Delta$ in a special family of
graphs for which significantly faster algorithms are already known. The
neighborhood independence $\theta$ of a graph is the maximum number of pairwise
non-adjacent neighbors of some node of the graph. In general, in graphs of
neighborhood independence $\theta=O(1)$ (e.g., line graphs), it is known that
$(\Delta+1)$-coloring can be solved in $2^{O(\sqrt{\log\Delta})}+O(\log^* n)$
rounds. In the present paper, we significantly improve this result, and we show
that in graphs of neighborhood independence $\theta$, a $(\Delta+1)$-coloring
can be computed in $(\theta\cdot\log\Delta)^{O(\log\log\Delta /
\log\log\log\Delta)}+O(\log^* n)$ rounds and thus in quasipolylogarithmic time
in $\Delta$ as long as $\theta$ is at most polylogarithmic in $\Delta$. We also
show that the known approach that leads to a polylogarithmic in $\Delta$
algorithm for $(2\Delta-1)$-edge coloring already fails for edge colorings of
hypergraphs of rank at least $3$.

</details>
