{"id": "2511.00294", "categories": ["cs.DC", "cs.NI", "68M14", "C.2.4"], "pdf": "https://arxiv.org/pdf/2511.00294", "abs": "https://arxiv.org/abs/2511.00294", "authors": ["Lucas Almeida", "Maycon Peixoto"], "title": "Tetris: An SLA-aware Application Placement Strategy in the Edge-Cloud Continuum", "comment": "10 pages, 7 sections, 12 figures, 9 tables", "summary": "An Edge-Cloud Continuum integrates edge and cloud resources to provide a\nflexible and scalable infrastructure. This paradigm can minimize latency by\nprocessing data closer to the source at the edge while leveraging the vast\ncomputational power of the cloud for more intensive tasks. In this context,\nmodule application placement requires strategic allocation plans that align\nuser demands with infrastructure constraints, aiming for efficient resource\nuse. Therefore, we propose Tetris, an application placement strategy that\nutilizes a heuristic algorithm to distribute computational services across edge\nand cloud resources efficiently. Tetris prioritizes services based on SLA\nurgencies and resource efficiency to avoid system overloading. Our results\ndemonstrate that Tetris reduces SLA violations by approximately 76% compared to\nthe baseline method, which serves as a reference point for benchmarking\nperformance in this scenario. Therefore, Tetris offers an effective placement\napproach for managing latency-sensitive applications in Edge-Cloud Continuum\nenvironments, enhancing Quality of Service (QoS) for users.", "AI": {"tldr": "Tetris\u662f\u4e00\u79cd\u9762\u5411\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u7684\u5e94\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u7b97\u6cd5\u9ad8\u6548\u5206\u914d\u8ba1\u7b97\u670d\u52a1\uff0c\u4f18\u5148\u8003\u8651SLA\u7d27\u6025\u7a0b\u5ea6\u548c\u8d44\u6e90\u6548\u7387\uff0c\u663e\u8457\u51cf\u5c11SLA\u8fdd\u89c4\uff0c\u63d0\u5347\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u5728\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u4e2d\uff0c\u5982\u4f55\u6709\u6548\u5206\u914d\u5e94\u7528\u6a21\u5757\u4ee5\u517c\u987e\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u8ba1\u7b97\u80fd\u529b\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u5728\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u540c\u65f6\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "challenges": "\u5e94\u7528\u653e\u7f6e\u9700\u5e73\u8861\u8fb9\u7f18\u7684\u4f4e\u5ef6\u8fdf\u4f18\u52bf\u4e0e\u4e91\u7684\u9ad8\u7b97\u529b\u7279\u6027\uff0c\u540c\u65f6\u907f\u514d\u7cfb\u7edf\u8fc7\u8f7d\uff0c\u6ee1\u8db3SLA\u8981\u6c42\u5e76\u63d0\u5347\u8d44\u6e90\u6548\u7387\u3002", "contributions": "\u63d0\u51faTetris\uff0c\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u5e94\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u80fd\u591f\u6839\u636eSLA\u7d27\u6025\u7a0b\u5ea6\u548c\u8d44\u6e90\u6548\u7387\u8fdb\u884c\u670d\u52a1\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u8d44\u6e90\u5206\u914d\u3002", "results": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cTetris\u5c06SLA\u8fdd\u89c4\u51cf\u5c11\u4e86\u7ea676%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u3002", "conclusion": "Tetris\u4e3a\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u73af\u5883\u4e0b\u7684\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u653e\u7f6e\u65b9\u6848\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u670d\u52a1\u8d28\u91cf\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u4efb\u52a1\u5378\u8f7d\u3001\u8d44\u6e90\u8c03\u5ea6\u548c\u4e91\u8fb9\u534f\u540c\u7ba1\u7406\uff0c\u4f46\u8f83\u5c11\u7efc\u5408\u8003\u8651SLA\u7d27\u6025\u7a0b\u5ea6\u4e0e\u8d44\u6e90\u6548\u7387\u7684\u52a8\u6001\u6743\u8861\u3002"}}
{"id": "2511.00603", "categories": ["cs.DC", "cs.AI", "cs.NI", "68T05", "I.2.11"], "pdf": "https://arxiv.org/pdf/2511.00603", "abs": "https://arxiv.org/abs/2511.00603", "authors": ["Yubo Wang", "Yubo Cui", "Tuo Shi", "Danyang Li", "Wenxin Li", "Lide Suo", "Tao Wang", "Xin Xie"], "title": "EPARA: Parallelizing Categorized AI Inference in Edge Clouds", "comment": "15 pages,20 figures", "summary": "With the increasing adoption of AI applications such as large language models\nand computer vision AI, the computational demands on AI inference systems are\ncontinuously rising, making the enhancement of task processing capacity using\nexisting hardware a primary objective in edge clouds. We propose EPARA, an\nend-to-end AI parallel inference framework in edge, aimed at enhancing the edge\nAI serving capability. Our key idea is to categorize tasks based on their\nsensitivity to latency/frequency and requirement for GPU resources, thereby\nachieving both request-level and service-level task-resource allocation. EPARA\nconsists of three core components: 1) a task-categorized parallelism allocator\nthat decides the parallel mode of each task, 2) a distributed request handler\nthat performs the calculation for the specific request, and 3) a state-aware\nscheduler that periodically updates service placement in edge clouds. We\nimplement a EPARA prototype and conduct a case study on the EPARA operation for\nLLMs and segmentation tasks. Evaluation through testbed experiments involving\nedge servers, embedded devices, and microcomputers shows that EPARA achieves up\nto 2.1$\\times$ higher goodput in production workloads compared to prior\nframeworks, while adapting to various edge AI inference tasks.", "AI": {"tldr": "EPARA\u662f\u4e00\u79cd\u9762\u5411\u8fb9\u7f18\u8ba1\u7b97\u7684\u7aef\u5230\u7aefAI\u5e76\u884c\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u7c7b\u548c\u8d44\u6e90\u611f\u77e5\u8c03\u5ea6\uff0c\u63d0\u5347\u8fb9\u7f18AI\u670d\u52a1\u7684\u541e\u5410\u91cf\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u751f\u4ea7\u8d1f\u8f7d\u4e0b\u76f8\u8f83\u73b0\u6709\u6846\u67b6\u6700\u9ad8\u53ef\u63d0\u53472.1\u500dgoodput\u3002", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49AI\u5e94\u7528\u7684\u666e\u53ca\uff0c\u8fb9\u7f18\u7aef\u7684\u63a8\u7406\u8ba1\u7b97\u9700\u6c42\u4e0d\u65ad\u4e0a\u5347\uff0c\u5982\u4f55\u5229\u7528\u73b0\u6709\u786c\u4ef6\u63d0\u5347\u4efb\u52a1\u5904\u7406\u80fd\u529b\u6210\u4e3a\u8fb9\u7f18\u4e91\u7684\u5173\u952e\u6311\u6218\u3002", "challenges": "\u8fb9\u7f18\u73af\u5883\u4e2d\u8d44\u6e90\u53d7\u9650\uff0c\u4e0d\u540cAI\u4efb\u52a1\u5bf9\u5ef6\u8fdf\u3001\u9891\u7387\u548cGPU\u8d44\u6e90\u7684\u9700\u6c42\u5dee\u5f02\u5927\uff0c\u96be\u4ee5\u7edf\u4e00\u9ad8\u6548\u8c03\u5ea6\uff1b\u540c\u65f6\u9700\u517c\u987e\u8bf7\u6c42\u7ea7\u548c\u670d\u52a1\u7ea7\u7684\u8d44\u6e90\u5206\u914d\u3002", "contributions": "\u63d0\u51fa\u4e86EPARA\u6846\u67b6\uff0c\u5305\u542b\u4efb\u52a1\u5206\u7c7b\u5e76\u884c\u5206\u914d\u5668\u3001\u5206\u5e03\u5f0f\u8bf7\u6c42\u5904\u7406\u5668\u548c\u72b6\u6001\u611f\u77e5\u8c03\u5ea6\u5668\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u4efb\u52a1\u7279\u6027\u7684\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5206\u914d\u4e0e\u52a8\u6001\u670d\u52a1\u90e8\u7f72\u3002", "results": "\u5728\u5305\u542b\u8fb9\u7f18\u670d\u52a1\u5668\u3001\u5d4c\u5165\u5f0f\u8bbe\u5907\u548c\u5fae\u8ba1\u7b97\u673a\u7684\u6d4b\u8bd5\u5e73\u53f0\u4e0a\uff0cEPARA\u5728LLM\u548c\u5206\u5272\u4efb\u52a1\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u76f8\u6bd4\u5148\u524d\u6846\u67b6\u6700\u9ad8\u5b9e\u73b0\u4e862.1\u500d\u7684goodput\u63d0\u5347\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u591a\u79cd\u8fb9\u7f18AI\u63a8\u7406\u4efb\u52a1\u7684\u826f\u597d\u9002\u5e94\u6027\u3002", "conclusion": "EPARA\u901a\u8fc7\u4efb\u52a1\u611f\u77e5\u7684\u5e76\u884c\u7b56\u7565\u548c\u52a8\u6001\u8c03\u5ea6\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8fb9\u7f18AI\u63a8\u7406\u7cfb\u7edf\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u8fb9\u7f18\u73af\u5883\u4e0b\u9ad8\u6548\u90e8\u7f72\u591a\u6837\u5316AI\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u8fb9\u7f18AI\u63a8\u7406\u4f18\u5316\u3001\u6a21\u578b\u5206\u5272\u3001\u4efb\u52a1\u8c03\u5ea6\u6846\u67b6\u4ee5\u53ca\u8d44\u6e90\u611f\u77e5\u7684\u5fae\u670d\u52a1\u90e8\u7f72\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u4efb\u52a1\u654f\u611f\u5ea6\u548c\u8d44\u6e90\u9700\u6c42\u7684\u7efc\u5408\u5206\u7c7b\u4e0e\u534f\u540c\u8c03\u5ea6\u3002"}}
{"id": "2511.00796", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00796", "abs": "https://arxiv.org/abs/2511.00796", "authors": ["Ran Yan", "Youhe Jiang", "Tianyuan Wu", "Jiaxuan Gao", "Zhiyu Mei", "Wei Fu", "Haohui Mai", "Wei Wang", "Yi Wu", "Binhang Yuan"], "title": "AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs", "comment": null, "summary": "Maximizing training throughput and cost-efficiency of RL for LLMs is\nessential to democratize this advanced technique. One promising but challenging\napproach is to deploy such a computational workflow over heterogeneous GPUs.\nUnlike conventional large-scale LLM pretraining, RL training generally\ndecomposes into three coupled stages, i.e., rollout generation, reward\ncomputation, and policy/value updates, which exhibit markedly different compute\nintensities, memory footprints, and communication patterns. Recent research\nshows that fully asynchronous RL training can disaggregate these stages across\ndisjoint hardware pools without sacrificing training stability, creating a\ngreat opportunity for real-world heterogeneous deployment. To this end, we\npresent AReaL-Hex, a heterogeneity-aware asynchronous RL training system that\neffectively schedules how to execute rollout generation and policy model\ntraining over heterogeneous GPUs while enforcing data staleness bounds.\nConcretely, we use a two-phase scheduler: (i) a constrained search with MILP to\nselect per-stage parallelization strategies and workload assignments given a\nresource budget, and (ii) a graph-partitioning step that allocates\nheterogeneous GPUs and interconnects to maximize end-to-end throughput. Built\natop a fully asynchronous RL architecture, AReaL-Hex maps HBM-I/O-bound\ngeneration and compute-bound optimization to more cost-efficient resources and\nbalances their producer-consumer interactions to avoid both idleness and stale\nrollout trajectories. On the mathematical reasoning task with various model\nscales (1.5B, 7B, and 14B), compared to homogeneous deployments of\nstate-of-the-art asynchronous RL systems: (i) When maintaining the same total\nbudgets, AReaL-Hex delivers up to 1.50x higher training throughput; (ii) When\nachieving the same training throughput, AReaL-Hex results in up to 1.46x\nreduction in training cost.", "AI": {"tldr": "AReaL-Hex \u662f\u4e00\u79cd\u9762\u5411\u5f02\u6784GPU\u7684\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8c03\u5ea6\u5668\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u5728\u4fdd\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u5728\u5f02\u6784GPU\u4e0a\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u5730\u8fdb\u884c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u8d44\u6e90\u5229\u7528\u7387\uff0c\u63a8\u52a8\u8be5\u6280\u672f\u7684\u666e\u53ca\u3002", "challenges": "RL\u8bad\u7ec3\u5305\u542b\u751f\u6210\u3001\u5956\u52b1\u8ba1\u7b97\u548c\u7b56\u7565\u66f4\u65b0\u4e09\u4e2a\u9636\u6bb5\uff0c\u5404\u9636\u6bb5\u8ba1\u7b97\u5f3a\u5ea6\u3001\u5185\u5b58\u9700\u6c42\u548c\u901a\u4fe1\u6a21\u5f0f\u5dee\u5f02\u5927\uff1b\u5728\u5f02\u6784\u786c\u4ef6\u4e0a\u534f\u8c03\u8fd9\u4e9b\u9636\u6bb5\u5e76\u63a7\u5236\u6570\u636e\u9648\u65e7\u6027\u662f\u4e00\u5927\u6311\u6218\u3002", "contributions": "\u63d0\u51fa\u4e86AReaL-Hex\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8c03\u5ea6\u5668\uff08MILP\u7ea6\u675f\u641c\u7d22\u4e0e\u56fe\u5212\u5206\uff09\u5b9e\u73b0\u5f02\u6784\u8d44\u6e90\u7684\u9ad8\u6548\u5206\u914d\uff1b\u652f\u6301\u5c06HBM/I-O\u5bc6\u96c6\u578b\u4e0e\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u5339\u914d\u5230\u5408\u9002\u7684\u786c\u4ef6\uff0c\u5e73\u8861\u751f\u4ea7-\u6d88\u8d39\u5173\u7cfb\uff0c\u4fdd\u8bc1\u4f4e\u9648\u65e7\u6027\u3002", "results": "\u57281.5B\u81f314B\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff1a\u5728\u76f8\u540c\u9884\u7b97\u4e0b\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.50\u500d\uff1b\u5728\u76f8\u540c\u541e\u5410\u91cf\u4e0b\uff0c\u8bad\u7ec3\u6210\u672c\u6700\u9ad8\u964d\u4f4e1.46\u500d\u3002", "conclusion": "AReaL-Hex\u6709\u6548\u5b9e\u73b0\u4e86\u5f02\u6784GPU\u4e0a\u7684\u9ad8\u6548\u5f02\u6b65RL\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6210\u672c\u6548\u76ca\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u3002", "related_work": "\u57fa\u4e8e\u5168\u5f02\u6b65RL\u67b6\u6784\u7684\u6700\u65b0\u7814\u7a76\uff0c\u652f\u6301\u9636\u6bb5\u89e3\u8026\u4e0e\u8de8\u786c\u4ef6\u6c60\u5e76\u884c\uff0c\u4e3a\u5f02\u6784\u90e8\u7f72\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00295", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.00295", "abs": "https://arxiv.org/abs/2511.00295", "authors": ["Kosmas Alexandridis", "Giorgos Dimitrakopoulos"], "title": "H-FA: A Hybrid Floating-Point and Logarithmic Approach to Hardware Accelerated FlashAttention", "comment": "Accepted for publication at IEEE Transactions on Circuits and Systems\n  for Artificial Intelligence", "summary": "Transformers have significantly advanced AI and machine learning through\ntheir powerful attention mechanism. However, computing attention on long\nsequences can become a computational bottleneck. FlashAttention mitigates this\nby fusing the softmax and matrix operations into a tiled computation pattern\nthat decouples performance from sequence length. Though designed for GPUs, its\nsimplicity also makes it well suited for direct hardware acceleration. To\nimprove hardware implementation, we compute FlashAttention using a mixture of\nfloating-point and fixed-point logarithm domain representations. Floating-point\nis used to compute attention scores from query and key matrices, while\nlogarithmic computation simplifies the fused computation of softmax\nnormalization and the multiplication with the value matrix. This\ntransformation, called H-FA, replaces vector-wide floating-point multiplication\nand division operations by additions and subtractions implemented efficiently\nwith fixed-point arithmetic in the logarithm domain. Exponential function\nevaluations are effectively omitted and fused with the rest operations, and the\nfinal result is directly returned to floating-point arithmetic without any\nadditional hardware overhead. Hardware implementation results at 28nm\ndemonstrate that H-FA achieves a 26.5% reduction in area and a 23.4% reduction\nin power, on average, compared to FlashAttention parallel hardware\narchitectures built solely with floating-point datapaths, without hindering\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aH-FA\u7684\u786c\u4ef6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6d6e\u70b9\u548c\u5bf9\u6570\u57df\u5b9a\u70b9\u8ba1\u7b97\u6765\u52a0\u901fFlashAttention\u7684\u786c\u4ef6\u5b9e\u73b0\uff0c\u572828nm\u5de5\u827a\u4e0b\u5b9e\u73b0\u4e86\u9762\u79ef\u548c\u529f\u8017\u7684\u663e\u8457\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8e\u4f20\u7edfFlashAttention\u5728\u957f\u5e8f\u5217\u4e0a\u7684\u8ba1\u7b97\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u4e14\u7eaf\u6d6e\u70b9\u786c\u4ef6\u5b9e\u73b0\u5f00\u9500\u5927\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\u3002", "challenges": "\u5982\u4f55\u5728\u4e0d\u635f\u5931\u7cbe\u5ea6\u548c\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u964d\u4f4eFlashAttention\u786c\u4ef6\u5b9e\u73b0\u7684\u9762\u79ef\u548c\u529f\u8017\u662f\u4e3b\u8981\u6311\u6218\u3002\u6b64\u5916\uff0c\u878d\u5408softmax\u548c\u77e9\u9635\u4e58\u6cd5\u64cd\u4f5c\u5bf9\u786c\u4ef6\u8bbe\u8ba1\u63d0\u51fa\u4e86\u9ad8\u8981\u6c42\u3002", "contributions": "\u63d0\u51fa\u4e86H-FA\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u5bf9\u6570\u57df\u5b9a\u70b9\u8ba1\u7b97\u5f15\u5165FlashAttention\u786c\u4ef6\u5b9e\u73b0\uff0c\u7528\u52a0\u51cf\u6cd5\u66ff\u4ee3\u4e58\u9664\u6cd5\uff0c\u5e76\u7701\u7565\u6307\u6570\u8fd0\u7b97\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u786c\u4ef6\u5f00\u9500\u3002", "results": "\u572828nm\u5de5\u827a\u4e0b\uff0cH-FA\u76f8\u6bd4\u7eaf\u6d6e\u70b9\u67b6\u6784\u5e73\u5747\u51cf\u5c1126.5%\u7684\u9762\u79ef\u548c23.4%\u7684\u529f\u8017\uff0c\u4e14\u672a\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "H-FA\u901a\u8fc7\u6df7\u5408\u6d6e\u70b9\u4e0e\u5bf9\u6570\u57df\u5b9a\u70b9\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u4e86FlashAttention\u7684\u786c\u4ef6\u6548\u7387\uff0c\u4e3aTransformer\u6a21\u578b\u7684\u9ad8\u6548\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ecFlashAttention\u7684GPU\u4f18\u5316\u3001\u6ce8\u610f\u529b\u673a\u5236\u7684\u786c\u4ef6\u52a0\u901f\u7814\u7a76\uff0c\u4ee5\u53ca\u5bf9\u6570\u57df\u8ba1\u7b97\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.00321", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00321", "abs": "https://arxiv.org/abs/2511.00321", "authors": ["Dowon Kim", "MinJae Lee", "Janghyeon Kim", "HyuckSung Kwon", "Hyeonggyu Jeong", "Sang-Soo Park", "Minyong Yoon", "Si-Dong Roh", "Yongsuk Kwon", "Jinin So", "Jungwook Choi"], "title": "Scalable Processing-Near-Memory for 1M-Token LLM Inference: CXL-Enabled KV-Cache Management Beyond GPU Limits", "comment": null, "summary": "The expansion of context windows in large language models (LLMs) to\nmulti-million tokens introduces severe memory and compute bottlenecks,\nparticularly in managing the growing Key-Value (KV) cache. While Compute\nExpress Link (CXL) enables non-eviction frameworks that offload the full\nKV-cache to scalable external memory, these frameworks still suffer from costly\ndata transfers when recalling non-resident KV tokens to limited GPU memory as\ncontext lengths increase. This work proposes scalable Processing-Near-Memory\n(PNM) for 1M-Token LLM Inference, a CXL-enabled KV-cache management system that\ncoordinates memory and computation beyond GPU limits. Our design offloads token\npage selection to a PNM accelerator within CXL memory, eliminating costly\nrecalls and enabling larger GPU batch sizes. We further introduce a hybrid\nparallelization strategy and a steady-token selection mechanism to enhance\ncompute efficiency and scalability. Implemented atop a state-of-the-art CXL-PNM\nsystem, our solution delivers consistent performance gains for LLMs with up to\n405B parameters and 1M-token contexts. Our PNM-only offloading scheme (PNM-KV)\nand GPU-PNM hybrid with steady-token execution (PnG-KV) achieve up to 21.9x\nthroughput improvement, up to 60x lower energy per token, and up to 7.3x better\ntotal cost efficiency than the baseline, demonstrating that CXL-enabled\nmulti-PNM architectures can serve as a scalable backbone for future\nlong-context LLM inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCXL\u7684\u8fd1\u5185\u5b58\u5904\u7406\uff08PNM\uff09KV\u7f13\u5b58\u7ba1\u7406\u65b9\u6848\uff0c\u7528\u4e8e\u652f\u6301\u767e\u4e07\u7ea7Token\u4e0a\u4e0b\u6587\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u901a\u8fc7\u5c06\u9875\u9762\u9009\u62e9\u5378\u8f7d\u81f3CXL\u5185\u5b58\u4e2d\u7684PNM\u52a0\u901f\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u541e\u5410\u91cf\u3001\u80fd\u6548\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6269\u5c55\u81f3\u767e\u4e07\u7ea7Token\uff0cKV\u7f13\u5b58\u7684\u589e\u957f\u5bfc\u81f4GPU\u5185\u5b58\u4e0e\u8ba1\u7b97\u8d44\u6e90\u9762\u4e34\u4e25\u91cd\u74f6\u9888\uff0c\u73b0\u6709CXL\u65b9\u6848\u4ecd\u56e0\u9891\u7e41\u8c03\u5165\u975e\u9a7b\u7559KV\u6570\u636e\u800c\u4ea7\u751f\u9ad8\u6602\u4f20\u8f93\u5f00\u9500\u3002", "challenges": "\u5982\u4f55\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u9ad8\u6548\u7ba1\u7406\u4e0d\u65ad\u589e\u957f\u7684KV\u7f13\u5b58\uff1b\u5982\u4f55\u51cf\u5c11GPU\u4e0e\u5916\u90e8\u5b58\u50a8\u95f4\u7684\u6570\u636e\u8fc1\u79fb\u5f00\u9500\uff1b\u5982\u4f55\u5728CXL\u67b6\u6784\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u4e0e\u5185\u5b58\u7684\u534f\u540c\u6269\u5c55\u3002", "contributions": "\u63d0\u51fa\u4e86\u5c06Token\u9875\u9762\u9009\u62e9\u5378\u8f7d\u5230CXL\u5185\u5b58\u4e2dPNM\u52a0\u901f\u5668\u7684\u65b0\u67b6\u6784\uff1b\u8bbe\u8ba1\u4e86PNM-only\uff08PNM-KV\uff09\u548cGPU-PNM\u6df7\u5408\uff08PnG-KV\uff09\u4e24\u79cd\u65b9\u6848\uff1b\u5f15\u5165\u6df7\u5408\u5e76\u884c\u7b56\u7565\u4e0e\u7a33\u6001Token\u9009\u62e9\u673a\u5236\u4ee5\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "results": "\u5728\u9ad8\u8fbe405B\u53c2\u6570\u30011M-Token\u4e0a\u4e0b\u6587\u7684LLM\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad821.9\u500d\u7684\u541e\u5410\u63d0\u5347\uff0c\u5355\u4f4dToken\u80fd\u8017\u964d\u4f4e60\u500d\uff0c\u603b\u6210\u672c\u6548\u7387\u63d0\u53477.3\u500d\u3002", "conclusion": "CXL\u652f\u6301\u7684\u591aPNM\u67b6\u6784\u53ef\u4f5c\u4e3a\u672a\u6765\u957f\u4e0a\u4e0b\u6587\u5927\u6a21\u578b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u57fa\u7840\uff0c\u6709\u6548\u7a81\u7834GPU\u5185\u5b58\u4e0e\u8ba1\u7b97\u9650\u5236\u3002", "related_work": "\u57fa\u4e8eCXL\u7684\u975e\u9010\u51fa\u5f0fKV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff1b\u8fd1\u5185\u5b58\u8ba1\u7b97\u5728AI\u52a0\u901f\u4e2d\u7684\u5e94\u7528\uff1b\u5927\u6a21\u578b\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\u538b\u7f29\u4e0e\u5206\u9875\u6280\u672f\u3002"}}
{"id": "2511.00271", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00271", "abs": "https://arxiv.org/abs/2511.00271", "authors": ["Saadat Izadi", "Shakib Komasi", "Ali Salimi", "Alireza Rezaei", "Mahmood Ahmadi"], "title": "Mist-Assisted Federated Learning for Intrusion Detection in Heterogeneous IoT Networks", "comment": null, "summary": "The rapid growth of the Internet of Things (IoT) offers new opportunities but\nalso expands the attack surface of distributed, resource-limited devices.\nIntrusion detection in such environments is difficult due to data heterogeneity\nfrom diverse sensing modalities and the non-IID distribution of samples across\nclients. Federated Learning (FL) provides a privacy-preserving alternative to\ncentralized training, yet conventional frameworks struggle under these\nconditions. To address this, we propose a Mist-assisted hierarchical framework\nfor IoT intrusion detection. The architecture spans four layers: (i) Mist,\nwhere raw data are abstracted into a unified feature space and lightweight\nmodels detect anomalies; (ii) Edge, which applies utility-based client\nselection; (iii) Fog, where multiple regional aggregators use FedProx to\nstabilize training; and (iv) Cloud, which consolidates and disseminates global\nmodels. Evaluations on the TON-IoT dataset show the framework achieves 98-99%\naccuracy, PR-AUC> 0.97, and stable convergence under heterogeneous and\nlarge-scale settings, while maintaining efficiency and preserving privacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96fe\u8f85\u52a9\u7684\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\uff0c\u80fd\u591f\u5728\u6570\u636e\u5f02\u6784\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5feb\u901f\u589e\u957f\u6269\u5927\u4e86\u653b\u51fb\u9762\uff0c\u4e14\u8bbe\u5907\u5206\u5e03\u5e7f\u6cdb\u3001\u8d44\u6e90\u53d7\u9650\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5165\u4fb5\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u5206\u5e03\u5f0f\u3001\u9690\u79c1\u5b89\u5168\u7684\u68c0\u6d4b\u673a\u5236\u3002", "challenges": "\u7269\u8054\u7f51\u73af\u5883\u4e2d\u6570\u636e\u6765\u6e90\u591a\u6837\u5bfc\u81f4\u6570\u636e\u5f02\u6784\uff0c\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\uff0c\u4e14\u8bbe\u5907\u8d44\u6e90\u6709\u9650\uff0c\u5bf9\u6a21\u578b\u6548\u7387\u548c\u901a\u4fe1\u5f00\u9500\u63d0\u51fa\u4e86\u6311\u6218\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56db\u5c42\u96fe\u8f85\u52a9\u5206\u5c42\u6846\u67b6\uff0c\u7ed3\u5408Mist\u5c42\u7279\u5f81\u7edf\u4e00\u4e0e\u8f7b\u91cf\u6a21\u578b\u3001\u8fb9\u7f18\u5c42\u5ba2\u6237\u7aef\u9009\u62e9\u3001\u96fe\u5c42FedProx\u805a\u5408\u548c\u4e91\u5c42\u5168\u5c40\u6a21\u578b\u6574\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5f02\u6784\u73af\u5883\u4e0b\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0e\u68c0\u6d4b\u6027\u80fd\u3002", "results": "\u5728TON-IoT\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5f02\u6784\u548c\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u4ecd\u80fd\u8fbe\u523098-99%\u7684\u51c6\u786e\u7387\uff0cPR-AUC\u8d85\u8fc70.97\uff0c\u5e76\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u6536\u655b\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u7269\u8054\u7f51\u73af\u5883\u4e2d\u6570\u636e\u5f02\u6784\u3001non-IID\u5206\u5e03\u548c\u8d44\u6e90\u9650\u5236\u7b49\u6311\u6218\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u5165\u4fb5\u68c0\u6d4b\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7269\u8054\u7f51\u90e8\u7f72\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u8054\u90a6\u5b66\u4e60\u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\u3001non-IID\u6570\u636e\u4e0b\u7684FedProx\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\uff08\u5982TON-IoT\uff09\u7684\u4f7f\u7528\u3002"}}
{"id": "2511.01001", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.01001", "abs": "https://arxiv.org/abs/2511.01001", "authors": ["Johansell Villalobos", "Daniel Caviedes-Voulli\u00e8me", "Silvio Rizzi", "Esteban Meneses"], "title": "Towards Portability at Scale: A Cross-Architecture Performance Evaluation of a GPU-enabled Shallow Water Solver", "comment": "Conference: SBAC-PAD 2025", "summary": "Current climate change has posed a grand challenge in the field of numerical\nmodeling due to its complex, multiscale dynamics. In hydrological modeling, the\nincreasing demand for high-resolution, real-time simulations has led to the\nadoption of GPU-accelerated platforms and performance portable programming\nframeworks such as Kokkos. In this work, we present a comprehensive performance\nstudy of the SERGHEI-SWE solver, a shallow water equations code, across four\nstate-of-the-art heterogeneous HPC systems: Frontier (AMD MI250X), JUWELS\nBooster (NVIDIA A100), JEDI (NVIDIA H100), and Aurora (Intel Max 1550). We\nassess strong scaling up to 1024 GPUs and weak scaling upwards of 2048 GPUs,\ndemonstrating consistent scalability with a speedup of 32 and an efficiency\nupwards of 90\\% for most almost all the test range. Roofline analysis reveals\nthat memory bandwidth is the dominant performance bottleneck, with key solver\nkernels residing in the memory-bound region. To evaluate performance\nportability, we apply both harmonic and arithmetic mean-based metrics while\nvarying problem size. Results indicate that while SERGHEI-SWE achieves\nportability across devices with tuned problem sizes (<70\\%), there is room for\nkernel optimization within the solver with more granular control of the\narchitecture specifically by using Kokkos teams and architecture specific\ntunable parameters. These findings position SERGHEI-SWE as a robust, scalable,\nand portable simulation tool for large-scale geophysical applications under\nevolving HPC architectures with potential to enhance its performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9SERGHEI-SWE\u6c42\u89e3\u5668\u5728\u56db\u79cd\u524d\u6cbf\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591aGPU\u73af\u5883\u4e0b\u7684\u826f\u597d\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u53ef\u79fb\u690d\u6027\uff0c\u540c\u65f6\u6307\u51fa\u5185\u5b58\u5e26\u5bbd\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u672a\u6765\u53ef\u901a\u8fc7Kokkos\u56e2\u961f\u548c\u67b6\u6784\u7279\u5b9a\u53c2\u6570\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u5e26\u6765\u7684\u590d\u6742\u591a\u5c3a\u5ea6\u52a8\u529b\u5b66\u6311\u6218\uff0c\u6c34\u6587\u6a21\u578b\u5bf9\u9ad8\u5206\u8fa8\u7387\u3001\u5b9e\u65f6\u6a21\u62df\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u63a8\u52a8\u4e86GPU\u52a0\u901f\u5e73\u53f0\u548c\u6027\u80fd\u53ef\u79fb\u690d\u7f16\u7a0b\u6846\u67b6\uff08\u5982Kokkos\uff09\u7684\u5e94\u7528\u3002", "challenges": "\u6c14\u5019\u7cfb\u7edf\u7684\u590d\u6742\u6027\u548c\u591a\u5c3a\u5ea6\u52a8\u6001\u7ed9\u6570\u503c\u5efa\u6a21\u5e26\u6765\u5de8\u5927\u6311\u6218\uff1b\u5728\u5f02\u6784HPC\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u79fb\u690d\u7684\u6c34\u6587\u6a21\u62df\u4ecd\u5b58\u5728\u6027\u80fd\u74f6\u9888\u548c\u4f18\u5316\u96be\u9898\u3002", "contributions": "1. \u5728\u56db\u7c7b\u5148\u8fdb\u5f02\u6784HPC\u7cfb\u7edf\u4e0a\u5bf9SERGHEI-SWE\u6c42\u89e3\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6027\u80fd\u7814\u7a76\uff1b2. \u8bc4\u4f30\u4e86\u5f3a\u6269\u5c55\u6027\u548c\u5f31\u6269\u5c55\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u8fbe2048\u4e2aGPU\u4e0a\u7684\u53ef\u6269\u5c55\u6027\uff1b3. \u901a\u8fc7Roofline\u5206\u6790\u8bc6\u522b\u51fa\u5185\u5b58\u5e26\u5bbd\u4e3a\u4e3b\u8981\u6027\u80fd\u74f6\u9888\uff1b4. \u4f7f\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u53ef\u79fb\u690d\u6027\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u65b9\u5411\u3002", "results": "SERGHEI-SWE\u5728\u6700\u591a1024\u4e2aGPU\u4e0a\u5b9e\u73b0\u4e8632\u500d\u52a0\u901f\u6bd4\uff0c\u5927\u591a\u6570\u6d4b\u8bd5\u8303\u56f4\u5185\u7684\u6269\u5c55\u6548\u7387\u8d85\u8fc790%\uff1b\u5f31\u6269\u5c55\u6027\u6d4b\u8bd5\u6269\u5c55\u81f32048\u4e2aGPU\u4ecd\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff1bRoofline\u5206\u6790\u663e\u793a\u5173\u952e\u6c42\u89e3\u5668\u5185\u6838\u5904\u4e8e\u5185\u5b58\u53d7\u9650\u533a\u57df\uff1b\u6027\u80fd\u53ef\u79fb\u690d\u6027\u5206\u6790\u8868\u660e\uff0c\u5728\u8c03\u6574\u95ee\u9898\u89c4\u6a21\u540e\u53ef\u5728\u4e0d\u540c\u8bbe\u5907\u95f4\u5b9e\u73b0\u8f83\u597d\u53ef\u79fb\u690d\u6027\uff08<70%\u5dee\u5f02\uff09\uff0c\u4f46\u4ecd\u6709\u4f18\u5316\u7a7a\u95f4\u3002", "conclusion": "SERGHEI-SWE\u662f\u4e00\u4e2a\u5728\u5f53\u524d\u5f02\u6784HPC\u67b6\u6784\u4e0b\u5177\u6709\u9ad8\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u79fb\u690d\u6027\u7684\u5927\u89c4\u6a21\u5730\u5b66\u7269\u7406\u6a21\u62df\u5de5\u5177\uff0c\u5177\u5907\u8fdb\u4e00\u6b65\u4f18\u5316\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5185\u5b58\u8bbf\u95ee\u548c\u67b6\u6784\u7279\u5b9a\u8c03\u4f18\u65b9\u9762\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u57fa\u4e8eGPU\u52a0\u901f\u7684\u6d45\u6c34\u65b9\u7a0b\u6c42\u89e3\u5668\u5f00\u53d1\u3001\u4f7f\u7528Kokkos\u7b49\u6027\u80fd\u53ef\u79fb\u690d\u6846\u67b6\u7684\u79d1\u5b66\u8ba1\u7b97\u5e94\u7528\u3001\u4ee5\u53ca\u5728Frontier\u3001JUWELS Booster\u7b49\u5927\u578b\u5f02\u6784\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\u5206\u6790\u7814\u7a76\u3002"}}
{"id": "2511.00276", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00276", "abs": "https://arxiv.org/abs/2511.00276", "authors": ["Mohammad Hadi Akbarzadeh", "Mahmood Ahmadi", "Mohammad Saeed Jahangiry", "Jae Young Hur"], "title": "Reinforcement Learning for Resource Allocation in Vehicular Multi-Fog Computing", "comment": null, "summary": "The exponential growth of Internet of Things (IoT) devices, smart vehicles,\nand latency-sensitive applications has created an urgent demand for efficient\ndistributed computing paradigms. Multi-Fog Computing (MFC), as an extension of\nfog and edge computing, deploys multiple fog nodes near end users to reduce\nlatency, enhance scalability, and ensure Quality of Service (QoS). However,\nresource allocation in MFC environments is highly challenging due to dynamic\nvehicular mobility, heterogeneous resources, and fluctuating workloads.\nTraditional optimization-based methods often fail to adapt to such dynamics.\nReinforcement Learning (RL), as a model-free decision-making framework, enables\nadaptive task allocation by continuously interacting with the environment. This\npaper formulates the resource allocation problem in MFC as a Markov Decision\nProcess (MDP) and investigates the application of RL algorithms such as\nQ-learning, Deep Q-Networks (DQN), and Actor-Critic. We present experimental\nresults demonstrating improvements in latency, workload balance, and task\nsuccess rate. The contributions and novelty of this study are also discussed,\nhighlighting the role of RL in addressing emerging vehicular computing\nchallenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e94\u7528Q-learning\u3001DQN\u548cActor-Critic\u7b49\u7b97\u6cd5\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u7531\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u3001\u667a\u80fd\u8f66\u8f86\u548c\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\u7684\u5feb\u901f\u589e\u957f\uff0c\u5bf9\u9ad8\u6548\u5206\u5e03\u5f0f\u8ba1\u7b97\u8303\u5f0f\u7684\u9700\u6c42\u65e5\u76ca\u8feb\u5207\uff0c\u800c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u591a\u96fe\u8ba1\u7b97\u4e2d\u52a8\u6001\u53d8\u5316\u7684\u8d44\u6e90\u9700\u6c42\u3002", "challenges": "\u591a\u96fe\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u9762\u4e34\u52a8\u6001\u8f66\u8f86\u79fb\u52a8\u6027\u3001\u5f02\u6784\u8d44\u6e90\u548c\u6ce2\u52a8\u5de5\u4f5c\u8d1f\u8f7d\u7b49\u6311\u6218\uff0c\u5bfc\u81f4\u4f20\u7edf\u65b9\u6cd5\u9002\u5e94\u80fd\u529b\u5dee\u3002", "contributions": "\u672c\u6587\u5c06\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u964d\u4f4e\u5ef6\u8fdf\u3001\u5e73\u8861\u8d1f\u8f7d\u548c\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7a81\u51fa\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u5e94\u5bf9 vehicular \u8ba1\u7b97\u6311\u6218\u4e2d\u7684\u6f5c\u529b\u3002", "results": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528Q-learning\u3001Deep Q-Networks\u548cActor-Critic\u7b49\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u663e\u8457\u6539\u5584\u4e86\u5ef6\u8fdf\u3001\u5de5\u4f5c\u8d1f\u8f7d\u5747\u8861\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u8fbe\u5230\u9884\u671f\u76ee\u6807\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u591a\u96fe\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u81ea\u9002\u5e94\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u96fe/\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u7ba1\u7406\u548c\u4f18\u5316\uff0c\u4ee5\u53ca\u4f7f\u7528\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u4efb\u52a1\u8c03\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2511.01235", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01235", "abs": "https://arxiv.org/abs/2511.01235", "authors": ["Shruthi Kannappan", "Ashwina Kumar", "Rupesh Nasre"], "title": "Scalable Maxflow Processing for Dynamic Graphs", "comment": null, "summary": "The Maximum Flow (Max-Flow) problem is a cornerstone in graph theory and\ncombinatorial optimization, aiming to determine the largest possible flow from\na designated source node to a sink node within a capacitated flow network. It\nhas extensive applications across diverse domains such as computer networking,\ntransportation systems, and image segmentation. The objective is to maximize\nthe total throughput while respecting edge capacity constraints and maintaining\nflow conservation at all intermediate vertices.\n  Among the various algorithms proposed for solving the Max-Flow problem, the\nPush--Relabel algorithm is particularly notable for its efficiency and\nsuitability for parallelization, owing to its localized vertex-based\noperations. This property has motivated extensive research into GPU-accelerated\nMax-Flow computation, leveraging the high degree of parallelism inherent to\nmodern GPU architectures.\n  In this paper, we present a novel GPU-parallel Max-Flow algorithm capable of\nincrementally recomputing the maximum flow of a dynamic graph following a batch\nof edge updates. In addition, we introduce a high-performance static GPU\nalgorithm designed for efficiently computing the initial Max-Flow on static\ngraphs. We further describe a series of CUDA-specific implementation\noptimizations that enhance performance, scalability, and memory efficiency on\nGPU platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GPU\u5e76\u884c\u6700\u5927\u6d41\u7b97\u6cd5\uff0c\u80fd\u591f\u5bf9\u52a8\u6001\u56fe\u5728\u6279\u91cf\u8fb9\u66f4\u65b0\u540e\u589e\u91cf\u5730\u91cd\u65b0\u8ba1\u7b97\u6700\u5927\u6d41\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u9759\u6001\u56fe\u521d\u59cb\u6700\u5927\u6d41\u8ba1\u7b97\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u9488\u5bf9CUDA\u7684\u4f18\u5316\u6280\u672f\u4ee5\u63d0\u5347GPU\u5e73\u53f0\u4e0a\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u7531\u4e8e\u6700\u5927\u6d41\u95ee\u9898\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4e14\u56fe\u7ed3\u6784\u5e38\u52a8\u6001\u53d8\u5316\uff0c\u9700\u8981\u9ad8\u6548\u5730\u5904\u7406\u52a8\u6001\u56fe\u7684\u6700\u5927\u6d41\u95ee\u9898\u3002\u73b0\u6709\u7684GPU\u5e76\u884c\u7b97\u6cd5\u591a\u96c6\u4e2d\u4e8e\u9759\u6001\u56fe\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u66f4\u65b0\u7684\u6709\u6548\u652f\u6301\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u9ad8\u6548\u5904\u7406\u8fb9\u6279\u91cf\u66f4\u65b0\u7684\u589e\u91cf\u5f0fGPU\u7b97\u6cd5\u3002", "challenges": "\u4e3b\u8981\u6311\u6218\u5305\u62ec\u5982\u4f55\u5728GPU\u4e0a\u9ad8\u6548\u5b9e\u73b0\u589e\u91cf\u5f0f\u6700\u5927\u6d41\u8ba1\u7b97\uff0c\u5982\u4f55\u5904\u7406\u52a8\u6001\u56fe\u4e2d\u7684\u6279\u91cf\u8fb9\u66f4\u65b0\uff0c\u4ee5\u53ca\u5982\u4f55\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u548c\u7ebf\u7a0b\u8c03\u5ea6\u4ee5\u63d0\u5347\u5e76\u884c\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "contributions": "\u672c\u6587\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a1\uff09\u63d0\u51fa\u4e00\u79cd\u65b0\u7684GPU\u5e76\u884c\u589e\u91cf\u6700\u5927\u6d41\u7b97\u6cd5\uff0c\u652f\u6301\u52a8\u6001\u56fe\u7684\u6279\u91cf\u8fb9\u66f4\u65b0\uff1b2\uff09\u8bbe\u8ba1\u9ad8\u6548\u7684\u9759\u6001\u56fe\u6700\u5927\u6d41GPU\u7b97\u6cd5\uff1b3\uff09\u5b9e\u73b0\u4e00\u7cfb\u5217CUDA\u7279\u5b9a\u4f18\u5316\uff0c\u63d0\u5347\u6027\u80fd\u548c\u5185\u5b58\u6548\u7387\u3002", "results": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u79cd\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u548c\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5c24\u5176\u5728\u5904\u7406\u52a8\u6001\u66f4\u65b0\u65f6\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u589e\u91cf\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684GPU\u5e76\u884c\u7b56\u7565\u548cCUDA\u4f18\u5316\uff0c\u53ef\u4ee5\u9ad8\u6548\u89e3\u51b3\u9759\u6001\u548c\u52a8\u6001\u56fe\u7684\u6700\u5927\u6d41\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u6570\u636e\u7684\u5b9e\u65f6\u6d41\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u5305\u62ec\u7ecf\u5178\u7684Push-Relabel\u7b97\u6cd5\u3001\u5176\u4ed6GPU\u52a0\u901f\u7684\u6700\u5927\u6d41\u7b97\u6cd5\u4ee5\u53ca\u52a8\u6001\u56fe\u4e0a\u7684\u589e\u91cf\u56fe\u7b97\u6cd5\uff0c\u672c\u6587\u5728\u8fd9\u4e9b\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86GPU\u4e0a\u7684\u589e\u91cf\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2511.00502", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00502", "abs": "https://arxiv.org/abs/2511.00502", "authors": ["Peng Zhang", "Vitaly Petrov", "Emil Bj\u00f6rnson"], "title": "Impact of Antenna Arrays Misalignment on the Near Field Distance in Terahertz Communications", "comment": "Accepted to IEEE Globecom, 2025. Copyright 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses, in any current or future media, including reprinting/republishing\n  this material, creating new works, for resale or redistribution to servers or\n  lists, or reuse of any copyrighted component of this work in other works", "summary": "The extremely short wavelength of terahertz (THz) communications leads to an\nextended radiative near-field region, in which some canonical far-field\nassumptions fail. Existing near-field boundary formulations (Fraunhofer\ndistance) for uniform linear/planar array (ULA/UPA) configurations assume ideal\nalignment between transceivers, overlooking practical misalignments caused by\nmobility or mechanical imperfections. This paper addresses this critical gap by\nanalyzing the impact of spatial misalignment on near-field distance\ncalculations in THz systems. We derive exact analytical expressions and\nsimplified approximations for the near-field boundary in both ULA--ULA and\nUPA--UPA configurations under arbitrary misalignment offsets. Through numerical\nsimulations, we validate our theoretical models and quantify how misalignment\nreshapes the near-field region. These findings provide essential guidelines for\noptimizing THz system deployment in realistic scenarios.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u7531\u4e8e\u7a7a\u95f4\u9519\u4f4d\u5bf9\u8fd1\u573a\u8ddd\u79bb\u8ba1\u7b97\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u4e86\u5728\u4efb\u610f\u9519\u4f4d\u60c5\u51b5\u4e0bULA\u548cUPA\u914d\u7f6e\u4e0b\u7684\u8fd1\u573a\u8fb9\u754c\u7cbe\u786e\u8868\u8fbe\u5f0f\u4e0e\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u592a\u8d6b\u5179\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002", "motivation": "\u7531\u4e8e\u592a\u8d6b\u5179\u901a\u4fe1\u6ce2\u957f\u6781\u77ed\uff0c\u5176\u8f90\u5c04\u8fd1\u573a\u533a\u57df\u663e\u8457\u6269\u5c55\uff0c\u4f20\u7edf\u57fa\u4e8e\u7406\u60f3\u5bf9\u9f50\u5047\u8bbe\u7684\u8fdc\u573a\u6761\u4ef6\uff08\u5982\u592b\u7405\u79be\u8d39\u8ddd\u79bb\uff09\u4e0d\u518d\u9002\u7528\uff0c\u5b9e\u9645\u4e2d\u7531\u79fb\u52a8\u6027\u6216\u673a\u68b0\u8bef\u5dee\u5f15\u8d77\u7684\u6536\u53d1\u5668\u9519\u4f4d\u95ee\u9898\u4e9f\u9700\u89e3\u51b3\u3002", "challenges": "\u73b0\u6709\u8fd1\u573a\u8fb9\u754c\u516c\u5f0f\u5047\u8bbe\u6536\u53d1\u5668\u5b8c\u5168\u5bf9\u9f50\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7a7a\u95f4\u9519\u4f4d\u5f71\u54cd\uff0c\u5bfc\u81f4\u8fd1\u573a\u533a\u57df\u4f30\u8ba1\u4e0d\u51c6\u786e\uff0c\u5f71\u54cd\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u6027\u80fd\u3002", "contributions": "1. \u63a8\u5bfc\u4e86\u5728\u4efb\u610f\u7a7a\u95f4\u9519\u4f4d\u4e0bULA-ULA\u548cUPA-UPA\u914d\u7f6e\u7684\u8fd1\u573a\u8fb9\u754c\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\uff1b2. \u63d0\u51fa\u4e86\u7b80\u5316\u7684\u8fd1\u4f3c\u516c\u5f0f\uff1b3. \u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\uff0c\u5e76\u91cf\u5316\u4e86\u9519\u4f4d\u5bf9\u8fd1\u573a\u533a\u57df\u7684\u5f71\u54cd\u3002", "results": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u7a7a\u95f4\u9519\u4f4d\u4f1a\u663e\u8457\u6539\u53d8\u8fd1\u573a\u8fb9\u754c\uff0c\u9519\u4f4d\u8d8a\u5927\uff0c\u8fd1\u573a\u533a\u57df\u6269\u5c55\u8d8a\u660e\u663e\uff0c\u4f20\u7edf\u516c\u5f0f\u5728\u9519\u4f4d\u5b58\u5728\u65f6\u4f1a\u4ea7\u751f\u8f83\u5927\u8bef\u5dee\u3002", "conclusion": "\u8003\u8651\u7a7a\u95f4\u9519\u4f4d\u7684\u8fd1\u573a\u6a21\u578b\u66f4\u7b26\u5408\u5b9e\u9645\u573a\u666f\uff0c\u5bf9\u592a\u8d6b\u5179\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u4f18\u5316\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5efa\u8bae\u5728\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5f15\u5165\u9519\u4f4d\u611f\u77e5\u7684\u8fd1\u573a\u5efa\u6a21\u65b9\u6cd5\u3002", "related_work": "\u5df2\u6709\u7814\u7a76\u4e3b\u8981\u57fa\u4e8e\u7406\u60f3\u5bf9\u9f50\u5047\u8bbe\u5b9a\u4e49\u8fd1\u573a\u8fb9\u754c\uff08\u5982Fraunhofer\u8ddd\u79bb\uff09\uff0c\u672a\u5145\u5206\u8003\u8651\u5b9e\u9645\u9519\u4f4d\u5f71\u54cd\uff0c\u672c\u6587\u5728\u6b64\u57fa\u7840\u4e0a\u6269\u5c55\u4e86\u66f4\u901a\u7528\u7684\u975e\u5bf9\u9f50\u573a\u666f\u6a21\u578b\u3002"}}
{"id": "2511.01255", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01255", "abs": "https://arxiv.org/abs/2511.01255", "authors": ["He Chen", "ZiHua Zheng", "JingHua Sun"], "title": "Design of quasi phase matching crystal based on differential gray wolf algorithm", "comment": null, "summary": "This paper focuses on the key problem in the development of nonlinear optical\ntechnology, the performance optimization of aperiodically polarized crystals.\nThe performance of the crystal depends on the precise control of the micro\ndistribution of crystal domains, but its optimization belongs to the\nhigh-dimensional discrete combination \"NP hard\" problem. The traditional\nalgorithm has the bottleneck of slow convergence and easy to fall into local\noptimization, while the heuristic methods such as genetic algorithm are limited\nby the CPU serial calculation and inefficient. In order to solve the above\nchallenges, this paper proposes the fusion scheme of hwsda hybrid optimization\nalgorithm and GPU parallel acceleration technology: the differential evolution\nalgorithm (DE) is used to realize the global search, and the gray wolf\noptimization algorithm (GWO) is used to strengthen the local search and\nconvergence speed, and the two coordinate to balance the global and local\noptimization requirements; At the same time, it relies on GPU multi-core\narchitecture to realize thread level parallel computing and improve\noptimization efficiency. This scheme effectively breaks through the\noptimization problem of high-dimensional discrete space, improves the accuracy\nof crystal domain control, improves the efficiency of quasi phase matching\ndesign by hundreds to thousands of times compared with traditional CPU serial\ncomputing, provides a new paradigm for the design of complex nonlinear optical\ndevices, and helps promote the performance breakthrough and industrial\napplication of related devices in the fields of quantum optics and laser\nprocessing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408hwsda\u6df7\u5408\u4f18\u5316\u7b97\u6cd5\u548cGPU\u5e76\u884c\u52a0\u901f\u6280\u672f\u7684\u65b0\u65b9\u6848\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u5468\u671f\u6781\u5316\u6676\u4f53\u6027\u80fd\u4f18\u5316\u4e2d\u7684\u9ad8\u7ef4\u79bb\u6563\u7ec4\u5408\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f18\u5316\u6548\u7387\u548c\u6676\u4f53\u6027\u80fd\u63a7\u5236\u7cbe\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u7a81\u7834\u4f20\u7edf\u7b97\u6cd5\u5728\u975e\u5468\u671f\u6781\u5316\u6676\u4f53\u4f18\u5316\u4e2d\u6536\u655b\u6162\u3001\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u4ee5\u53caCPU\u4e32\u884c\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "challenges": "\u6676\u4f53\u6027\u80fd\u4f18\u5316\u5c5e\u4e8e\u9ad8\u7ef4\u79bb\u6563\u7ec4\u5408\u7684NP\u96be\u95ee\u9898\uff0c\u4f20\u7edf\u7b97\u6cd5\u6536\u655b\u6162\u4e14\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u542f\u53d1\u5f0f\u7b97\u6cd5\u53d7\u9650\u4e8eCPU\u4e32\u884c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002", "contributions": "\u63d0\u51fa\u4e86DE\u4e0eGWO\u878d\u5408\u7684\u6df7\u5408\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408GPU\u5e76\u884c\u8ba1\u7b97\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u4e0e\u5c40\u90e8\u641c\u7d22\u7684\u5e73\u8861\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f18\u5316\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "results": "\u76f8\u6bd4\u4f20\u7edfCPU\u4e32\u884c\u8ba1\u7b97\uff0c\u51c6\u76f8\u4f4d\u5339\u914d\u8bbe\u8ba1\u6548\u7387\u63d0\u5347\u4e86\u6570\u767e\u81f3\u6570\u5343\u500d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u79bb\u6563\u7a7a\u95f4\u4f18\u5316\u96be\u9898\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u590d\u6742\u975e\u7ebf\u6027\u5149\u5b66\u5668\u4ef6\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u91cf\u5b50\u5149\u5b66\u548c\u6fc0\u5149\u52a0\u5de5\u7b49\u9886\u57df\u5668\u4ef6\u7684\u6027\u80fd\u7a81\u7834\u548c\u4ea7\u4e1a\u5316\u5e94\u7528\u3002", "related_work": "\u4f20\u7edf\u4f18\u5316\u7b97\u6cd5\u5982\u9057\u4f20\u7b97\u6cd5\u5728\u6676\u4f53\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u672c\u6587\u63d0\u51fa\u7684\u6df7\u5408\u7b97\u6cd5\u7ed3\u5408GPU\u52a0\u901f\u663e\u8457\u8d85\u8d8a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u3002"}}
{"id": "2511.00767", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00767", "abs": "https://arxiv.org/abs/2511.00767", "authors": ["Shi Gengtian", "Takashi Koshimizu", "Megumi Saito", "Pan Zhenni", "Liu Jiang", "Shigeru Shimamoto"], "title": "Power Control Based on Multi-Agent Deep Q Network for D2D Communication", "comment": "Published in IEEE ICAIIC 2020. This is the preprint version of the\n  paper", "summary": "In device-to-device (D2D) communication under a cell with resource sharing\nmode the spectrum resource utilization of the system will be improved. However,\nif the interference generated by the D2D user is not controlled, the\nperformance of the entire system and the quality of service (QOS) of the\ncellular user may be degraded. Power control is important because it helps to\nreduce interference in the system. In this paper, we propose a reinforcement\nlearning algorithm for adaptive power control that helps reduce interference to\nincrease system throughput. Simulation results show the proposed algorithm has\nbetter performance than traditional algorithm in LTE (Long Term Evolution).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u529f\u7387\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347D2D\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u9891\u8c31\u8d44\u6e90\u5229\u7528\u7387\u5e76\u51cf\u5c11\u5bf9\u8702\u7a9d\u7528\u6237\u7684\u5e72\u6270\uff0c\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u7cfb\u7edf\u541e\u5410\u91cf\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfLTE\u7b97\u6cd5\u3002", "motivation": "\u5728D2D\u901a\u4fe1\u4e2d\uff0c\u82e5\u4e0d\u63a7\u5236D2D\u7528\u6237\u4ea7\u751f\u7684\u5e72\u6270\uff0c\u4f1a\u964d\u4f4e\u8702\u7a9d\u7528\u6237\u7684\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u529f\u7387\u63a7\u5236\u673a\u5236\u6765\u5e73\u8861\u8d44\u6e90\u5229\u7528\u4e0e\u5e72\u6270\u7ba1\u7406\u3002", "challenges": "\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u5982\u4f55\u5728\u63d0\u5347\u7cfb\u7edf\u9891\u8c31\u5229\u7528\u7387\u7684\u540c\u65f6\uff0c\u6709\u6548\u63a7\u5236D2D\u7528\u6237\u5bf9\u8702\u7a9d\u7528\u6237\u7684\u5e72\u6270\uff0c\u786e\u4fdd\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u548cQoS\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u529f\u7387\u63a7\u5236\u7b97\u6cd5\uff0c\u80fd\u591f\u52a8\u6001\u8c03\u6574\u53d1\u5c04\u529f\u7387\u4ee5\u51cf\u5c11\u5e72\u6270\uff0c\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "results": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7cfb\u7edf\u541e\u5410\u91cf\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684LTE\u529f\u7387\u63a7\u5236\u7b97\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5e72\u6270\u7ba1\u7406\u548c\u8d44\u6e90\u5229\u7528\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0D2D\u901a\u4fe1\u4e2d\u7684\u81ea\u9002\u5e94\u529f\u7387\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u5177\u6709\u5728\u5b9e\u9645LTE\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u6f5c\u529b\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728D2D\u901a\u4fe1\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u4e0e\u529f\u7387\u63a7\u5236\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u7684\u5e72\u6270\u7ba1\u7406\u673a\u5236\uff0c\u800c\u672c\u6587\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u548c\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u63a7\u5236\u3002"}}
{"id": "2511.01573", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01573", "abs": "https://arxiv.org/abs/2511.01573", "authors": ["Melanie Tonarelli", "Simone Riva", "Pietro Benedusi", "Fabrizio Ferrandi", "Rolf Krause"], "title": "Adaptive Multidimensional Quadrature on Multi-GPU Systems", "comment": "9 pages, 8 figures. Submitted to the proceedings of the 29th\n  International Conference on Domain Decomposition Methods (DD29)", "summary": "We introduce a distributed adaptive quadrature method that formulates\nmultidimensional integration as a hierarchical domain decomposition problem on\nmulti-GPU architectures. The integration domain is recursively partitioned into\nsubdomains whose refinement is guided by local error estimators. Each subdomain\nevolves independently on a GPU, which exposes a significant load imbalance as\nthe adaptive process progresses. To address this challenge, we introduce a\ndecentralised load redistribution schemes based on a cyclic round-robin policy.\nThis strategy dynamically rebalance subdomains across devices through\nnon-blocking, CUDA-aware MPI communication that overlaps with computation. The\nproposed strategy has two main advantages compared to a state-of-the-art\nGPU-tailored package: higher efficiency in high dimensions; and improved\nrobustness w.r.t the integrand regularity and the target accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591aGPU\u67b6\u6784\u7684\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u6570\u503c\u79ef\u5206\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u57df\u5206\u89e3\u548c\u52a8\u6001\u8d1f\u8f7d\u91cd\u5206\u914d\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u9ad8\u7ef4\u79ef\u5206\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u591aGPU\u67b6\u6784\u4e0a\u9ad8\u6548\u6c42\u89e3\u9ad8\u7ef4\u81ea\u9002\u5e94\u6570\u503c\u79ef\u5206\u95ee\u9898\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u7ef4\u548c\u4e0d\u89c4\u5219\u88ab\u79ef\u51fd\u6570\u4e0b\u7684\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3002", "challenges": "\u81ea\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5b50\u57df\u5212\u5206\u5bfc\u81f4\u4e25\u91cd\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\uff1b\u591aGPU\u95f4\u901a\u4fe1\u4e0e\u8ba1\u7b97\u7684\u534f\u8c03\u56f0\u96be\uff1b\u9ad8\u7ef4\u79ef\u5206\u4e2d\u8bef\u5dee\u4f30\u8ba1\u4e0e\u6536\u655b\u6548\u7387\u4f4e\u4e0b\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u5316\u57df\u5206\u89e3\u7684\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u79ef\u5206\u65b9\u6cd5\uff1b\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5faa\u73af\u8f6e\u8be2\u7684\u53bb\u4e2d\u5fc3\u5316\u8d1f\u8f7d\u91cd\u5206\u914d\u673a\u5236\uff1b\u5b9e\u73b0\u4e86\u975e\u963b\u585e\u3001CUDA-aware MPI\u901a\u4fe1\u4ee5\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\u3002", "results": "\u76f8\u6bd4\u73b0\u6709GPU\u4f18\u5316\u79ef\u5206\u5305\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u6548\u7387\u66f4\u9ad8\uff0c\u5bf9\u88ab\u79ef\u51fd\u6570\u7684\u6b63\u5219\u6027\u548c\u76ee\u6807\u7cbe\u5ea6\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591aGPU\u73af\u5883\u4e0b\u81ea\u9002\u5e94\u79ef\u5206\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u7ef4\u6570\u503c\u79ef\u5206\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "related_work": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u5355GPU\u6216CPU\u4e0a\u7684\u81ea\u9002\u5e94\u79ef\u5206\uff0c\u7f3a\u4e4f\u5bf9\u591aGPU\u95f4\u52a8\u6001\u8d1f\u8f7d\u5e73\u8861\u7684\u6709\u6548\u652f\u6301\uff0c\u4e14\u5728\u9ad8\u7ef4\u573a\u666f\u4e0b\u6027\u80fd\u53d7\u9650\u3002"}}
{"id": "2511.01843", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.01843", "abs": "https://arxiv.org/abs/2511.01843", "authors": ["Andrew Goodng", "Kevin Porter", "Thomas Lopatic", "Ashish Shinde", "Sunil Sayyaparaju", "Srinivasan Seshadri", "V. Srinivasan"], "title": "LARK -- Linearizability Algorithms for Replicated Keys in Aerospike", "comment": "Submitted to Industry Track of a Database Conference", "summary": "We present LARK (Linearizability Algorithms for Replicated Keys), a\nsynchronous replication protocol that achieves linearizability while minimizing\nlatency and infrastructure cost, at significantly higher availability than\ntraditional quorum-log consensus. LARK introduces Partition Availability\nConditions (PAC) that reason over the entire database cluster rather than fixed\nreplica sets, improving partition availability under independent failures by\nroughly 3x when tolerating one failure and 10x when tolerating two. Unlike\nRaft, Paxos, and Viewstamped Replication, LARK eliminates ordered logs,\nenabling immediate partition readiness after leader changes -- with at most a\nper-key duplicate-resolution round trip when the new leader lacks the latest\ncopy. Under equal storage budgets -- where both systems maintain only f+1 data\ncopies to tolerate f failures -- LARK continues committing through data-node\nfailures while log-based protocols must pause commits for replica rebuilding.\nThese properties also enable zero-downtime rolling restarts even when\nmaintaining only two copies. We provide formal safety arguments and a TLA+\nspecification, and we demonstrate through analysis and experiments that LARK\nachieves significant availability gains.", "AI": {"tldr": "LARK\u662f\u4e00\u79cd\u540c\u6b65\u590d\u5236\u534f\u8bae\uff0c\u901a\u8fc7\u5f15\u5165\u5206\u533a\u53ef\u7528\u6027\u6761\u4ef6\uff08PAC\uff09\u5728\u4fdd\u8bc1\u7ebf\u6027\u4e00\u81f4\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u5e76\u5728\u72ec\u7acb\u6545\u969c\u4e0b\u6bd4\u4f20\u7edf\u57fa\u4e8e\u65e5\u5fd7\u7684\u5171\u8bc6\u534f\u8bae\uff08\u5982Raft\u3001Paxos\uff09\u63d0\u4f9b\u66f4\u9ad8\u7684\u53ef\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u5171\u8bc6\u534f\u8bae\uff08\u5982Raft\u3001Paxos\uff09\u4f9d\u8d56\u6709\u5e8f\u65e5\u5fd7\u548c\u56fa\u5b9a\u526f\u672c\u96c6\uff0c\u5728\u8282\u70b9\u6545\u969c\u65f6\u9700\u6682\u505c\u63d0\u4ea4\u4ee5\u91cd\u5efa\u526f\u672c\uff0c\u5bfc\u81f4\u53ef\u7528\u6027\u964d\u4f4e\uff1bLARK\u65e8\u5728\u6d88\u9664\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u5347\u7cfb\u7edf\u5728\u6545\u969c\u671f\u95f4\u7684\u6301\u7eed\u63d0\u4ea4\u80fd\u529b\u548c\u6062\u590d\u6548\u7387\u3002", "challenges": "\u5982\u4f55\u5728\u4e0d\u727a\u7272\u5b89\u5168\u6027\u7684\u60c5\u51b5\u4e0b\u6d88\u9664\u6709\u5e8f\u65e5\u5fd7\u3001\u5b9e\u73b0\u9ad8\u53ef\u7528\u6027\uff1b\u5982\u4f55\u5728\u4ec5\u7ef4\u62a4f+1\u4e2a\u526f\u672c\u7684\u60c5\u51b5\u4e0b\u5bb9\u5fcdf\u4e2a\u6545\u969c\u5e76\u7ee7\u7eed\u63d0\u4ea4\uff1b\u5982\u4f55\u786e\u4fdd\u5206\u533a\u5728\u9886\u5bfc\u8005\u53d8\u66f4\u540e\u7acb\u5373\u5c31\u7eea\u3002", "contributions": "\u63d0\u51faLARK\u534f\u8bae\uff0c\u5f15\u5165\u57fa\u4e8e\u5168\u5c40\u96c6\u7fa4\u72b6\u6001\u7684\u5206\u533a\u53ef\u7528\u6027\u6761\u4ef6\uff08PAC\uff09\uff1b\u6d88\u9664\u6709\u5e8f\u65e5\u5fd7\uff0c\u5b9e\u73b0\u9886\u5bfc\u8005\u53d8\u66f4\u540e\u7684\u5373\u65f6\u5206\u533a\u5c31\u7eea\uff1b\u652f\u6301\u5728f+1\u526f\u672c\u914d\u7f6e\u4e0b\u6301\u7eed\u63d0\u4ea4\uff0c\u4f18\u4e8e\u4f20\u7edf\u534f\u8bae\u7684\u505c\u5199\u91cd\u5efa\u673a\u5236\uff1b\u5b9e\u73b0\u96f6\u505c\u673a\u6eda\u52a8\u91cd\u542f\u3002", "results": "\u5728\u5bb9\u5fcd1\u4e2a\u548c2\u4e2a\u6545\u969c\u65f6\uff0cLARK\u7684\u5206\u533a\u53ef\u7528\u6027\u5206\u522b\u63d0\u5347\u7ea63\u500d\u548c10\u500d\uff1b\u5b9e\u9a8c\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8868\u660e\u5176\u5728\u76f8\u540c\u5b58\u50a8\u9884\u7b97\u4e0b\u663e\u8457\u4f18\u4e8eRaft\u7b49\u534f\u8bae\uff0c\u652f\u6301\u6545\u969c\u671f\u95f4\u6301\u7eed\u63d0\u4ea4\u548c\u5feb\u901f\u6062\u590d\u3002", "conclusion": "LARK\u901a\u8fc7\u521b\u65b0\u7684PAC\u673a\u5236\u548c\u65e0\u65e5\u5fd7\u8bbe\u8ba1\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u548c\u7ebf\u6027\u4e00\u81f4\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u5236\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u3001\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u8fd0\u7ef4\u6210\u672c\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u53ef\u7528\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\u7684\u573a\u666f\u3002", "related_work": "Raft\u3001Paxos\u3001Viewstamped Replication\u7b49\u57fa\u4e8e\u65e5\u5fd7\u7684\u5171\u8bc6\u534f\u8bae\uff0c\u4ee5\u53ca\u4f20\u7edf\u7684\u591a\u6570\u6d3e\uff08quorum\uff09\u673a\u5236\u3002"}}
{"id": "2511.01373", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01373", "abs": "https://arxiv.org/abs/2511.01373", "authors": ["Kaining Wang", "Bo Yang", "Yusheng Lei", "Zhiwen Yu", "Xuelin Cao", "Liang Wang", "Bin Guo", "George C. Alexandropoulos", "M\u00e9rouane Debbah", "Zhu Han"], "title": "3D Gaussian Radiation Field Modeling for Integrated RIS-FAS Systems: Analysis and Optimization", "comment": null, "summary": "The integration of reconfigurable intelligent surfaces (RIS) and fluid\nantenna systems (FAS) has attracted considerable attention due to its\ntremendous potential in enhancing wireless communication performance. However,\nunder fast-fading channel conditions, rapidly and effectively performing joint\noptimization of the antenna positions in an FAS system and the RIS phase\nconfiguration remains a critical challenge. Traditional optimization methods\ntypically rely on complex iterative computations, thus making it challenging to\nobtain optimal solutions in real time within dynamic channel environments. To\naddress this issue, this paper introduces a field information-driven\noptimization method based on three-dimensional Gaussian radiation-field\nmodeling for real-time optimization of integrated FAS-RIS systems. In the\nproposed approach, obstacles are treated as virtual transmitters and, by\nseparately learning the amplitude and phase variations, the model can quickly\ngenerate high-precision channel information based on the transmitter's\nposition. This design eliminates the need for extensive pilot overhead and\ncumbersome computations. On this framework, an alternating optimization scheme\nis presented to jointly optimize the FAS position and the RIS phase\nconfiguration. Simulation results demonstrate that the proposed method\nsignificantly outperforms existing approaches in terms of spectrum prediction\naccuracy, convergence speed, and minimum achievable rate, validating its\neffectiveness and practicality in fast-fading scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u7684\u573a\u4fe1\u606f\u9a71\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u8870\u843d\u4fe1\u9053\u4e0b\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\uff08FAS\uff09\u4e0e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u8054\u5408\u5b9e\u65f6\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u4f4e\u53ef\u8fbe\u901f\u7387\u3002", "motivation": "\u5728\u5feb\u901f\u8870\u843d\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b9e\u65f6\u9ad8\u6548\u5730\u8054\u5408\u4f18\u5316FAS\u7684\u5929\u7ebf\u4f4d\u7f6e\u548cRIS\u7684\u76f8\u4f4d\u914d\u7f6e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4f4e\u5f00\u9500\u3001\u9ad8\u7cbe\u5ea6\u7684\u5b9e\u65f6\u4f18\u5316\u65b9\u6848\u3002", "challenges": "\u5feb\u901f\u8870\u843d\u4fe1\u9053\u4e0b\u4fe1\u9053\u72b6\u6001\u53d8\u5316\u5267\u70c8\uff0c\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u3001\u8017\u65f6\u957f\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u6027\u8981\u6c42\uff1b\u540c\u65f6\u83b7\u53d6\u7cbe\u786e\u4fe1\u9053\u4fe1\u606f\u9700\u8981\u5927\u91cf\u5bfc\u9891\u5f00\u9500\u3002", "contributions": "1\uff09\u63d0\u51fa\u57fa\u4e8e\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u7684\u573a\u4fe1\u606f\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u969c\u788d\u7269\u89c6\u4e3a\u865a\u62df\u53d1\u5c04\u673a\uff0c\u5206\u522b\u5b66\u4e60\u5e45\u5ea6\u548c\u76f8\u4f4d\u53d8\u5316\uff0c\u5feb\u901f\u751f\u6210\u9ad8\u7cbe\u5ea6\u4fe1\u9053\u4fe1\u606f\uff1b2\uff09\u8bbe\u8ba1\u65e0\u9700\u5927\u91cf\u5bfc\u9891\u548c\u590d\u6742\u8ba1\u7b97\u7684\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\uff0c\u5b9e\u73b0FAS\u4f4d\u7f6e\u4e0eRIS\u76f8\u4f4d\u7684\u8054\u5408\u4f18\u5316\u3002", "results": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u5c0f\u53ef\u8fbe\u901f\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5feb\u901f\u8870\u843d\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86FAS-RIS\u7cfb\u7edf\u5728\u52a8\u6001\u4fe1\u9053\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u8054\u5408\u4f18\u5316\u96be\u9898\uff0c\u5177\u5907\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u5f00\u9500\u7684\u4f18\u52bf\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728RIS\u76f8\u4f4d\u4f18\u5316\u548cFAS\u5929\u7ebf\u9009\u62e9\u7684\u72ec\u7acb\u7814\u7a76\u4e0a\uff0c\u90e8\u5206\u5de5\u4f5c\u5f00\u59cb\u63a2\u7d22RIS\u4e0eFAS\u7684\u8054\u5408\u8bbe\u8ba1\uff0c\u4f46\u5927\u591a\u4f9d\u8d56\u4f20\u7edf\u8fed\u4ee3\u7b97\u6cd5\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u4fe1\u9053\u7684\u5feb\u901f\u54cd\u5e94\u80fd\u529b\u3002"}}
