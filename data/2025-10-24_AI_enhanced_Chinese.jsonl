{"id": "2510.18893", "categories": ["cs.DC", "cs.AI", "cs.SE", "I.2.11; D.2.11"], "pdf": "https://arxiv.org/pdf/2510.18893", "abs": "https://arxiv.org/abs/2510.18893", "authors": ["Sergey Pugachev"], "title": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation", "comment": "11 pages, 3 figures", "summary": "Multi-agent LLM systems fail to realize parallel speedups due to costly\ncoordination. We present CodeCRDT, an observation-driven coordination pattern\nwhere agents coordinate by monitoring a shared state with observable updates\nand deterministic convergence, rather than explicit message passing. Using\nConflict-Free Replicated Data Types (CRDTs), CodeCRDT enables lock-free,\nconflict-free concurrent code generation with strong eventual consistency.\nEvaluation across 600 trials (6 tasks, 50 runs per mode) shows both benefits\nand trade-offs: up to 21.1% speedup on some tasks, up to 39.4% slowdown on\nothers, and 100% convergence with zero merge failures. The study formalizes\nobservation-driven coordination for stochastic LLM agents, revealing semantic\nconflict rates (5-10%) and quality-performance tradeoffs, and provides\nempirical characterization of when parallel coordination succeeds versus fails\nbased on task structure.", "AI": {"tldr": "CodeCRDT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c2\u5bdf\u7684\u534f\u8c03\u6a21\u5f0f\uff0c\u5229\u7528CRDT\u5b9e\u73b0\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e2d\u7684\u65e0\u9501\u3001\u65e0\u51b2\u7a81\u5e76\u53d1\u4ee3\u7801\u751f\u6210\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u90e8\u5206\u4efb\u52a1\u4e0a\u53ef\u52a0\u901f\uff0c\u4f46\u67d0\u4e9b\u4efb\u52a1\u4e2d\u4f1a\u53d8\u6162\uff0c\u4e14\u59cb\u7ec8\u4fdd\u8bc1\u5f3a\u6700\u7ec8\u4e00\u81f4\u6027\u4e0e\u96f6\u5408\u5e76\u5931\u8d25\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7531\u4e8e\u534f\u8c03\u6210\u672c\u9ad8\u800c\u96be\u4ee5\u5b9e\u73b0\u5e76\u884c\u52a0\u901f\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u534f\u8c03\u673a\u5236\u3002", "challenges": "\u5982\u4f55\u5728\u4fdd\u8bc1\u4e00\u81f4\u6027\u7684\u540c\u65f6\u907f\u514d\u663e\u5f0f\u6d88\u606f\u4f20\u9012\u5e26\u6765\u7684\u5f00\u9500\uff0c\u5e76\u5904\u7406LLM\u667a\u80fd\u4f53\u5728\u5e76\u53d1\u751f\u6210\u4e2d\u7684\u8bed\u4e49\u51b2\u7a81\u3002", "contributions": "\u63d0\u51fa\u4e86CodeCRDT\u534f\u8c03\u6a21\u5f0f\uff0c\u5f62\u5f0f\u5316\u4e86\u9762\u5411LLM\u667a\u80fd\u4f53\u7684\u89c2\u5bdf\u9a71\u52a8\u534f\u8c03\u673a\u5236\uff0c\u63ed\u793a\u4e86\u8bed\u4e49\u51b2\u7a81\u7387\u4e0e\u6027\u80fd\u8d28\u91cf\u6743\u8861\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u523b\u753b\u4e86\u4efb\u52a1\u7ed3\u6784\u5bf9\u5e76\u884c\u534f\u8c03\u6210\u8d25\u7684\u5f71\u54cd\u3002", "results": "\u5728600\u6b21\u5b9e\u9a8c\u4e2d\uff0c\u90e8\u5206\u4efb\u52a1\u83b7\u5f97\u6700\u9ad821.1%\u7684\u52a0\u901f\uff0c\u90e8\u5206\u4efb\u52a1\u6700\u6162\u4e0b\u964d39.4%\uff0c\u6240\u6709\u8fd0\u884c\u5747100%\u6536\u655b\u4e14\u65e0\u5408\u5e76\u5931\u8d25\uff0c\u8bed\u4e49\u51b2\u7a81\u7387\u4e3a5-10%\u3002", "conclusion": "\u89c2\u5bdf\u9a71\u52a8\u534f\u8c03\u5728\u7279\u5b9a\u4efb\u52a1\u7ed3\u6784\u4e0b\u53ef\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u5e76\u884c\u6548\u7387\uff0c\u4f46\u5b58\u5728\u6027\u80fd\u4e0e\u751f\u6210\u8d28\u91cf\u7684\u6743\u8861\uff0c\u9700\u6839\u636e\u4efb\u52a1\u7279\u6027\u8fdb\u884c\u8bbe\u8ba1\u3002", "related_work": "Conflict-Free Replicated Data Types (CRDTs) \u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u4e00\u81f4\u6027\u7ef4\u62a4\u5de5\u4f5c\uff0c\u4ee5\u53ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u534f\u8c03\u673a\u5236\u3002"}}
{"id": "2510.18897", "categories": ["cs.DC", "cs.AI", "cs.DB", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18897", "abs": "https://arxiv.org/abs/2510.18897", "authors": ["Jacopo Tagliabue"], "title": "AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators", "comment": "Pre-print IAAA workshop submission", "summary": "We explore AI-driven distributed-systems policy design by combining\nstochastic code generation from large language models (LLMs) with deterministic\nverification in a domain-specific simulator. Using a Function-as-a-Service\nruntime (Bauplan) and its open-source simulator (Eudoxia) as a case study, we\nframe scheduler design as an iterative generate-and-verify loop: an LLM\nproposes a Python policy, the simulator evaluates it on standardized traces,\nand structured feedback steers subsequent generations. This setup preserves\ninterpretability while enabling targeted search over a large design space. We\ndetail the system architecture and report preliminary results on throughput\nimprovements across multiple models. Beyond early gains, we discuss the limits\nof the current setup and outline next steps; in particular, we conjecture that\nAI will be crucial for scaling this methodology by helping to bootstrap new\nsimulators.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u968f\u673a\u4ee3\u7801\u751f\u6210\u4e0e\u7279\u5b9a\u9886\u57df\u6a21\u62df\u5668\u4e2d\u7684\u786e\u5b9a\u6027\u9a8c\u8bc1\uff0c\u6765\u5b9e\u73b0AI\u9a71\u52a8\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u7b56\u7565\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u8c03\u5ea6\u7b56\u7565\u7684\u8bbe\u8ba1\u6548\u7387\u548c\u6548\u679c\uff0c\u7814\u7a76\u8005\u4eec\u8bd5\u56fe\u5229\u7528AI\u6280\u672f\u81ea\u52a8\u63a2\u7d22\u5927\u7684\u8bbe\u8ba1\u7a7a\u95f4\u3002", "challenges": "\u5982\u4f55\u6709\u6548\u5730\u7ed3\u5408\u751f\u6210\u6a21\u578b\u4e0e\u9a8c\u8bc1\u673a\u5236\u4ee5\u786e\u4fdd\u751f\u6210\u7684\u7b56\u7565\u65e2\u521b\u65b0\u53c8\u53ef\u9760\uff1b\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u662f\u4e00\u4e2a\u6311\u6218\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fed\u4ee3\u7684\u751f\u6210-\u9a8c\u8bc1\u5faa\u73af\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5730\u8bbe\u8ba1\u548c\u4f18\u5316\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u5e76\u5728Function-as-a-Service\u8fd0\u884c\u65f6\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\u3002", "results": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u541e\u5410\u91cf\u7684\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "AI\u5c06\u5728\u6269\u5c55\u6b64\u65b9\u6cd5\u8bba\u65b9\u9762\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u5e2e\u52a9\u542f\u52a8\u65b0\u7684\u6a21\u62df\u5668\u65b9\u9762\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4f18\u5316\u5206\u5e03\u5f0f\u7cfb\u7edf\u6027\u80fd\u7684\u7814\u7a76\uff0c\u4ee5\u53ca\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8f6f\u4ef6\u5f00\u53d1\u8f85\u52a9\u7684\u5de5\u4f5c\u3002"}}
{"id": "2510.19262", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.19262", "abs": "https://arxiv.org/abs/2510.19262", "authors": ["Heng Xu", "Zhiwei Yu", "Chengze Du", "Ying Zhou", "Letian Li", "Haojie Wang", "Weiqiang Cheng", "Jialong Li"], "title": "RailS: Load Balancing for All-to-All Communication in Distributed Mixture-of-Experts Training", "comment": null, "summary": "Training Mixture-of-Experts (MoE) models introduces sparse and highly\nimbalanced all-to-all communication that dominates iteration time. Conventional\nload-balancing methods fail to exploit the deterministic topology of Rail\narchitectures, leaving multi-NIC bandwidth underutilized. We present RailS, a\ndistributed load-balancing framework that minimizes all-to-all completion time\nin MoE training. RailS leverages the Rail topology's symmetry to prove that\nuniform sending ensures uniform receiving, transforming global coordination\ninto local scheduling. Each node independently executes a Longest Processing\nTime First (LPT) spraying scheduler to proactively balance traffic using local\ninformation. RailS activates N parallel rails for fine-grained, topology-aware\nmultipath transmission. Across synthetic and real-world MoE workloads, RailS\nimproves bus bandwidth by 20%--78% and reduces completion time by 17%--78%. For\nMixtral workloads, it shortens iteration time by 18%--40% and achieves\nnear-optimal load balance, fully exploiting architectural parallelism in\ndistributed training.", "AI": {"tldr": "RailS\u662f\u4e00\u79cd\u9488\u5bf9MoE\u8bad\u7ec3\u4e2d\u901a\u4fe1\u74f6\u9888\u7684\u5206\u5e03\u5f0f\u8d1f\u8f7d\u5747\u8861\u6846\u67b6\uff0c\u5229\u7528Rail\u62d3\u6251\u7684\u5bf9\u79f0\u6027\u5b9e\u73b0\u5c40\u90e8\u8c03\u5ea6\u4e0b\u7684\u5168\u5c40\u5747\u8861\uff0c\u663e\u8457\u63d0\u5347\u5e26\u5bbd\u5229\u7528\u7387\u5e76\u964d\u4f4e\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "MoE\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u7a00\u758f\u4e14\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u5168\u5bf9\u5168\u901a\u4fe1\u6210\u4e3a\u8fed\u4ee3\u7684\u4e3b\u8981\u5f00\u9500\uff0c\u4f20\u7edf\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528Rail\u67b6\u6784\u7684\u786e\u5b9a\u6027\u62d3\u6251\u548c\u591aNIC\u5e26\u5bbd\u3002", "challenges": "\u5982\u4f55\u5728\u4e0d\u4f9d\u8d56\u5168\u5c40\u534f\u8c03\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u8d1f\u8f7d\u5747\u8861\uff1b\u5982\u4f55\u5145\u5206\u5229\u7528Rail\u67b6\u6784\u7684\u591a\u8def\u5f84\u5e76\u884c\u80fd\u529b\u4ee5\u51cf\u5c11\u901a\u4fe1\u5ef6\u8fdf\u3002", "contributions": "\u63d0\u51fa\u4e86RailS\u6846\u67b6\uff0c\u9996\u6b21\u5229\u7528Rail\u62d3\u6251\u7684\u5bf9\u79f0\u6027\u8bc1\u660e\u5747\u5300\u53d1\u9001\u53ef\u4fdd\u8bc1\u5747\u5300\u63a5\u6536\uff0c\u5c06\u5168\u5c40\u534f\u8c03\u8f6c\u5316\u4e3a\u5c40\u90e8\u8c03\u5ea6\uff1b\u8bbe\u8ba1\u4e86\u57fa\u4e8eLPT\u7684\u55b7\u6d12\u8c03\u5ea6\u5668\uff0c\u5e76\u542f\u7528N\u6761\u5e76\u884c\u901a\u9053\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u3001\u62d3\u6251\u611f\u77e5\u7684\u591a\u8def\u5f84\u4f20\u8f93\u3002", "results": "\u5728\u5408\u6210\u548c\u771f\u5b9eMoE\u8d1f\u8f7d\u4e0b\uff0c\u603b\u7ebf\u5e26\u5bbd\u63d0\u534720%\u201378%\uff0c\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1117%\u201378%\uff1b\u5728Mixtral\u8d1f\u8f7d\u4e0a\u8fed\u4ee3\u65f6\u95f4\u7f29\u77ed18%\u201340%\uff0c\u8fbe\u5230\u8fd1\u4f3c\u6700\u4f18\u8d1f\u8f7d\u5747\u8861\u3002", "conclusion": "RailS\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u5c40\u90e8\u8c03\u5ea6\u6709\u6548\u89e3\u51b3\u4e86MoE\u8bad\u7ec3\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\uff0c\u5145\u5206\u6316\u6398\u4e86\u5206\u5e03\u5f0f\u67b6\u6784\u7684\u5e76\u884c\u6f5c\u529b\uff0c\u4e3a\u5927\u89c4\u6a21MoE\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u901a\u4fe1\u652f\u6301\u3002", "related_work": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u7528\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u7f3a\u4e4f\u5bf9Rail\u8fd9\u7c7b\u7279\u5b9a\u62d3\u6251\u7ed3\u6784\u7684\u4f18\u5316\u5229\u7528\uff1b\u90e8\u5206\u7814\u7a76\u5c1d\u8bd5\u52a8\u6001\u8def\u7531\u4f46\u672a\u7ed3\u5408\u62d3\u6251\u5bf9\u79f0\u6027\u548c\u672c\u5730\u5316\u8c03\u5ea6\u3002"}}
{"id": "2510.19012", "categories": ["cs.DC", "cs.DB", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19012", "abs": "https://arxiv.org/abs/2510.19012", "authors": ["Ivan Borodii", "Illia Fedorovych", "Halyna Osukhivska", "Diana Velychko", "Roman Butsii"], "title": "Comparative analysis of large data processing in Apache Spark using Java, Python and Scala", "comment": "CITI 2025, 3rd International Workshop on Computer Information\n  Technologies in Industry 4.0, June 11-12, 2025, Ternopil, Ukraine. The\n  article includes 10 pages, 5 figures, 9 tables", "summary": "During the study, the results of a comparative analysis of the process of\nhandling large datasets using the Apache Spark platform in Java, Python, and\nScala programming languages were obtained. Although prior works have focused on\nindividual stages, comprehensive comparisons of full ETL workflows across\nprogramming languages using Apache Iceberg remain limited. The analysis was\nperformed by executing several operations, including downloading data from CSV\nfiles, transforming and loading it into an Apache Iceberg analytical table. It\nwas found that the performance of the Spark algorithm varies significantly\ndepending on the amount of data and the programming language used. When\nprocessing a 5-megabyte CSV file, the best result was achieved in Python: 6.71\nseconds, which is superior to Scala's score of 9.13 seconds and Java's time of\n9.62 seconds. For processing a large CSV file of 1.6 gigabytes, all programming\nlanguages demonstrated similar results: the fastest performance was showed in\nPython: 46.34 seconds, while Scala and Java showed results of 47.72 and 50.56\nseconds, respectively. When performing a more complex operation that involved\ncombining two CSV files into a single dataset for further loading into an\nApache Iceberg table, Scala demonstrated the highest performance, at 374.42\nseconds. Java processing was completed in 379.8 seconds, while Python was the\nleast efficient, with a runtime of 398.32 seconds. It follows that the\nprogramming language significantly affects the efficiency of data processing by\nthe Apache Spark algorithm, with Scala and Java being more productive for\nprocessing large amounts of data and complex operations, while Python\ndemonstrates an advantage in working with small amounts of data. The results\nobtained can be useful for optimizing data handling processes depending on\nspecific performance requirements and the amount of information being\nprocessed.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4f7f\u7528Java\u3001Python\u548cScala\u5728Apache Spark\u5e73\u53f0\u4e0a\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u4e0d\u540c\u6570\u636e\u91cf\u548c\u64cd\u4f5c\u590d\u6742\u5ea6\u4e0b\u5404\u8bed\u8a00\u5728\u5b8c\u6574ETL\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5229\u7528Apache Iceberg\u8fdb\u884c\u6570\u636e\u5b58\u50a8\u3002", "motivation": "\u4e3a\u4e86\u4f18\u5316\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u548c\u5904\u7406\u9700\u6c42\u4e0b\u7684\u6570\u636e\u5904\u7406\u6548\u7387\uff0c\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83Java\u3001Python\u548cScala\u5728Spark\u5e73\u53f0\u4e0a\u7684\u7aef\u5230\u7aefETL\u6027\u80fd\u5dee\u5f02\u3002", "challenges": "\u7f3a\u4e4f\u5bf9\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u5728\u5b8c\u6574ETL\u6d41\u7a0b\u4e2d\u3001\u5c24\u5176\u662f\u5728\u4f7f\u7528Apache Iceberg\u65f6\u7684\u7efc\u5408\u6027\u80fd\u5bf9\u6bd4\u7814\u7a76\uff1b\u4e0d\u540c\u8bed\u8a00\u5728\u6267\u884c\u590d\u6742\u64cd\u4f5c\u548c\u5904\u7406\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u65f6\u7684\u6027\u80fd\u5dee\u5f02\u663e\u8457\u3002", "contributions": "\u63d0\u4f9b\u4e86Java\u3001Python\u548cScala\u5728Spark\u5e73\u53f0\u4e0a\u6267\u884c\u5b8c\u6574ETL\u6d41\u7a0b\uff08\u5305\u62ec\u8bfb\u53d6CSV\u3001\u8f6c\u6362\u3001\u5199\u5165Iceberg\u8868\uff09\u7684\u5b9e\u8bc1\u6027\u80fd\u5bf9\u6bd4\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u9009\u62e9\u4e0e\u6570\u636e\u89c4\u6a21\u3001\u64cd\u4f5c\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "results": "\u5904\u74065MB\u5c0f\u6587\u4ef6\u65f6\uff0cPython\u6700\u5feb\uff086.71\u79d2\uff09\uff0c\u4f18\u4e8eScala\uff089.13\u79d2\uff09\u548cJava\uff089.62\u79d2\uff09\uff1b\u5904\u74061.6GB\u5927\u6587\u4ef6\u65f6\uff0c\u4e09\u8005\u6027\u80fd\u63a5\u8fd1\uff0cPython\u6700\u5feb\uff0846.34\u79d2\uff09\uff0cJava\u6700\u6162\uff0850.56\u79d2\uff09\uff1b\u5728\u590d\u6742\u64cd\u4f5c\uff08\u5408\u5e76\u4e24\u4e2aCSV\u6587\u4ef6\uff09\u4e2d\uff0cScala\u6700\u5feb\uff08374.42\u79d2\uff09\uff0cJava\u6b21\u4e4b\uff08379.8\u79d2\uff09\uff0cPython\u6700\u6162\uff08398.32\u79d2\uff09\u3002", "conclusion": "\u7f16\u7a0b\u8bed\u8a00\u663e\u8457\u5f71\u54cdSpark\u7684\u6570\u636e\u5904\u7406\u6548\u7387\uff1aPython\u5728\u5904\u7406\u5c0f\u6570\u636e\u91cf\u65f6\u66f4\u5177\u4f18\u52bf\uff0c\u800cScala\u548cJava\u5728\u5904\u7406\u5927\u6570\u636e\u91cf\u548c\u590d\u6742\u64cd\u4f5c\u65f6\u66f4\u9ad8\u6548\u3002\u8be5\u7ed3\u679c\u53ef\u4e3a\u6839\u636e\u6570\u636e\u89c4\u6a21\u548c\u6027\u80fd\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u7f16\u7a0b\u8bed\u8a00\u63d0\u4f9b\u4f9d\u636e\u3002", "related_work": "\u5df2\u6709\u7814\u7a76\u591a\u5173\u6ce8Spark\u5728\u5355\u4e00\u8bed\u8a00\u4e0b\u7684\u7279\u5b9a\u9636\u6bb5\u6027\u80fd\uff0c\u6216\u6bd4\u8f83\u8bed\u8a00\u5728\u5185\u5b58\u8ba1\u7b97\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u4f46\u7f3a\u4e4f\u5728\u4f7f\u7528Apache Iceberg\u7684\u5b8c\u6574ETL\u6d41\u7a0b\u4e2d\u5bf9\u591a\u8bed\u8a00\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u3002"}}
{"id": "2510.19151", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.19151", "abs": "https://arxiv.org/abs/2510.19151", "authors": ["Seri Khoury", "Manish Purohit", "Aaron Schild", "Joshua Wang"], "title": "On the Randomized Locality of Matching Problems in Regular Graphs", "comment": "DISC 2025. Abstract modified for arXiv", "summary": "The main goal in distributed symmetry-breaking is to understand the locality\nof problems; i.e., the radius of the neighborhood that a node needs to explore\nin order to arrive at its part of a global solution. In this work, we study the\nlocality of matching problems in the family of regular graphs, which is one of\nthe main benchmarks for establishing lower bounds on the locality of\nsymmetry-breaking problems, as well as for obtaining classification results.\nFor approximate matching, we develop randomized algorithms to show that $(1 +\n\\epsilon)$-approximate matching in regular graphs is truly local; i.e., the\nlocality depends only on $\\epsilon$ and is independent of all other graph\nparameters. Furthermore, as long as the degree $\\Delta$ is not very small\n(namely, as long as $\\Delta \\geq \\text{poly}(1/\\epsilon)$), this dependence is\nonly logarithmic in $1/\\epsilon$. This stands in sharp contrast to maximal\nmatching in regular graphs which requires some dependence on the number of\nnodes $n$ or the degree $\\Delta$. We show matching lower bounds for both\nresults. For maximal matching, our techniques further allow us to establish a\nstrong separation between the node-averaged complexity and worst-case\ncomplexity of maximal matching in regular graphs, by showing that the former is\nonly $O(1)$. Central to our main technical contribution is a novel\nmartingale-based analysis for the $\\approx 40$-year-old algorithm by Luby. In\nparticular, our analysis shows that applying one round of Luby's algorithm on\nthe line graph of a $\\Delta$-regular graph results in an almost\n$\\Delta/2$-regular graph.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6b63\u5219\u56fe\u4e2d\u5339\u914d\u95ee\u9898\u7684\u5c40\u90e8\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5728\u6b63\u5219\u56fe\u4e2d(1+\u03b5)-\u8fd1\u4f3c\u5339\u914d\u662f\u771f\u6b63\u5c40\u90e8\u7684\uff0c\u5176\u5c40\u90e8\u6027\u4ec5\u4f9d\u8d56\u4e8e\u03b5\uff0c\u4e14\u5f53\u5ea6\u0394\u8db3\u591f\u5927\u65f6\uff0c\u8fd9\u79cd\u4f9d\u8d56\u4ec5\u4e3alog(1/\u03b5)\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u5c55\u793a\u4e86\u6700\u5927\u5339\u914d\u5728\u8282\u70b9\u5e73\u5747\u590d\u6742\u5ea6\u548c\u6700\u574f\u60c5\u51b5\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u663e\u8457\u5206\u79bb\uff0c\u5e76\u901a\u8fc7Luby\u7b97\u6cd5\u7684\u65b0\u9896\u9785\u5206\u6790\u6280\u672f\uff0c\u8bc1\u660e\u4e86\u4e00\u8f6eLuby\u7b97\u6cd5\u5e94\u7528\u4e8e\u0394-\u6b63\u5219\u56fe\u7684\u7ebf\u56fe\u540e\u4f1a\u4ea7\u751f\u51e0\u4e4e\u0394/2-\u6b63\u5219\u56fe\u3002", "motivation": "\u7406\u89e3\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u6253\u7834\u95ee\u9898\u4e2d\u7684\u5c40\u90e8\u6027\uff0c\u5373\u8282\u70b9\u9700\u8981\u63a2\u7d22\u5176\u90bb\u57df\u534a\u5f84\u4ee5\u8fbe\u5230\u5168\u5c40\u89e3\u7684\u4e00\u90e8\u5206\u3002", "challenges": "\u786e\u5b9a\u6b63\u5219\u56fe\u4e2d\u5339\u914d\u95ee\u9898\u7684\u5c40\u90e8\u6027\uff0c\u7279\u522b\u662f\u8fd1\u4f3c\u5339\u914d\u4e0e\u6700\u5927\u5339\u914d\u7684\u5c40\u90e8\u6027\u5dee\u5f02\u3002", "contributions": "\u63d0\u51fa\u4e86\u65b0\u7684\u968f\u673a\u7b97\u6cd5\u6765\u5c55\u793a(1+\u03b5)-\u8fd1\u4f3c\u5339\u914d\u5728\u6b63\u5219\u56fe\u4e2d\u7684\u5c40\u90e8\u6027\uff1b\u5efa\u7acb\u4e86\u6700\u5927\u5339\u914d\u5728\u8282\u70b9\u5e73\u5747\u590d\u6742\u5ea6\u548c\u6700\u574f\u60c5\u51b5\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u5f3a\u5206\u79bb\uff1b\u5f15\u5165\u4e86\u57fa\u4e8e\u9785\u5206\u6790\u7684\u6280\u672f\u6765\u5206\u6790Luby\u7b97\u6cd5\u3002", "results": "\u8bc1\u660e\u4e86(1+\u03b5)-\u8fd1\u4f3c\u5339\u914d\u5728\u6b63\u5219\u56fe\u4e2d\u7684\u5c40\u90e8\u6027\u4ec5\u4f9d\u8d56\u4e8e\u03b5\uff0c\u4e14\u5f53\u0394\u2265poly(1/\u03b5)\u65f6\uff0c\u8fd9\u79cd\u4f9d\u8d56\u4e3alog(1/\u03b5)\uff1b\u6700\u5927\u5339\u914d\u7684\u8282\u70b9\u5e73\u5747\u590d\u6742\u5ea6\u4ec5\u4e3aO(1)\uff1b\u4e00\u8f6eLuby\u7b97\u6cd5\u5e94\u7528\u4e8e\u0394-\u6b63\u5219\u56fe\u7684\u7ebf\u56fe\u540e\u4ea7\u751f\u51e0\u4e4e\u0394/2-\u6b63\u5219\u56fe\u3002", "conclusion": "\u8bba\u6587\u6210\u529f\u5730\u63ed\u793a\u4e86\u6b63\u5219\u56fe\u4e2d\u8fd1\u4f3c\u5339\u914d\u548c\u6700\u5927\u5339\u914d\u7684\u5c40\u90e8\u6027\u7279\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u6253\u7834\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u548c\u6280\u672f\u5de5\u5177\u3002", "related_work": "\u6b63\u5219\u56fe\u4f5c\u4e3a\u5efa\u7acb\u5bf9\u79f0\u6027\u6253\u7834\u95ee\u9898\u4e0b\u754c\u548c\u5206\u7c7b\u7ed3\u679c\u7684\u4e3b\u8981\u57fa\u51c6\uff0c\u5df2\u6709\u5927\u91cf\u7814\u7a76\u5173\u6ce8\u4e8e\u6700\u5927\u5339\u914d\u7684\u5c40\u90e8\u6027\u3002"}}
{"id": "2510.19225", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19225", "abs": "https://arxiv.org/abs/2510.19225", "authors": ["Yongji Wu", "Xueshen Liu", "Haizhong Zheng", "Juncheng Gu", "Beidi Chen", "Z. Morley Mao", "Arvind Krishnamurthy", "Ion Stoica"], "title": "RLBoost: Harvesting Preemptible Resources for Cost-Efficient Reinforcement Learning on LLMs", "comment": null, "summary": "Reinforcement learning (RL) has become essential for unlocking advanced\nreasoning capabilities in large language models (LLMs). RL workflows involve\ninterleaving rollout and training stages with fundamentally different resource\nrequirements. Rollout typically dominates overall execution time, yet scales\nefficiently through multiple independent instances. In contrast, training\nrequires tightly-coupled GPUs with full-mesh communication. Existing RL\nframeworks fall into two categories: co-located and disaggregated\narchitectures. Co-located ones fail to address this resource tension by forcing\nboth stages to share the same GPUs. Disaggregated architectures, without\nmodifications of well-established RL algorithms, suffer from resource\nunder-utilization. Meanwhile, preemptible GPU resources, i.e., spot instances\non public clouds and spare capacity in production clusters, present significant\ncost-saving opportunities for accelerating RL workflows, if efficiently\nharvested for rollout.\n  In this paper, we present RLBoost, a systematic solution for cost-efficient\nRL training that harvests preemptible GPU resources. Our key insight is that\nrollout's stateless and embarrassingly parallel nature aligns perfectly with\npreemptible and often fragmented resources. To efficiently utilize these\nresources despite frequent and unpredictable availability changes, RLBoost\nadopts a hybrid architecture with three key techniques: (1) adaptive rollout\noffload to dynamically adjust workloads on the reserved (on-demand) cluster,\n(2) pull-based weight transfer that quickly provisions newly available\ninstances, and (3) token-level response collection and migration for efficient\npreemption handling and continuous load balancing. Extensive experiments show\nRLBoost increases training throughput by 1.51x-1.97x while improving cost\nefficiency by 28%-49% compared to using only on-demand GPU resources.", "AI": {"tldr": "RLBoost\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u62a2\u5360\u5f0fGPU\u8d44\u6e90\uff08\u5982\u4e91\u4e0a\u7684\u7ade\u4ef7\u5b9e\u4f8b\uff09\u6765\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u9636\u6bb5\uff08rollout\uff09\uff0c\u91c7\u7528\u6df7\u5408\u67b6\u6784\u548c\u4e09\u9879\u5173\u952e\u6280\u672f\uff1a\u81ea\u9002\u5e94rollout\u5378\u8f7d\u3001\u57fa\u4e8e\u62c9\u53d6\u7684\u6743\u91cd\u4f20\u8f93\u3001\u4ee5\u53catoken\u7ea7\u54cd\u5e94\u6536\u96c6\u4e0e\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u6210\u672c\u6548\u7387\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u5176\u8bad\u7ec3\u6d41\u7a0b\u4e2drollout\u548c\u8bad\u7ec3\u9636\u6bb5\u5b58\u5728\u8d44\u6e90\u9700\u6c42\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff1b\u540c\u65f6\uff0c\u73b0\u6709\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u5229\u7528\u62a2\u5360\u5f0fGPU\u8d44\u6e90\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u4e14\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3002", "challenges": "\u5982\u4f55\u5728\u9891\u7e41\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u62a2\u5360\u5f0f\u8d44\u6e90\u4e2d\u65ad\u4e0b\uff0c\u9ad8\u6548\u5229\u7528\u788e\u7247\u5316GPU\u8d44\u6e90\u8fdb\u884c\u5927\u89c4\u6a21rollout\uff1b\u540c\u65f6\u4fdd\u6301\u4e0e\u8bad\u7ec3\u9636\u6bb5\u7684\u534f\u8c03\uff0c\u907f\u514d\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d\u3002", "contributions": "1) \u63d0\u51faRLBoost\u6846\u67b6\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5c06\u62a2\u5360\u5f0fGPU\u8d44\u6e90\u7528\u4e8eLLM\u7684RL\u8bad\u7ec3\uff1b2) \u8bbe\u8ba1\u6df7\u5408\u67b6\u6784\u4e0e\u4e09\u9879\u6838\u5fc3\u6280\u672f\uff1a\u81ea\u9002\u5e94rollout\u5378\u8f7d\u3001pull-based\u6743\u91cd\u540c\u6b65\u3001token\u7ea7\u54cd\u5e94\u6536\u96c6\u4e0e\u8fc1\u79fb\uff1b3) \u5b9e\u73b0\u9ad8\u541e\u5410\u4e0e\u9ad8\u6210\u672c\u6548\u76ca\u7684\u5e73\u8861\u3002", "results": "\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6309\u9700GPU\u8d44\u6e90\uff0cRLBoost\u5c06\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\u4e861.51\u500d\u81f31.97\u500d\uff0c\u6210\u672c\u6548\u7387\u63d0\u9ad8\u4e8628%\u523049%\u3002", "conclusion": "RLBoost\u901a\u8fc7\u6709\u6548\u6574\u5408\u62a2\u5360\u5f0fGPU\u8d44\u6e90\uff0c\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u8d44\u6e90\u5229\u7528\u4e0d\u5145\u5206\u548c\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u5171\u7f6e\u5f0f\u4e0e disaggregated \u67b6\u6784\u7684RL\u8bad\u7ec3\u6846\u67b6\uff0c\u4ee5\u53ca\u62a2\u5360\u5f0f\u8d44\u6e90\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u7814\u7a76\uff0c\u4f46\u8fd9\u4e9b\u5de5\u4f5c\u672a\u5145\u5206\u89e3\u51b3rollout\u4e0e\u8bad\u7ec3\u9636\u6bb5\u7684\u8d44\u6e90\u9519\u914d\u53ca\u62a2\u5360\u5e26\u6765\u7684\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2510.19301", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.19301", "abs": "https://arxiv.org/abs/2510.19301", "authors": ["Ziheng Deng", "Xue Liu", "Jiantong Jiang", "Yankai Li", "Qingxu Deng", "Xiaochun Yang"], "title": "FLASH Viterbi: Fast and Adaptive Viterbi Decoding for Modern Data Systems", "comment": "Accepted for ICDE 2026", "summary": "The Viterbi algorithm is a key operator for structured sequence inference in\nmodern data systems, with applications in trajectory analysis, online\nrecommendation, and speech recognition. As these workloads increasingly migrate\nto resource-constrained edge platforms, standard Viterbi decoding remains\nmemory-intensive and computationally inflexible. Existing methods typically\ntrade decoding time for space efficiency, but often incur significant runtime\noverhead and lack adaptability to various system constraints. This paper\npresents FLASH Viterbi, a Fast, Lightweight, Adaptive, and Hardware-Friendly\nViterbi decoding operator that enhances adaptability and resource efficiency.\nFLASH Viterbi combines a non-recursive divide-and-conquer strategy with pruning\nand parallelization techniques to enhance both time and memory efficiency,\nmaking it well-suited for resource-constrained data systems. To further\ndecouple space complexity from the hidden state space size, we present FLASH-BS\nViterbi, a dynamic beam search variant built on a memory-efficient data\nstructure. Both proposed algorithms exhibit strong adaptivity to diverse\ndeployment scenarios by dynamically tuning internal parameters. To ensure\npractical deployment on edge devices, we also develop FPGA-based hardware\naccelerators for both algorithms, demonstrating high throughput and low\nresource usage. Extensive experiments show that our algorithms consistently\noutperform existing baselines in both decoding time and memory efficiency,\nwhile preserving adaptability and hardware-friendly characteristics essential\nfor modern data systems. All codes are publicly available at\nhttps://github.com/Dzh-16/FLASH-Viterbi.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FLASH Viterbi\u548cFLASH-BS Viterbi\u4e24\u79cd\u65b0\u578bViterbi\u89e3\u7801\u7b97\u6cd5\uff0c\u901a\u8fc7\u975e\u9012\u5f52\u5206\u6cbb\u3001\u526a\u679d\u548c\u5e76\u884c\u5316\u6280\u672f\u63d0\u5347\u4e86\u89e3\u7801\u7684\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u3002", "motivation": "\u968f\u7740\u5de5\u4f5c\u8d1f\u8f7d\u8d8a\u6765\u8d8a\u591a\u5730\u8fc1\u79fb\u5230\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u5e73\u53f0\uff0c\u6807\u51c6Viterbi\u89e3\u7801\u4ecd\u7136\u5185\u5b58\u5bc6\u96c6\u4e14\u8ba1\u7b97\u4e0d\u7075\u6d3b\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4ee5\u89e3\u7801\u65f6\u95f4\u4e3a\u4ee3\u4ef7\u6362\u53d6\u7a7a\u95f4\u6548\u7387\uff0c\u4f46\u5f80\u5f80\u5e26\u6765\u663e\u8457\u7684\u8fd0\u884c\u65f6\u5f00\u9500\u5e76\u4e14\u7f3a\u4e4f\u5bf9\u5404\u79cd\u7cfb\u7edf\u7ea6\u675f\u7684\u9002\u5e94\u6027\u3002", "challenges": "\u5982\u4f55\u5728\u4fdd\u6301\u89e3\u7801\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u65f6\u95f4\uff0c\u4ee5\u53ca\u5982\u4f55\u4f7f\u7b97\u6cd5\u9002\u5e94\u4e0d\u540c\u7684\u7cfb\u7edf\u7ea6\u675f\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u3001\u8f7b\u91cf\u3001\u81ea\u9002\u5e94\u4e14\u786c\u4ef6\u53cb\u597d\u7684Viterbi\u89e3\u7801\u7b97\u5b50FLASH Viterbi\uff0c\u4ee5\u53ca\u57fa\u4e8e\u52a8\u6001\u675f\u641c\u7d22\u7684\u53d8\u4f53FLASH-BS Viterbi\uff1b\u5f00\u53d1\u4e86\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff1b\u5b9e\u9a8c\u8868\u660e\u65b0\u7b97\u6cd5\u5728\u89e3\u7801\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "results": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u89e3\u7801\u65f6\u95f4\u548c\u5185\u5b58\u6548\u7387\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9002\u5e94\u6027\u548c\u786c\u4ef6\u53cb\u597d\u7279\u6027\u3002", "conclusion": "FLASH Viterbi\u548cFLASH-BS Viterbi\u7b97\u6cd5\u53ca\u5176\u786c\u4ef6\u52a0\u901f\u5668\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u6570\u636e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684Viterbi\u89e3\u7801\u89e3\u51b3\u65b9\u6848\u3002", "related_work": "\u73b0\u6709\u7684Viterbi\u89e3\u7801\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u727a\u7272\u89e3\u7801\u65f6\u95f4\u6765\u63d0\u9ad8\u7a7a\u95f4\u6548\u7387\uff0c\u4f46\u901a\u5e38\u4f1a\u5e26\u6765\u8f83\u5927\u7684\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u7cfb\u7edf\u7ea6\u675f\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2510.19470", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19470", "abs": "https://arxiv.org/abs/2510.19470", "authors": ["Weihao Yang", "Hao Huang", "Donglei Wu", "Ningke Li", "Yanqi Pan", "Qiyang Zheng", "Wen Xia", "Shiyi Li", "Qiang Wang"], "title": "HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission", "comment": null, "summary": "Mixture-of-Experts (MoE) has become a popular architecture for scaling large\nmodels. However, the rapidly growing scale outpaces model training on a single\nDC, driving a shift toward a more flexible, cross-DC training paradigm. Under\nthis, Expert Parallelism (EP) of MoE faces significant scalability issues due\nto the limited cross-DC bandwidth. Specifically, existing EP optimizations\nattempt to overlap data communication and computation, which has little benefit\nin low-bandwidth scenarios due to a much longer data communication time.\nTherefore, the trends of cross-DC EP scaling is fast becoming a critical\nroadblock to the continued growth of MoE models.\n  To address this, we propose HybridEP, a modeling-guided framework to optimize\nEP under constrained bandwidth. Our key idea is to dynamically transform the\nspatial placement of experts to reduce data communication traffic and\nfrequency, thereby minimizing EP's communication overheads. However, it is\nnon-trivial to find the optimal solution because it complicates the original\ncommunication pattern by mixing data and expert communication. We therefore\nbuild a stream-based model to determine the optimal transmission ratio. Guided\nby this, we incorporate two techniques: (1) domain-based partition to construct\nthe mapping between hybrid patterns and specific communication topology at GPU\nlevel, and (2) parameter-efficient migration to further refine this topology by\nreducing expert transmission overhead and enlarging the domain size. Combining\nall these designs, HybridEP can be considered as a more general EP with better\nscalability. Experimental results show that HybridEP outperforms existing\nstate-of-the-art MoE training systems by up to 5.6x under constrained\nbandwidth. We further compare HybridEP and EP on large-scale simulations.\nHybridEP achieves up to 1.45x speedup with 1k DCs under different bandwidths.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HybridEP\uff0c\u4e00\u79cd\u5728\u5e26\u5bbd\u53d7\u9650\u73af\u5883\u4e0b\u4f18\u5316MoE\u6a21\u578b\u4e13\u5bb6\u5e76\u884c\uff08EP\uff09\u7684\u6df7\u5408\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u7684\u5206\u5e03\u4f4d\u7f6e\u5e76\u7ed3\u5408\u5efa\u6a21\u6307\u5bfc\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u968f\u7740MoE\u6a21\u578b\u89c4\u6a21\u7684\u5feb\u901f\u589e\u957f\uff0c\u5355\u6570\u636e\u4e2d\u5fc3\u5df2\u96be\u4ee5\u652f\u6491\u8bad\u7ec3\u9700\u6c42\uff0c\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u6210\u4e3a\u8d8b\u52bf\u3002\u7136\u800c\uff0c\u53d7\u9650\u4e8e\u8de8DC\u5e26\u5bbd\uff0c\u4e13\u5bb6\u5e76\u884c\uff08EP\uff09\u9762\u4e34\u4e25\u91cd\u7684\u901a\u4fe1\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u4f4e\u5e26\u5bbd\u4e0b\u96be\u4ee5\u6709\u6548\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\uff0c\u4e9f\u9700\u65b0\u7684\u4f18\u5316\u65b9\u6848\u3002", "challenges": "\u5728\u4f4e\u5e26\u5bbd\u73af\u5883\u4e0b\uff0cEP\u7684\u901a\u4fe1\u65f6\u95f4\u8fdc\u957f\u4e8e\u8ba1\u7b97\u65f6\u95f4\uff0c\u5bfc\u81f4\u901a\u4fe1\u91cd\u53e0\u7b56\u7565\u6548\u679c\u6709\u9650\uff1b\u540c\u65f6\uff0c\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u5206\u5e03\u4f1a\u5f15\u5165\u989d\u5916\u7684\u4e13\u5bb6\u8fc1\u79fb\u5f00\u9500\uff0c\u5e76\u6539\u53d8\u539f\u6709\u7684\u901a\u4fe1\u6a21\u5f0f\uff0c\u4f7f\u5f97\u901a\u4fe1\u4f18\u5316\u66f4\u52a0\u590d\u6742\u3002", "contributions": "1\uff09\u63d0\u51faHybridEP\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u53d8\u6362\u4e13\u5bb6\u7a7a\u95f4\u5e03\u5c40\u6765\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff1b2\uff09\u6784\u5efa\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u4ee5\u786e\u5b9a\u6700\u4f18\u4f20\u8f93\u6bd4\u4f8b\uff1b3\uff09\u8bbe\u8ba1\u57df\u5212\u5206\u548c\u53c2\u6570\u9ad8\u6548\u8fc1\u79fb\u6280\u672f\uff0c\u5728GPU\u5c42\u7ea7\u4f18\u5316\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\uff1b4\uff09\u5b9e\u73b0\u4e86\u5728\u53d7\u9650\u5e26\u5bbd\u4e0b\u66f4\u5177\u53ef\u6269\u5c55\u6027\u7684EP\u8bad\u7ec3\u65b9\u6848\u3002", "results": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u573a\u666f\u4e0b\uff0cHybridEP\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684MoE\u8bad\u7ec3\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe5.6\u500d\uff1b\u5728\u5927\u89c4\u6a21\u4eff\u771f\u4e2d\uff081000\u4e2a\u6570\u636e\u4e2d\u5fc3\uff09\uff0c\u4e0d\u540c\u5e26\u5bbd\u6761\u4ef6\u4e0b\u6700\u9ad8\u5b9e\u73b01.45\u500d\u7684\u52a0\u901f\u3002", "conclusion": "HybridEP\u901a\u8fc7\u5efa\u6a21\u6307\u5bfc\u7684\u6df7\u5408\u4e13\u5bb6\u5e76\u884c\u7b56\u7565\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u4e2d\u56e0\u5e26\u5bbd\u53d7\u9650\u5bfc\u81f4\u7684\u901a\u4fe1\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86MoE\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u5305\u62ecMoE\u67b6\u6784\u8bbe\u8ba1\uff08\u5982Switch Transformer\uff09\u3001\u4e13\u5bb6\u5e76\u884c\u7b56\u7565\uff08\u5982EP\u3001DP\uff09\u3001\u901a\u4fe1\u4f18\u5316\u6280\u672f\uff08\u5982\u6d41\u6c34\u7ebf\u5e76\u884c\u3001\u901a\u4fe1\u91cd\u53e0\uff09\u4ee5\u53ca\u8de8\u6570\u636e\u4e2d\u5fc3\u8bad\u7ec3\u4e2d\u7684\u8d44\u6e90\u8c03\u5ea6\u673a\u5236\u3002"}}
{"id": "2510.19617", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.19617", "abs": "https://arxiv.org/abs/2510.19617", "authors": ["Eric Ding"], "title": "Propius: A Platform for Collaborative Machine Learning across the Edge and the Cloud", "comment": null, "summary": "Collaborative Machine Learning is a paradigm in the field of distributed\nmachine learning, designed to address the challenges of data privacy,\ncommunication overhead, and model heterogeneity. There have been significant\nadvancements in optimization and communication algorithm design and ML hardware\nthat enables fair, efficient and secure collaborative ML training. However,\nless emphasis is put on collaborative ML infrastructure development. Developers\nand researchers often build server-client systems for a specific collaborative\nML use case, which is not scalable and reusable. As the scale of collaborative\nML grows, the need for a scalable, efficient, and ideally multi-tenant resource\nmanagement system becomes more pressing. We propose a novel system, Propius,\nthat can adapt to the heterogeneity of client machines, and efficiently manage\nand control the computation flow between ML jobs and edge resources in a\nscalable fashion. Propius is comprised of a control plane and a data plane. The\ncontrol plane enables efficient resource sharing among multiple collaborative\nML jobs and supports various resource sharing policies, while the data plane\nimproves the scalability of collaborative ML model sharing and result\ncollection. Evaluations show that Propius outperforms existing resource\nmanagement techniques and frameworks in terms of resource utilization (up to\n$1.88\\times$), throughput (up to $2.76$), and job completion time (up to\n$1.26\\times$).", "AI": {"tldr": "Propius\u662f\u4e00\u4e2a\u4e3a\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u8d44\u6e90\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u63a7\u5236\u5e73\u9762\u548c\u6570\u636e\u5e73\u9762\u5b9e\u73b0\u9ad8\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u548c\u8ba1\u7b97\u6d41\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u7387\u3001\u541e\u5410\u91cf\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u9762\u4e34\u6570\u636e\u9690\u79c1\u3001\u901a\u4fe1\u5f00\u9500\u548c\u6a21\u578b\u5f02\u6784\u6027\u7b49\u6311\u6218\uff0c\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u4e9f\u9700\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u79df\u6237\u8d44\u6e90\u7ba1\u7406\u6846\u67b6\u3002", "challenges": "\u5982\u4f55\u5728\u5f02\u6784\u5ba2\u6237\u7aef\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u8d44\u6e90\u5171\u4eab\u3001\u53ef\u6269\u5c55\u7684\u6a21\u578b\u5206\u53d1\u4e0e\u7ed3\u679c\u6536\u96c6\uff0c\u5e76\u652f\u6301\u591a\u79cd\u8d44\u6e90\u5206\u914d\u7b56\u7565\u3002", "contributions": "\u63d0\u51fa\u4e86Propius\u7cfb\u7edf\uff0c\u5305\u542b\u63a7\u5236\u5e73\u9762\uff08\u652f\u6301\u591a\u4efb\u52a1\u8d44\u6e90\u8c03\u5ea6\uff09\u548c\u6570\u636e\u5e73\u9762\uff08\u63d0\u5347\u901a\u4fe1\u6548\u7387\uff09\uff0c\u5b9e\u73b0\u4e86\u5bf9\u534f\u4f5cML\u4efb\u52a1\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7ba1\u7406\u3002", "results": "\u5b9e\u9a8c\u8868\u660e\uff0cPropius\u5728\u8d44\u6e90\u5229\u7528\u7387\u4e0a\u6700\u9ad8\u63d0\u53471.88\u500d\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53472.76\u500d\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u6700\u9ad8\u7f29\u77ed1.26\u500d\u3002", "conclusion": "Propius\u4e3a\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u652f\u6301\u591a\u79df\u6237\u7684\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u96c6\u4e2d\u5728\u534f\u4f5c\u673a\u5668\u5b66\u4e60\u7684\u4f18\u5316\u7b97\u6cd5\u3001\u901a\u4fe1\u8bbe\u8ba1\u548c\u786c\u4ef6\u652f\u6301\uff0c\u4f46\u5728\u7cfb\u7edf\u7ea7\u57fa\u7840\u8bbe\u65bd\u7279\u522b\u662f\u8d44\u6e90\u7ba1\u7406\u65b9\u9762\u7814\u7a76\u8f83\u5c11\u3002"}}
{"id": "2510.19805", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.19805", "abs": "https://arxiv.org/abs/2510.19805", "authors": ["Carl-Johan Fauvelle Munck af Rosensch\"old", "Feras M. Awaysheh", "Ahmad Awad"], "title": "Next Generation Cloud-native In-Memory Stores: From Redis to Valkey and Beyond", "comment": "10 pages, 5 figures, 2 algorithms, 4 tables", "summary": "In-memory key-value datastores have become indispensable building blocks of\nmodern cloud-native infrastructures, yet their evolution faces scalability,\ncompatibility, and sustainability constraints. The current literature lacks an\nexperimental evaluation of state-of-the-art tools in the domain. This study\naddressed this timely gap by benchmarking Redis alternatives and systematically\nevaluating Valkey, KeyDB, and Garnet under realistic workloads within\nKubernetes deployments. The results demonstrate clear trade-offs among the\nbenchmarked data systems. Our study presents a comprehensive performance and\nviability assessment of the emerging in-memory key-value stores. Metrics\ninclude throughput, tail latency, CPU and memory efficiency, and migration\ncomplexity. We highlight trade-offs between performance, compatibility, and\nlong-term viability, including project maturity, community support, and\nsustained development.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u73b0\u4ee3\u4e91\u539f\u751f\u73af\u5883\u4e2d\u5173\u952e\u7684\u5185\u5b58\u952e\u503c\u5b58\u50a8\u7cfb\u7edf\uff08Redis\u66ff\u4ee3\u54c1Valkey\u3001KeyDB\u548cGarnet\uff09\u8fdb\u884c\u4e86\u5728Kubernetes\u73af\u5883\u4e0b\u7684\u6027\u80fd\u4e0e\u53ef\u884c\u6027\u8bc4\u4f30\uff0c\u586b\u8865\u4e86\u5f53\u524d\u6587\u732e\u7684\u7a7a\u767d\u3002", "motivation": "\u5185\u5b58\u952e\u503c\u6570\u636e\u5b58\u50a8\u5df2\u6210\u4e3a\u73b0\u4ee3\u4e91\u539f\u751f\u57fa\u7840\u8bbe\u65bd\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u4f46\u5176\u53d1\u5c55\u9762\u4e34\u53ef\u6269\u5c55\u6027\u3001\u517c\u5bb9\u6027\u548c\u53ef\u6301\u7eed\u6027\u9650\u5236\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u6700\u65b0\u5de5\u5177\u7684\u5b9e\u9a8c\u6027\u8bc4\u4f30\u3002", "challenges": "\u5728Kubernetes\u73af\u5883\u4e2d\u8bc4\u4f30\u4e0d\u540c\u5185\u5b58\u952e\u503c\u5b58\u50a8\u7cfb\u7edf\u7684\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u957f\u671f\u53ef\u884c\u6027\uff0c\u540c\u65f6\u8861\u91cf\u541e\u5410\u91cf\u3001\u5c3e\u90e8\u5ef6\u8fdf\u3001\u8d44\u6e90\u6548\u7387\u548c\u8fc1\u79fb\u590d\u6742\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "contributions": "\u7cfb\u7edf\u6027\u5730\u6bd4\u8f83\u4e86Valkey\u3001KeyDB\u548cGarnet\u5728\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u8868\u73b0\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6027\u80fd\u3001\u8d44\u6e90\u5229\u7528\u548c\u9879\u76ee\u53ef\u6301\u7eed\u6027\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u586b\u8865\u4e86\u5f53\u524d\u7814\u7a76\u7684\u7a7a\u767d\u3002", "results": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5404\u7cfb\u7edf\u5728\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u957f\u671f\u53ef\u884c\u6027\u4e4b\u95f4\u7684\u660e\u663e\u6743\u8861\uff1b\u4f8b\u5982\uff0c\u67d0\u4e9b\u7cfb\u7edf\u5728\u541e\u5410\u91cf\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u5728\u5ef6\u8fdf\u6216\u8d44\u6e90\u6548\u7387\u65b9\u9762\u66f4\u5177\u4f18\u52bf\u3002", "conclusion": "\u4e0d\u540c\u7684Redis\u66ff\u4ee3\u65b9\u6848\u5404\u6709\u4f18\u52a3\uff0c\u9009\u62e9\u5e94\u57fa\u4e8e\u5177\u4f53\u5e94\u7528\u573a\u666f\u5bf9\u6027\u80fd\u3001\u517c\u5bb9\u6027\u548c\u9879\u76ee\u53ef\u6301\u7eed\u6027\u7684\u9700\u6c42\u3002", "related_work": "\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u4f20\u7edf\u6570\u636e\u5e93\u6216\u5355\u4e00\u7cfb\u7edf\u7684\u4f18\u5316\uff0c\u7f3a\u4e4f\u5bf9\u65b0\u5174\u5185\u5b58\u952e\u503c\u5b58\u50a8\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u5c24\u5176\u662f\u5728\u4e91\u539f\u751f\u548c\u5bb9\u5668\u5316\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u3002"}}
