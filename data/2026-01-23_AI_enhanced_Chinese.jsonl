{"id": "2601.14466", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14466", "abs": "https://arxiv.org/abs/2601.14466", "authors": ["Roeland Wiersema"], "title": "JAXMg: A multi-GPU linear solver in JAX", "comment": null, "summary": "Solving large dense linear systems and eigenvalue problems is a core requirement in many areas of scientific computing, but scaling these operations beyond a single GPU remains challenging within modern programming frameworks. While highly optimized multi-GPU solver libraries exist, they are typically difficult to integrate into composable, just-in-time (JIT) compiled Python workflows. JAXMg provides multi-GPU dense linear algebra for JAX, enabling Cholesky-based linear solves and symmetric eigendecompositions for matrices that exceed single-GPU memory limits. By interfacing JAX with NVIDIA's cuSOLVERMg through an XLA Foreign Function Interface, JAXMg exposes distributed GPU solvers as JIT-compatible JAX primitives. This design allows scalable linear algebra to be embedded directly within JAX programs, preserving composability with JAX transformations and enabling multi-GPU execution in end-to-end scientific workflows.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14608", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14608", "abs": "https://arxiv.org/abs/2601.14608", "authors": ["Torben R. Lahnor", "Mia Reitz", "Jonas Posner", "Patrick Diehl"], "title": "Exploring Performance-Productivity Trade-offs in AMT Runtimes: A Task Bench Study of Itoyori, ItoyoriFBC, HPX, and MPI", "comment": null, "summary": "Asynchronous Many-Task (AMT) runtimes offer a productive alternative to the Message Passing Interface (MPI). However, the diverse AMT landscape makes fair comparisons challenging. Task Bench, proposed by Slaughter et al., addresses this challenge through a parameterized framework for evaluating parallel programming systems. This work integrates two recent cluster AMTs, Itoyori and ItoyoriFBC, into Task Bench for comprehensive evaluation against MPI and HPX. Itoyori employs a Partitioned Global Address Space (PGAS) model with RDMA-based work stealing, while ItoyoriFBC extends it with futurebased synchronization.\n  We evaluate these systems in terms of both performance and programmer productivity. Performance is assessed across various configurations, including compute-bound kernels, weak scaling, and both imbalanced and communication-intensive patterns. Performance is quantified using application efficiency, i.e., the percentage of maximum performance achieved, and the Minimum Effective Task Granularity (METG), i.e., the smallest task duration before runtime overheads dominate. Programmer productivity is quantified using Lines of Code (LOC) and the Number of Library Constructs (NLC).\n  Our results reveal distinct trade-offs. MPI achieves the highest efficiency for regular, communication-light workloads but requires verbose, lowlevel code. HPX maintains stable efficiency under load imbalance across varying node counts, yet ranks last in productivity metrics, demonstrating that AMTs do not inherently guarantee improved productivity over MPI. Itoyori achieves the highest efficiency in communication-intensive configurations while leading in programmer productivity. ItoyoriFBC exhibits slightly lower efficiency than Itoyori, though its future-based synchronization offers potential for expressing irregular workloads.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14612", "categories": ["cs.DC", "cs.NI", "cs.PF", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14612", "abs": "https://arxiv.org/abs/2601.14612", "authors": ["Neelkamal Bhuyan", "Randeep Bhatia", "Murali Kodialam", "TV Lakshman"], "title": "Exploiting Spot Instances for Time-Critical Cloud Workloads Using Optimal Randomized Strategies", "comment": "Accepted for publication in the 45th IEEE International Conference on Computer Communications (INFOCOM 2026). Copyright 2026 IEEE", "summary": "This paper addresses the challenge of deadline-aware online scheduling for jobs in hybrid cloud environments, where jobs may run on either cost-effective but unreliable spot instances or more expensive on-demand instances, under hard deadlines. We first establish a fundamental limit for existing (predominantly-) deterministic policies, proving a worst-case competitive ratio of $\u03a9(K)$, where $K$ is the cost ratio between on-demand and spot instances. We then present a novel randomized scheduling algorithm, ROSS, that achieves a provably optimal competitive ratio of $\\sqrt{K}$ under reasonable deadlines, significantly improving upon existing approaches. Extensive evaluations on real-world trace data from Azure and AWS demonstrate that ROSS effectively balances cost optimization and deadline guarantees, consistently outperforming the state-of-the-art by up to $30\\%$ in cost savings, across diverse spot market conditions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14480", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.14480", "abs": "https://arxiv.org/abs/2601.14480", "authors": ["Egemen Erbayat", "Gustavo B. Figueiredo", "Shih-Chun Lin", "Motoharu Matsuura", "Hiroshi Hasegawa", "Suresh Subramaniam"], "title": "A benchmarking framework for PON-based fronthaul network design", "comment": null, "summary": "As mobile networks transition toward 5G and 6G RAN architectures, Passive Optical Networks (PONs) offer a critical solution for cost-effective fronthaul transport. However, the lack of standardized evaluation models in current literature makes an objective comparison of diverse optimization strategies difficult. This paper addresses this gap by proposing a unified benchmarking framework that standardizes cost catalogs and deployment scenarios. We formulate the network design problem using Integer Linear Programming (ILP) to establish optimality bounds and evaluate three scalable heuristic strategies: a Genetic Algorithm, K-Means Clustering (KMC+), and a graph-based Randomized Successive Splitter Assignment (RSSA+) algorithm. Simulation results show that a time-limited ILP remains a strong reference point, even when optimality is not reached. Despite being rarely used in prior fronthaul planning studies, it consistently yields solutions superior to those produced by standard heuristic methods. Among scalable approaches, RSSA+ reliably attains near-ILP performance while ensuring feasibility across all evaluated scenarios, which underscores the importance of advanced, constraint-aware algorithmic designs over simpler heuristics. The complete benchmarking framework and datasets are publicly shared in [1].", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14260", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14260", "abs": "https://arxiv.org/abs/2601.14260", "authors": ["Xiaoxuan Yang", "Peilin Chen", "Tergel Molom-Ochir", "Yiran Chen"], "title": "End-to-End Transformer Acceleration Through Processing-in-Memory Architectures", "comment": "ICM 2025", "summary": "Transformers have become central to natural language processing and large language models, but their deployment at scale faces three major challenges. First, the attention mechanism requires massive matrix multiplications and frequent movement of intermediate results between memory and compute units, leading to high latency and energy costs. Second, in long-context inference, the key-value cache (KV cache) can grow unpredictably and even surpass the model's weight size, creating severe memory and bandwidth bottlenecks. Third, the quadratic complexity of attention with respect to sequence length amplifies both data movement and compute overhead, making large-scale inference inefficient. To address these issues, this work introduces processing-in-memory solutions that restructure attention and feed-forward computation to minimize off-chip data transfers, dynamically compress and prune the KV cache to manage memory growth, and reinterpret attention as an associative memory operation to reduce complexity and hardware footprint. Moreover, we evaluate our processing-in-memory design against state-of-the-art accelerators and general-purpose GPUs, demonstrating significant improvements in energy efficiency and latency. Together, these approaches address computation overhead, memory scalability, and attention complexity, further enabling efficient, end-to-end acceleration of Transformer models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14642", "categories": ["cs.DC", "cs.LO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14642", "abs": "https://arxiv.org/abs/2601.14642", "authors": ["Guillaume Ambal", "Max Stupple", "Brijesh Dongol", "Azalea Raad"], "title": "Specifying and Verifying RDMA Synchronisation (Extended Version)", "comment": "95 pages, extended version of ESOP 2026 paper", "summary": "Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\\text{RDMA}^\\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\\text{RDMA}^{\\text{TSO}}_{\\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$ library. Underpinned by $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\\text{RDMA}^{\\text{SC}}_{\\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14883", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.14883", "abs": "https://arxiv.org/abs/2601.14883", "authors": ["Francesco Rossato", "Mattia Figaro", "Alessandro Traspadini", "Takayuki Shimizu", "Chinmay Mahabal", "Sanjeewa Herath", "Chunghan Lee", "Dogan Kutay Pekcan", "Michele Zorzi", "Marco Giordani"], "title": "5G NR Non-Terrestrial Networks: Open Challenges for Full-Stack Protocol Design", "comment": "8 pages, 4 figures, 1 table, This article has been submitted to IEEE for publication. Copyright may change without notice", "summary": "As 5th generation (5G) networks continue to evolve, there is a growing interest toward the integration of Terrestrial Networks (TNs) and Non-Terrestrial Networks (NTNs). Specifically, NTNs leverage space/air base stations such as satellites, High Altitude Platforms (HAPs), and Unmanned Aerial Vehicles (UAVs) for expanding wireless coverage to underserved rural/remote areas, supporting emergency communications, and offloading traffic in highly congested urban environments. In this paper we focus on the 3GPP 5G NR-NTN standard in the context of satellite communication networks, and highlight critical challenges that must be addressed for proper full-stack protocol design, with considerations related to the PHY, MAC, and higher layers. We also present simulation results in ns-3 to demonstrate the impact of some of these challenges on the network, as an initial step toward more advanced standardization activities on 3GPP 5G NR-NTN.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14347", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.14347", "abs": "https://arxiv.org/abs/2601.14347", "authors": ["George Rafael Gourdoumanis", "Fotoini Oikonomou", "Maria Pantazi-Kypraiou", "Pavlos Stoikos", "Olympia Axelou", "Athanasios Tziouvaras", "Georgios Karakonstantis", "Tahani Aladwani", "Christos Anagnostopoulos", "Yixian Shen", "Anuj Pathania", "Alberto Garcia-Ortiz", "George Floros"], "title": "Multi-Partner Project: COIN-3D -- Collaborative Innovation in 3D VLSI Reliability", "comment": "DATE 2026", "summary": "As semiconductor manufacturing advances from the 3-nm process toward the sub-nanometer regime and transitions from FinFETs to gate-all-around field-effect transistors (GAAFETs), the resulting complexity and manufacturing challenges continue to increase. In this context, 3D chiplet-based approaches have emerged as key enablers to address these limitations while exploiting the expanded design space. Specifically, chiplets help address the lower yields typically associated with large monolithic designs. This paradigm enables the modular design of heterogeneous systems consisting of multiple chiplets (e.g., CPUs, GPUs, memory) fabricated using different technology nodes and processes. Consequently, it offers a capable and cost-effective strategy for designing heterogeneous systems. This paper introduces the Horizon Europe Twinning project COIN-3D (Collaborative Innovation in 3D VLSI Reliability), which aims to strengthen research excellence in 2.5D/3D VLSI systems reliability through collaboration between leading European institutions. More specifically, our primary scientific goal is the provision of novel open-source Electronic Design Automation (EDA) tools for reliability assessment of 3D systems, integrating advanced algorithms for physical- and system-level reliability analysis.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14735", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14735", "abs": "https://arxiv.org/abs/2601.14735", "authors": ["Varad Kulkarni", "Vaibhav Jha", "Nikhil Reddy", "Yogesh Simmhan"], "title": "Optimizing FaaS Platforms for MCP-enabled Agentic Workflows", "comment": null, "summary": "Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.15103", "categories": ["cs.NI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2601.15103", "abs": "https://arxiv.org/abs/2601.15103", "authors": ["Erwin J. Sacoto-Cabrera", "Luis Guijarro", "Jose R. Vidal", "Vicent Pla"], "title": "Economic feasibility of virtual operators in 5G via network slicing", "comment": null, "summary": "The provision of services by more than one operator over a common network infrastructure, as enabled by 5G network slicing, is analyzed. Two business models to be implemented by a network operator, who owns the network, and a virtual operator, who does not, are proposed. In one business model, named \\emph{strategic}, the network operator provides service to its user base and the virtual operator provides service to its user base and pays a per-subscriber fee to the network operator. In the other business model, named \\emph{monopolistic}, the network operator provides service to both user bases. The two proposals are analyzed by means of a model that captures both system and economic features. As regards the systems features, the slicing of the network is modeled by means of a Discriminatory Processor Sharing queue. As regards the economic features, the incentives are modeled by means of the user utilities and the operators' revenues; and game theory is used to model the strategic interaction between the users' subscription decision and the operators' pricing decision. In both business models, it is shown that the network operator can be provided with the appropriate economic incentives so that it acquiesces in serving the virtual operator's user base (monopolistic model) and in allowing the virtual operator to provide service over the network operator's infrastructure (strategic model). From the point of view of the users, the strategic model results in a higher subscription rate than the monopolistic model.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.15151", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.15151", "abs": "https://arxiv.org/abs/2601.15151", "authors": ["Jean Bruant", "Pierre-Henri Horrein", "Olivier Muller", "Fr\u00e9d\u00e9ric P\u00e9trot"], "title": "Pipeline Automation Framework for Reusable High-throughput Network Applications on FPGA", "comment": "29 pages, 10 listings, 5 tables", "summary": "In a context of ever-growing worldwide communication traffic, cloud service providers aim at deploying scalable infrastructures to address heterogeneous needs. Part of the network infrastructure, FPGAs are tailored to guarantee low-latency and high-throughput packet processing. However, slowness of the hardware design process impairs FPGA ability to be part of an agile infrastructure under constant evolution, from incident response to long-term transformation. Deploying and maintaining network functionalities across a wide variety of FPGAs raises the need to fine-tune hardware designs for several FPGA targets. To address this issue, we introduce PAF, an open-source architectural parameterization framework based on a pipeline-oriented design methodology. PAF (Pipeline Automation Framework) implementation is based on Chisel, a Scala-embedded Hardware Construction Language (HCL), that we leverage to interface with circuit elaboration. Applied to industrial network packet classification systems, PAF demonstrates efficient parameterization abilities, enabling to reuse and optimize the same pipelined design on several FPGAs. In addition, PAF focuses the pipeline description on the architectural intent, incidentally reducing the number of lines of code to express complex functionalities. Finally, PAF confirms that automation does not imply any loss of tight control on the architecture by achieving on par performance and resource usage with equivalent exhaustively described implementations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14912", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14912", "abs": "https://arxiv.org/abs/2601.14912", "authors": ["Guangba Yu", "Genting Mai", "Rui Wang", "Ruipeng Li", "Pengfei Chen", "Long Pan", "Ruijie Xu"], "title": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems", "comment": "Accepted by ASE 2025", "summary": "Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8\\% alert reduction ratios) and accelerates fault diagnosis (90.5\\% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2601.14923", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14923", "abs": "https://arxiv.org/abs/2601.14923", "authors": ["Kaddour Sidi", "Daniel Balouek", "Baptiste Jonglez"], "title": "Application-level observability for adaptive Edge to Cloud continuum systems", "comment": "UCC 2025 - IEEE/ACM 18th International Conference on Utility and Cloud Computing, Dec 2025, NANTES, France", "summary": "Modern Edge-to-Cloud (E2C) systems require fine-grained observability to ensure adaptive behavior and compliance with performance objectives across heterogeneous and dynamic environments. This work introduces an application-level observability framework that integrates developer-driven instrumentation and SLO-aware feedback for autonomous adaptation. By combining OpenTelemetry, Prometheus, K3s, and Chaos Mesh, the framework enables real-time monitoring and adaptive control across the continuum. A video processing use case demonstrates how application-level metrics guide automatic adjustments to maintain target frame rate, latency, and detection accuracy under variable workloads and injected faults. Preliminary results highlight improved scalability, fault tolerance, and responsiveness, providing a practical foundation for adaptive, SLO-compliant E2C applications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
