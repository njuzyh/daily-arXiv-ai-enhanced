{"id": "2512.02278", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02278", "abs": "https://arxiv.org/abs/2512.02278", "authors": ["Yi Liu", "Chen Qian"], "title": "Fantasy: Efficient Large-scale Vector Search on GPU Clusters with GPUDirect Async", "comment": null, "summary": "Vector similarity search has become a critical component in AI-driven applications such as large language models (LLMs). To achieve high recall and low latency, GPUs are utilized to exploit massive parallelism for faster query processing. However, as the number of vectors continues to grow, the graph size quickly exceeds the memory capacity of a single GPU, making it infeasible to store and process the entire index on a single GPU. Recent work uses CPU-GPU architectures to keep vectors in CPU memory or SSDs, but the loading step stalls GPU computation. We present Fantasy, an efficient system that pipelines vector search and data transfer in a GPU cluster with GPUDirect Async. Fantasy overlaps computation and network communication to significantly improve search throughput for large graphs and deliver large query batch sizes.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02300", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02300", "abs": "https://arxiv.org/abs/2512.02300", "authors": ["Haoyu Zheng", "Shouwei Gao", "Jie Ren", "Wenqian Dong"], "title": "DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications", "comment": null, "summary": "Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant challenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while providing quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging disaggregated memory in HPC domains while minimally compromising application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degradation to less than 16% while reducing local memory usage by up to 63%, on average.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02546", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02546", "abs": "https://arxiv.org/abs/2512.02546", "authors": ["Jan Meizner", "Maciej Malawski"], "title": "Solutions for Distributed Memory Access Mechanism on HPC Clusters", "comment": null, "summary": "Paper presents and evaluates various mechanisms for remote access to memory in distributed systems based on two distinct HPC clusters. We are comparing solutions based on the shared storage and MPI (over Infiniband and Slingshot) to the local memory access. This paper also mentions medical use-cases that would mostly benefit from the described solution. We have found out that results for remote access esp. backed by MPI are similar to local memory access.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02646", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02646", "abs": "https://arxiv.org/abs/2512.02646", "authors": ["Alex Barcel\u00f3", "Sebasti\u00e1n A. Cajas Ordo\u00f1ez", "Jaydeep Samanta", "Andr\u00e9s L. Su\u00e1rez-Cetrulo", "Romila Ghosh", "Ricardo Sim\u00f3n Carbajo", "Anna Queralt"], "title": "Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems", "comment": "17 pages, 7 tables, 12 figures", "summary": "The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution.\n  By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers.\n  This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02189", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02189", "abs": "https://arxiv.org/abs/2512.02189", "authors": ["Aaron Jarmusch", "Sunita Chandrasekaran"], "title": "Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis", "comment": null, "summary": "As GPU architectures rapidly evolve to meet the overcoming demands of exascale computing and machine learning, the performance implications of architectural innovations remain poorly understood across diverse workloads. NVIDIA's Blackwell (B200) generation introduce significant architectural advances including the 5th generation tensor cores, tensor memory (TMEM), decompression engine (DE), and dual chips; however systematic methodologies for quantifying these improvements lag behind hardware development cycles. We contribute an open-source microbenchmark suite that offers practical insights into optimizing workloads to fully utilize the rich feature sets of the modern GPU architecture. This work aims to enable application developers make informed architectural decisions and guide future GPU design directions.\n  Our work studies Blackwell GPUs, compares them to H200 generation with regards to the memory subsystem, tensor core pipeline and floating-point precisions (FP32, FP16, FP8, FP6, FP4). Our systematic evaluation of dense/sparse GEMM, transformer inference, and training workloads demonstrate that B200's tensor core enhancements achieves 1.56x higher mixed-precision throughput and 42% better energy efficiency than H200. Our memory analysis reveals 58% reduction in memory access latency in cache-misses, fundamentally changing optimal algorithm design strategies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02272", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02272", "abs": "https://arxiv.org/abs/2512.02272", "authors": ["Ali Diab", "Adel Chehade", "Edoardo Ragusa", "Paolo Gastaldo", "Rodolfo Zunino", "Amer Baghdadi", "Mostafa Rizk"], "title": "Intrusion Detection on Resource-Constrained IoT Devices with Hardware-Aware ML and DL", "comment": "Accepted at the 2025 IEEE International Conference on Emerging Trends in Engineering and Computing (ETECOM). Recipient of the ETECOM 2025 Best Paper Award", "summary": "This paper proposes a hardware-aware intrusion detection system (IDS) for Internet of Things (IoT) and Industrial IoT (IIoT) networks; it targets scenarios where classification is essential for fast, privacy-preserving, and resource-efficient threat detection. The goal is to optimize both tree-based machine learning (ML) models and compact deep neural networks (DNNs) within strict edge-device constraints. This allows for a fair comparison and reveals trade-offs between model families. We apply constrained grid search for tree-based classifiers and hardware-aware neural architecture search (HW-NAS) for 1D convolutional neural networks (1D-CNNs). Evaluation on the Edge-IIoTset benchmark shows that selected models meet tight flash, RAM, and compute limits: LightGBM achieves 95.3% accuracy using 75 KB flash and 1.2 K operations, while the HW-NAS-optimized CNN reaches 97.2% with 190 KB flash and 840 K floating-point operations (FLOPs). We deploy the full pipeline on a Raspberry Pi 3 B Plus, confirming that tree-based models operate within 30 ms and that CNNs remain suitable when accuracy outweighs latency. These results highlight the practicality of hardware-constrained model design for real-time IDS at the edge.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02683", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02683", "abs": "https://arxiv.org/abs/2512.02683", "authors": ["Luiz A. Rodrigues", "Elias P. Duarte", "Luciana Arantes"], "title": "Distributed and Autonomic Minimum Spanning Trees", "comment": "This preprint is an English translation and slightly extended version of the paper published in Portuguese at the 32nd Brazilian Symposium on Computer Networks and Distributed Systems (2014), reference [1]", "summary": "The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02346", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02346", "abs": "https://arxiv.org/abs/2512.02346", "authors": ["Hongyang Shang", "An Guo", "Shuai Dong", "Junyi Yang", "Ye Ke", "Arindam Basu"], "title": "Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras", "comment": null, "summary": "Event-based Cameras (EBCs) are widely utilized in surveillance and autonomous driving applications due to their high speed and low power consumption. Corners are essential low-level features in event-driven computer vision, and novel algorithms utilizing event-based representations, such as Threshold-Ordinal Surface (TOS), have been developed for corner detection. However, the implementation of these algorithms on resource-constrained edge devices is hindered by significant latency, undermining the advantages of EBCs. To address this challenge, a near-memory architecture for efficient TOS updates (NM-TOS) is proposed. This architecture employs a read-write decoupled 8T SRAM cell and optimizes patch update speed through pipelining. Hardware-software co-optimized peripheral circuits and dynamic voltage and frequency scaling (DVFS) enable power and latency reductions. Compared to traditional digital implementations, our architecture reduces latency/energy by 24.7x/1.2x at Vdd = 1.2 V or 1.93x/6.6x at Vdd = 0.6 V based on 65nm CMOS process. Monte Carlo simulations confirm robust circuit operation, demonstrating zero bit error rate at operating voltages above 0.62 V, with only 0.2% at 0.61 V and 2.5% at 0.6 V. Corner detection evaluation using precision-recall area under curve (AUC) metrics reveals minor AUC reductions of 0.027 and 0.015 at 0.6 V for two popular EBC datasets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02818", "categories": ["cs.DC", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.02818", "abs": "https://arxiv.org/abs/2512.02818", "authors": ["Sean R. Wilkinson", "Patrick Widener", "Sarp Oral", "Rafael Ferreira da Silva"], "title": "Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science", "comment": null, "summary": "High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02297", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.02297", "abs": "https://arxiv.org/abs/2512.02297", "authors": ["Philip Rodgers", "Paul Harvey"], "title": "The xApp Store: A Framework for xApp Onboarding and Deployment in O-RAN", "comment": "Accepted to ANMS'25", "summary": "5G and beyond mobile telecommunication networks are increasingly embracing software technologies in their operation and control, similar to what has powered the growth of the cloud. This is most recently seen in the radio access network (RAN). In this new approach, the RAN is increasingly controlled by software applications known as xApps, and opens the door to third party development of xApps bringing diversity to the ecosystem, similar to mobile phone apps. This model aligns closely with the controllers in the ITU-T architecture for autonomous networks, and provides a pathway towards autonomous operation in the RAN. Unfortunately, no marketplace to host or supply xApps currently exists.\n  This work describes our experiences in leveraging open-source O-RAN implementations to design and develop an xApp store.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02875", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02875", "abs": "https://arxiv.org/abs/2512.02875", "authors": ["Cristian Tirelli", "Lorenzo Ferretti", "Laura Pozzi"], "title": "SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures", "comment": null, "summary": "Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.\n  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \\textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.\n  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02347", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02347", "abs": "https://arxiv.org/abs/2512.02347", "authors": ["Anjali Yadav", "Arya Agarwal", "Alok Kumar", "Tushar S. Muratkar", "Gaurav S. Kasbekar"], "title": "Coalitional Game Framework for Multicast in Wireless Networks", "comment": null, "summary": "We consider a wireless network in which there is a transmitter and a set of users, all of whom want to download a popular file from the transmitter. Using the framework of cooperative game theory, we investigate conditions under which users have incentives to cooperate among themselves to form coalitions for the purpose of receiving the file via multicast from the transmitter. First, using the solution concept of core, we investigate conditions under which it is beneficial for all users to cooperate, i.e., the grand coalition is stable. We provide several sets of sufficient conditions under which the core is non-empty as well as those under which the core is empty. Next, we use the concept of $\\mathbb{D}_c$-stability to identify a set of sufficient conditions under which the users in the network form a certain fixed number of coalitions such that all the users within each coalition cooperate among themselves. Our analytical results show how the values of different system parameters, e.g., data rates of different users, transmit and receive power, file size, bandwidth cost, etc., influence stability properties of coalitions, and provide a systematic approach to evaluating cooperation of users for multicast. We also study cooperation among different users using numerical computations. The problem of coalition formation in the context of multicast addressed in this paper is fundamental, and our analysis provides new insights into the feasibility of stable cooperative multicast strategies, contributing to a deeper understanding of cooperation in wireless networks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02884", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02884", "abs": "https://arxiv.org/abs/2512.02884", "authors": ["Cristian Tirelli", "Laura Pozzi"], "title": "Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver", "comment": null, "summary": "Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02370", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02370", "abs": "https://arxiv.org/abs/2512.02370", "authors": ["Hongyang Pan", "Bin Lin", "Yanheng Liu", "Shuang Liang", "Chau Yuen"], "title": "Diffusion-Model-enhanced Multiobjective Optimization for Improving Forest Monitoring Efficiency in UAV-enabled Internet-of-Things", "comment": null, "summary": "The Internet-of-Things (IoT) is widely applied for forest monitoring, since the sensor nodes (SNs) in IoT network are low-cost and have computing ability to process the monitoring data. To further improve the performance of forest monitoring, uncrewed aerial vehicles (UAVs) are employed as the data processors to enhance computing capability. However, efficient forest monitoring with limited energy budget and computing resource presents a significant challenge. For this purpose, this paper formulates a multi-objective optimization framework to simultaneously consider three optimization objectives, which are minimizing the maximum computing delay, minimizing the total motion energy consumption, and minimizing the maximum computing resource, corresponding to efficient forest monitoring, energy consumption reduction, and computing resource control, respectively. Due to the hybrid solution space that consists of continuous and discrete solutions, we propose a diffusion model-enhanced improved multi-objective grey wolf optimizer (IMOGWO) to solve the formulated framework. The simulation results show that the proposed IMOGWO outperforms other benchmarks for solving the formulated framework. Specifically, for a small-scale network with $6$ UAVs and $50$ SNs, compared to the suboptimal benchmark, IMOGWO reduces the motion energy consumption and the computing resource by $53.32\\%$ and $9.83\\%$, respectively, while maintaining computing delay at the same level. Similarly, for a large-scale network with $8$ UAVs and $100$ SNs, IMOGWO achieves reductions of $41.81\\%$ in motion energy consumption and $7.93\\%$ in computing resource, with the computing delay also remaining comparable.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02398", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02398", "abs": "https://arxiv.org/abs/2512.02398", "authors": ["Zhiyu Zhou", "Xin Zhe Khooi", "Satis Kumar Permal", "Mun Choon Chan"], "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs", "comment": "9 pages, 12 figures", "summary": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02454", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02454", "abs": "https://arxiv.org/abs/2512.02454", "authors": ["Gianluca Cena", "Pietro Chiavassa", "Gabriele Formis", "Stefano Scanzio"], "title": "Widening the Coverage of Reference Broadcast Infrastructure Synchronization in Wi-Fi Networks", "comment": "preprint accepted, 8 pages, 2025", "summary": "Precise clock synchronization protocols are increasingly used to ensure that all the nodes in a network share the very same time base. They enable several mechanisms aimed at improving determinism at both the application and communication levels, which makes them highly relevant to industrial environments. Reference Broadcast Infrastructure Synchronization (RBIS) is a solution specifically conceived for Wi-Fi that exploits existing beacons and can run on commercial devices. In this paper, an evolution of RBIS is presented, we call DOMINO, whose coverage area is much larger than the single Wi-Fi infrastructure network, potentially including the whole plant. In particular, wireless stations that can see more than one access point at the same time behave as boundary clocks and propagate the reference time across overlapping networks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02455", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02455", "abs": "https://arxiv.org/abs/2512.02455", "authors": ["Pietro Chiavassa", "Stefano Scanzio", "Gianluca Cena"], "title": "Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments", "comment": "preprint accepted, 4 pages, 2025", "summary": "Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02649", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02649", "abs": "https://arxiv.org/abs/2512.02649", "authors": ["Sameera Bandaranayake", "Amirreza Moradi", "Tanja Suomalainen", "Harri Saarnisaari", "Pasi Karppinen", "Payal Gupta", "Jaap van de Beek"], "title": "Rural Connectivity Inequalities in Finland and Sweden: Evidence, Measures, and Policy Reflections", "comment": null, "summary": "Persistent rural-urban disparities in broadband connectivity remain a major policy challenge, even in digitally advanced countries. This paper examines how these inequalities manifest in northern Finland and Sweden, where sparse populations, long distances, and seasonal variations in demand create persistent gaps in service quality and reliability. Drawing on survey data (n = 148), in-depth interviews, and spatial analysis, the study explores the lived experience of connectivity in Arctic rural communities and introduces a novel Cellular Coverage Inequality (CCI) Index. The index combines measures of rurality and network performance to quantify spatial disparities that are masked by national coverage statistics. Results reveal that headline indicators overstate inclusiveness, while local users report chronic connectivity gaps affecting work, safety, and access to services. Building on these findings, the paper outlines policy reflections in six areas: shared infrastructure and roaming frameworks, spectrum flexibility for rural operators, performance-based Quality-of-Service monitoring, standardized and transparent reporting, temporal and seasonal capacity management, and digital-skills initiatives. Together, these recommendations highlight the need for multidimensional metrics and governance mechanisms that link technical performance, spatial equity, and user experience. The analysis contributes to ongoing debates on how broadband policy in sparsely populated regions can move beyond nominal coverage targets toward genuine inclusion and reliability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02843", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02843", "abs": "https://arxiv.org/abs/2512.02843", "authors": ["Israel Leyva-Mayorga", "Shashi Raj Pandey", "Petar Popovski", "Fabio Saggese", "Beatriz Soret", "Cedomir Stefanovic"], "title": "ISAC-Powered Distributed Matching and Resource Allocation in Multi-band NTN", "comment": "Accepted for publication in Proc. Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Scalability is a major challenge in non-geostationary orbit (NGSO) satellite networks due to the massive number of ground users sharing the limited sub-6 GHz spectrum. Using K- and higher bands is a promising alternative to increase the accessible bandwidth, but these bands are subject to significant atmospheric attenuation, notably rainfall, which can lead to degraded performance and link outages. We present an integrated sensing and communications (ISAC)-powered framework for resilient and efficient operation of multi-band satellite networks. It is based on distributed mechanisms for atmospheric sensing, cell-to-satellite matching, and resource allocation (RA) in a 5G Non-Terrestrial Network (NTN) wide-area scenario with quasi-Earth fixed cells and a beam hopping mechanism. Results with a multi-layer multi-band constellation with satellites operating in the S- and K-bands demonstrate the benefits of our framework for ISAC-powered multi-band systems, which achieves 73% higher throughput per user when compared to single S- and K-band systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2512.02861", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02861", "abs": "https://arxiv.org/abs/2512.02861", "authors": ["Oscar G. Lira", "Oscar M. Caicedo", "Nelson L. S. Da Fonseca"], "title": "Network Self-Configuration based on Fine-Tuned Small Language Models", "comment": "16 pages, 11 figures, 3 tables", "summary": "As modern networks grow in scale and complexity, manual configuration becomes increasingly inefficient and prone to human error. While intent-driven self-configuration using large language models has shown significant promise, such models remain computationally expensive, resource-intensive, and often raise privacy concerns because they typically rely on external cloud infrastructure. This work introduces SLM_netconfig, a fine-tuned small language model framework that uses an agent-based architecture and parameter-efficient adaptation techniques to translate configuration intents expressed as natural language requirements or questions into syntactically and semantically valid network configurations. The system is trained on a domain-specific dataset generated through a pipeline derived from vendor documentation, ensuring strong alignment with real-world configuration practices. Extensive evaluation shows that SLM_netconfig, when using its question-to-configuration model, achieves higher syntactic accuracy and goal accuracy than LLM-NetCFG while substantially reducing translation latency and producing concise, interpretable configurations. These results demonstrate that fine-tuned small language models, as implemented in SLM_netconfig, can deliver efficient, accurate, and privacy-preserving automated configuration generation entirely on-premise, making them a practical and scalable solution for modern autonomous network configuration.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
