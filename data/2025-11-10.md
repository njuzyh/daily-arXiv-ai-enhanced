<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Marionette: Data Structure Description and Management for Heterogeneous Computing](https://arxiv.org/abs/2511.04853)
*Nuno dos Santos Fernandes,Pedro Tomás,Nuno Roma,Frank Winklmeier,Patricia Conde-Muíño*

Main category: cs.DC

TL;DR: Marionette是一个C++17库，通过在编译时抽象实现数据结构布局与接口的解耦，支持多种内存管理策略和高效设备间数据传输，从而简化大型C++代码库在异构平台（如GPU）上的硬件加速适应。


<details>
  <summary>Details</summary>
Motivation: 大型面向对象的C++代码库在迁移到GPU等异构硬件平台时面临数据布局和内存管理的复杂性，缺乏灵活性和可移植性，导致开发效率低和性能瓶颈。

Challenges: 如何在保持低运行时开销的同时，实现数据结构的灵活布局、跨设备高效数据传输，并兼容现有C++代码。

Contributions: 提出了Marionette库，实现了编译时的数据结构抽象，解耦接口与数据布局，支持多种内存管理策略和设备间高效转换，同时保持与现有代码的兼容性。

Results: 通过基于CUDA的案例研究，验证了Marionette在性能和灵活性方面的优势，展示了其在实际应用中的高效性和可移植性。

Conclusion: Marionette有效解决了C++代码在异构平台上硬件加速的适配难题，提供了一种高效、灵活且低开销的解决方案，适用于从简单到复杂的多种使用场景。

Related Work: 相关工作包括其他C++库和框架，如Thrust、SYCL和Kokkos，它们也致力于提升C++在异构计算中的性能和可移植性，但Marionette通过编译时抽象和接口扩展机制提供了更高的灵活性和更低的运行时开销。

Abstract: Adapting large, object-oriented C++ codebases for hardware acceleration might
be extremely challenging, particularly when targeting heterogeneous platforms
such as GPUs. Marionette is a C++17 library designed to address this by
enabling flexible, efficient, and portable data structure definitions. It
decouples data layout from the description of the interface, supports multiple
memory management strategies, and provides efficient data transfers and
conversions across devices, all of this with minimal runtime overhead due to
the compile-time nature of its abstractions. By allowing interfaces to be
augmented with arbitrary functions, Marionette maintains compatibility with
existing code and offers a streamlined interface that supports both
straightforward and advanced use cases. This paper outlines its design, usage,
and performance, including a CUDA-based case study demonstrating its efficiency
and flexibility.

</details>


### [2] [GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters](https://arxiv.org/abs/2511.05067)
*Giuseppe Esposito,Juan-David Guerrero-Balaguera,Josie Esteban Rodriguez Condia,Matteo Sonza Reorda,Marco Barbiero,Rossella Fortuna*

Main category: cs.DC

TL;DR: 本文提出了一种结合在线遥测参数和硬件性能计数器来评估GPU在不同应用下所承受压力的方法，以预测其可靠性，特别是老化效应。


<details>
  <summary>Details</summary>
Motivation: 由于持续工作负载可能对GPU组件造成显著压力，引发可靠性问题，因此需要有效评估GPU压力以预测潜在故障。

Challenges: 如何准确估计并量化由并行工作负载引起的GPU压力，特别是与老化相关的长期可靠性问题。

Contributions: 提出了一种结合遥测数据和性能计数器（如吞吐量、指令数量和停顿事件）评估GPU压力的新方法，并通过实验验证了其有效性。

Results: 实验结果表明，通过结合遥测数据和关键性能计数器可以有效估计GPU在不同应用下的压力水平。

Conclusion: 该方法能够有效评估GPU在运行计算密集型应用时的压力，有助于预测其可靠性，特别是在老化效应方面的表现。

Related Work: 已有研究利用性能计数器或遥测数据单独分析GPU行为，但缺乏将两者结合用于可靠性预测的工作。

Abstract: Graphics Processing Units (GPUs) are specialized accelerators in data centers
and high-performance computing (HPC) systems, enabling the fast execution of
compute-intensive applications, such as Convolutional Neural Networks (CNNs).
However, sustained workloads can impose significant stress on GPU components,
raising reliability concerns due to potential faults that corrupt the
intermediate application computations, leading to incorrect results. Estimating
the stress induced by an application is thus crucial to predict reliability
(with\,special\,emphasis\,on\,aging\,effects). In this work, we combine online
telemetry parameters and hardware performance counters to assess GPU stress
induced by different applications. The experimental results indicate the stress
induced by a parallel workload can be estimated by combining telemetry data and
Performance Counters that reveal the efficiency in the resource usage of the
target workload. For this purpose the selected performance counters focus on
measuring the i) throughput, ii) amount of issued instructions and iii) stall
events.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [3] [Eliminating the Hidden Cost of Zone Management in ZNS SSDs](https://arxiv.org/abs/2511.04687)
*Teona Bagashvili,Tarikul Islam Papon,Subhadeep Sarkar,Manos Athanassoulis*

Main category: cs.AR

TL;DR: SilentZNS提出了一种新的ZNS SSD管理方法，通过动态分配资源、避免不必要的写入和优化磨损均衡，显著降低了设备级写入放大、设备磨损，并提升了执行性能。


<details>
  <summary>Details</summary>
Motivation: 现有的ZNS SSD存在设备级写入放大（DLWA）、增加磨损和主机I/O干扰等问题，主要源于固定物理区域和全区域操作的设计缺陷，因此需要一种更高效的区域映射与管理机制。

Challenges: 如何在保持并行性的同时，消除因固定物理区域和全区域操作导致的过度物理写入；如何减少设备级写入放大和磨损；如何避免区域重置时的无效写入（dummy writes）并对主机I/O造成最小干扰。

Contributions: 提出了SilentZNS，一种灵活的区域分配方案，摒弃了传统的逻辑到物理区域映射方式，支持将任意块集合分配给一个区域；实现了按需分配块以避免重置时的无效写入；保证了良好的磨损均衡和读取性能。

Results: 在ConfZNS++模拟器上的实验表明，SilentZNS最多可减少20倍的无效写入，在10%区域占用率下设备级写入放大降低86%，总体磨损减少高达76.9%，工作负载执行速度提升最高达3.7倍。

Conclusion: SilentZNS通过动态、灵活的区域管理机制有效解决了当前ZNS SSD中存在的写入放大、磨损和效率问题，在保持高性能的同时显著提升了设备寿命和系统效率。

Related Work: 相关工作包括ZNS SSD的设计理念、ConfZNS++模拟器以及现有ZNS实现中的区域管理机制，如固定大小区域划分和全区域操作带来的性能瓶颈。

Abstract: Zoned Namespace (ZNS) SSDs offer a promising interface for stable throughput
and low-latency storage by eliminating device-side garbage collection. They
expose storage as append-only zones that give the host applications direct
control over data placement. However, current ZNS implementations suffer from
(a) device-level write amplification (DLWA), (b) increased wear, and (c)
interference with host I/O due to zone mapping and management. We identify two
primary design decisions as the main cause: (i) fixed physical zones and (ii)
full-zone operations that lead to excessive physical writes. We propose
SilentZNS, a new zone mapping and management approach that addresses the
aforementioned limitations by on-the-fly allocating available resources to
zones, while minimizing wear, maintaining parallelism, and avoiding unnecessary
writes at the device-level. SilentZNS is a flexible zone allocation scheme that
departs from the traditional logical-to-physical zone mapping and allows for
arbitrary collections of blocks to be assigned to a zone. We add the necessary
constraints to ensure wear-leveling and state-of-the-art read performance, and
use only the required blocks to avoid dummy writes during zone reset. We
implement SilentZNS using the state-of-the-art ConfZNS++ emulator and show that
it eliminates the undue burden of dummy writes by up to 20x, leading to lower
DLWA (86% less at 10% zone occupancy), less overall wear (up to 76.9%), and up
to 3.7x faster workload execution.

</details>


### [4] [MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars](https://arxiv.org/abs/2511.04798)
*Matheus Farias,Wanghley Martins,H. T. Kung*

Main category: cs.AR

TL;DR: Manhattan Distance Mapping (MDM) 是一种针对忆阻器位切片存内计算交叉阵列的DNN权重映射技术，通过优化活动忆阻器的布局来减轻寄生电阻（PR）非理想性，提升模型准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 寄生电阻（PR）限制了交叉阵列的效率，导致DNN矩阵被分割成小块，降低存内计算（CIM）的加速效果，并增加延迟、I/O压力和芯片面积。

Challenges: 如何在不增加硬件复杂度的前提下，有效缓解PR引起的非理想效应，同时保持DNN的高精度和高效计算。

Contributions: 提出MDM方法，利用位级结构稀疏性，通过曼哈顿距离重排序行，将活跃单元移至受PR影响较小的区域，从而降低非理想因子（NF），提升精度。

Results: 在ImageNet-1k上的ResNet模型中，MDM将非理想因子（NF）最多降低46%，在模拟失真下平均提升准确率3.6%。

Conclusion: MDM提供了一种轻量级、空间感知的解决方案，有助于扩展基于CIM的DNN加速器的规模和性能。

Related Work: 现有工作主要集中在并行使用多个小交叉阵列或顺序重用少数阵列，但均增加了模数转换、延迟和I/O压力；MDM通过结构化稀疏性和重映射策略改进了这些方法。

Abstract: Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN)
weight mapping technique for memristive bit-sliced compute-in-memory (CIM)
crossbars that reduces parasitic resistance (PR) nonidealities.
  PR limits crossbar efficiency by mapping DNN matrices into small crossbar
tiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring
digital synchronization before the next layer. At this granularity, designers
either deploy many small crossbars in parallel or reuse a few sequentially-both
increasing analog-to-digital conversions, latency, I/O pressure, and chip area.
  MDM alleviates PR effects by optimizing active-memristor placement.
Exploiting bit-level structured sparsity, it feeds activations from the denser
low-order side and reorders rows according to the Manhattan distance,
relocating active cells toward regions less affected by PR and thus lowering
the nonideality factor (NF).
  Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and
improves accuracy under analog distortion by an average of 3.6% in ResNets.
Overall, it provides a lightweight, spatially informed method for scaling CIM
DNN accelerators.

</details>
