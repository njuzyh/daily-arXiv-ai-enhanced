{"id": "2510.20137", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.20137", "abs": "https://arxiv.org/abs/2510.20137", "authors": ["Hasnain A. Ziad", "Ashiq A. Sakib"], "title": "HALOC-AxA: An Area/-Energy-Efficient Approximate Adder for Image Processing Application", "comment": "5 Pages, 6 Figures, and 1 Table", "summary": "The design of approximate adders has been widely researched to advance\nenergy-efficient hardware for computation-intensive multimedia applications,\nsuch as image, audio, or video processing. The design of approximate adders has\nbeen widely researched to advance energy-efficient hardware for computation\nintensive multimedia applications, such as image/audio/video processing.\nSeveral static and dynamic approximate adders exist in the literature, each of\nwhich endeavors to balance the conflicting demands of high performance,\ncomputational accuracy, and energy efficiency. This work introduces a novel\napproximate adder that is more energy- and area-efficient than existing adders,\nwhile achieving improved or comparable accuracy, as demonstrated by simulation\nresults. The proposed adder's ability to digitally reconstruct high quality\nimages is further demonstrated by the deployment of the design for an image\nprocessing task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fd1\u4f3c\u52a0\u6cd5\u5668\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u52a0\u6cd5\u5668\u5728\u80fd\u6548\u548c\u9762\u79ef\u6548\u7387\u4e0a\u66f4\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u5e76\u901a\u8fc7\u56fe\u50cf\u5904\u7406\u4efb\u52a1\u9a8c\u8bc1\u4e86\u5176\u5728\u9ad8\u8d28\u91cf\u56fe\u50cf\u91cd\u5efa\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u8ba1\u7b97\u5bc6\u96c6\u578b\u591a\u5a92\u4f53\u5e94\u7528\uff08\u5982\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u5904\u7406\uff09\u4e2d\u786c\u4ef6\u7684\u80fd\u6548\uff0c\u7814\u7a76\u8005\u5e7f\u6cdb\u63a2\u7d22\u4e86\u8fd1\u4f3c\u52a0\u6cd5\u5668\u7684\u8bbe\u8ba1\u3002", "challenges": "\u5982\u4f55\u5728\u9ad8\u6027\u80fd\u3001\u9ad8\u8ba1\u7b97\u7cbe\u5ea6\u548c\u9ad8\u80fd\u6548\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u662f\u8fd1\u4f3c\u52a0\u6cd5\u5668\u8bbe\u8ba1\u7684\u4e3b\u8981\u6311\u6218\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8fd1\u4f3c\u52a0\u6cd5\u5668\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u80fd\u6548\u548c\u9762\u79ef\u6548\u7387\uff0c\u540c\u65f6\u7cbe\u5ea6\u4f18\u4e8e\u6216\u76f8\u5f53\u4e8e\u73b0\u6709\u52a0\u6cd5\u5668\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u548c\u56fe\u50cf\u5904\u7406\u5e94\u7528\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "results": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u52a0\u6cd5\u5668\u5728\u80fd\u6548\u548c\u9762\u79ef\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff1b\u5728\u56fe\u50cf\u5904\u7406\u4efb\u52a1\u4e2d\u80fd\u591f\u9ad8\u8d28\u91cf\u5730\u91cd\u5efa\u56fe\u50cf\u3002", "conclusion": "\u8be5\u65b0\u578b\u8fd1\u4f3c\u52a0\u6cd5\u5668\u5728\u591a\u5a92\u4f53\u5e94\u7528\u4e2d\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\uff0c\u517c\u987e\u4e86\u80fd\u6548\u3001\u9762\u79ef\u548c\u7cbe\u5ea6\u3002", "related_work": "\u5df2\u6709\u591a\u79cd\u9759\u6001\u548c\u52a8\u6001\u8fd1\u4f3c\u52a0\u6cd5\u5668\u88ab\u63d0\u51fa\uff0c\u81f4\u529b\u4e8e\u5728\u6027\u80fd\u3001\u7cbe\u5ea6\u548c\u80fd\u6548\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2510.20269", "categories": ["cs.AR", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20269", "abs": "https://arxiv.org/abs/2510.20269", "authors": ["Ismail Emir Yuksel", "Ataberk Olgun", "F. Nisa Bostanci", "Oguzhan Canpolat", "Geraldo F. Oliveira", "Mohammad Sadrosadati", "Abdullah Giray Yaglikci", "Onur Mutlu"], "title": "In-DRAM True Random Number Generation Using Simultaneous Multiple-Row Activation: An Experimental Study of Real DRAM Chips", "comment": "Extended version of our publication at the 43rd IEEE International\n  Conference on Computer Design (ICCD-43), 2025", "summary": "In this work, we experimentally demonstrate that it is possible to generate\ntrue random numbers at high throughput and low latency in commercial\noff-the-shelf (COTS) DRAM chips by leveraging simultaneous multiple-row\nactivation (SiMRA) via an extensive characterization of 96 DDR4 DRAM chips. We\nrigorously analyze SiMRA's true random generation potential in terms of\nentropy, latency, and throughput for varying numbers of simultaneously\nactivated DRAM rows (i.e., 2, 4, 8, 16, and 32), data patterns, temperature\nlevels, and spatial variations. Among our 11 key experimental observations, we\nhighlight four key results. First, we evaluate the quality of our TRNG designs\nusing the commonly-used NIST statistical test suite for randomness and find\nthat all SiMRA-based TRNG designs successfully pass each test. Second, 2-, 8-,\n16-, and 32-row activation-based TRNG designs outperform the state-of-theart\nDRAM-based TRNG in throughput by up to 1.15x, 1.99x, 1.82x, and 1.39x,\nrespectively. Third, SiMRA's entropy tends to increase with the number of\nsimultaneously activated DRAM rows. Fourth, operational parameters and\nconditions (e.g., data pattern and temperature) significantly affect entropy.\nFor example, for most of the tested modules, the average entropy of 32-row\nactivation is 2.51x higher than that of 2-row activation. For example,\nincreasing the temperature from 50{\\deg}C to 90{\\deg}C decreases SiMRA's\nentropy by 1.53x for 32-row activation. To aid future research and development,\nwe open-source our infrastructure at https://github.com/CMU-SAFARI/SiMRA-TRNG.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u572896\u4e2a\u5546\u7528DDR4 DRAM\u82af\u7247\u4e0a\u5e7f\u6cdb\u8868\u5f81\uff0c\u5229\u7528\u540c\u65f6\u591a\u884c\u6fc0\u6d3b\uff08SiMRA\uff09\u6280\u672f\uff0c\u5728COTS DRAM\u82af\u7247\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u91cf\u3001\u4f4e\u5ef6\u8fdf\u7684\u771f\u968f\u673a\u6570\u751f\u6210\u3002\u6240\u6709\u57fa\u4e8eSiMRA\u7684\u771f\u968f\u673a\u6570\u751f\u6210\u5668\uff08TRNG\uff09\u8bbe\u8ba1\u5747\u901a\u8fc7\u4e86NIST\u968f\u673a\u6027\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u4e14\u5728\u541e\u5410\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684DRAM-based TRNG\u3002\u71b5\u503c\u968f\u540c\u65f6\u6fc0\u6d3b\u7684\u884c\u6570\u589e\u52a0\u800c\u589e\u52a0\uff0c\u4f46\u53d7\u6570\u636e\u6a21\u5f0f\u548c\u6e29\u5ea6\u7b49\u64cd\u4f5c\u6761\u4ef6\u663e\u8457\u5f71\u54cd\u3002\u7814\u7a76\u8fd8\u5f00\u6e90\u4e86\u76f8\u5173\u57fa\u7840\u8bbe\u65bd\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u771f\u968f\u673a\u6570\u751f\u6210\uff08TRNG\uff09\u5728\u5bc6\u7801\u5b66\u548c\u5b89\u5168\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6848\u5728\u6210\u672c\u3001\u541e\u5410\u91cf\u6216\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5229\u7528\u5e7f\u6cdb\u4f7f\u7528\u7684\u5546\u7528DRAM\u82af\u7247\u4e2d\u7684\u7269\u7406\u73b0\u8c61\uff08SiMRA\uff09\u6765\u6784\u5efa\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684TRNG\u3002", "challenges": "\u5982\u4f55\u5728\u5546\u7528DRAM\u4e2d\u7a33\u5b9a\u6fc0\u53d1\u5e76\u5229\u7528SiMRA\u6548\u5e94\u751f\u6210\u9ad8\u8d28\u91cf\u968f\u673a\u6027\uff1b\u786e\u4fdd\u751f\u6210\u7684\u968f\u673a\u6570\u901a\u8fc7\u4e25\u683c\u7684\u7edf\u8ba1\u6d4b\u8bd5\uff1b\u4f18\u5316\u541e\u5410\u91cf\u4e0e\u5ef6\u8fdf\uff1b\u5206\u6790\u4e0d\u540c\u53c2\u6570\uff08\u5982\u6fc0\u6d3b\u884c\u6570\u3001\u6e29\u5ea6\u3001\u6570\u636e\u6a21\u5f0f\uff09\u5bf9\u71b5\u7684\u5f71\u54cd\u3002", "contributions": "1\uff09\u9996\u6b21\u572896\u4e2a\u771f\u5b9eDDR4\u82af\u7247\u4e0a\u7cfb\u7edf\u8868\u5f81SiMRA\u7528\u4e8eTRNG\u7684\u6f5c\u529b\uff1b2\uff09\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u591a\u79cd\u57fa\u4e8e\u4e0d\u540c\u540c\u65f6\u6fc0\u6d3b\u884c\u6570\u7684TRNG\u8bbe\u8ba1\uff1b3\uff09\u63ed\u793a\u4e86SiMRA\u71b5\u4e0e\u884c\u6570\u3001\u6e29\u5ea6\u3001\u6570\u636e\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b4\uff09\u5f00\u6e90\u5b9e\u9a8c\u57fa\u7840\u8bbe\u65bd\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002", "results": "1\uff09\u6240\u6709SiMRA-TRNG\u8bbe\u8ba1\u5747\u901a\u8fc7NIST\u968f\u673a\u6027\u6d4b\u8bd5\uff1b2\uff098\u884c\u6fc0\u6d3b\u8bbe\u8ba1\u541e\u5410\u91cf\u6700\u9ad8\uff0c\u8f83\u73b0\u6709\u6700\u4f18DRAM-TRNG\u63d0\u53471.99\u500d\uff1b3\uff09\u71b5\u503c\u968f\u540c\u65f6\u6fc0\u6d3b\u884c\u6570\u589e\u52a0\u800c\u4e0a\u5347\uff0c32\u884c\u6fc0\u6d3b\u7684\u5e73\u5747\u71b5\u662f2\u884c\u76842.51\u500d\uff1b4\uff09\u6e29\u5ea6\u5347\u9ad8\uff0850\u00b0C\u81f390\u00b0C\uff09\u4f7f32\u884c\u6fc0\u6d3b\u7684\u71b5\u964d\u4f4e1.53\u500d\u3002", "conclusion": "SiMRA\u662f\u4e00\u79cd\u5728\u5546\u7528DRAM\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3001\u9ad8\u71b5\u771f\u968f\u673a\u6570\u751f\u6210\u7684\u6709\u6548\u673a\u5236\uff0c\u5177\u5907\u826f\u597d\u7684\u7edf\u8ba1\u7279\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5176\u6027\u80fd\u53d7\u64cd\u4f5c\u6761\u4ef6\u5f71\u54cd\u663e\u8457\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "related_work": "\u5df2\u6709\u7814\u7a76\u5229\u7528DRAM\u7684\u884c\u51b2\u7a81\u3001\u6fc0\u6d3b\u5ef6\u8fdf\u53d8\u5316\u7b49\u7269\u7406\u7279\u6027\u6784\u5efaTRNG\uff0c\u4f46\u901a\u5e38\u541e\u5410\u91cf\u8f83\u4f4e\u6216\u4f9d\u8d56\u7279\u6b8a\u786c\u4ef6\u3002\u672c\u6587\u4e0d\u540c\u4e8e\u4ee5\u5f80\u5de5\u4f5c\uff0c\u9996\u6b21\u7cfb\u7edf\u63a2\u7d22\u540c\u65f6\u591a\u884c\u6fc0\u6d3b\uff08SiMRA\uff09\u4f5c\u4e3a\u71b5\u6e90\uff0c\u5e76\u5728\u5927\u91cf\u771f\u5b9e\u82af\u7247\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.19972", "categories": ["cs.DC", "cs.CC"], "pdf": "https://arxiv.org/pdf/2510.19972", "abs": "https://arxiv.org/abs/2510.19972", "authors": ["Alkida Balliu", "Filippo Casagrande", "Francesco d'Amore", "Dennis Olivetti"], "title": "New Hardness Results for the LOCAL Model via a Simple Self-Reduction", "comment": "21 pages, no figures", "summary": "Very recently, Khoury and Schild [FOCS 2025] showed that any randomized LOCAL\nalgorithm that solves maximal matching requires $\\Omega(\\min\\{\\log \\Delta,\n\\log_\\Delta n\\})$ rounds, where $n$ is the number of nodes in the graph and\n$\\Delta$ is the maximum degree. This result is shown through a new technique,\ncalled round elimination via self-reduction. The lower bound proof is beautiful\nand presents very nice ideas. However, it spans more than 25 pages of technical\ndetails, and hence it is hard to digest and generalize to other problems.\nHistorically, the simplification of proofs and techniques has marked an\nimportant turning point in our understanding of the complexity of graph\nproblems. Our paper makes a step forward towards this direction, and provides\nthe following contributions.\n  1. We present a short and simplified version of the round elimination via\nself-reduction technique. The simplification of this technique enables us to\nobtain the following two hardness results.\n  2. We show that any randomized LOCAL algorithm that solves the maximal\n$b$-matching problem requires $\\Omega(\\min\\{\\log_{1+b}\\Delta, \\log_\\Delta n\\})$\nand $\\Omega(\\sqrt{\\log_{1+b} n})$ rounds. We recall that the $b$-matching\nproblem is a generalization of the matching problem where each vertex can have\nup to $b$ incident edges in the matching. As a corollary, for $b=1$, we obtain\na short proof for the maximal matching lower bound shown by Khoury and Schild.\n  3. Finally, we show that any randomized LOCAL algorithm that properly colors\nthe edges of a graph with $\\Delta + k$ colors requires $\\Omega(\\min\\{\\log\n\\Delta, \\log_\\Delta n\\})$ and $\\Omega(\\sqrt{\\log n})$ rounds, for any $k\\le\n\\Delta^{1-\\varepsilon}$ and any constant $\\varepsilon > 0$.", "AI": {"tldr": "\u672c\u6587\u7b80\u5316\u4e86Khoury\u548cSchild\u63d0\u51fa\u7684\u201c\u901a\u8fc7\u81ea\u7ea6\u7b80\u7684\u8f6e\u6b21\u6d88\u9664\u201d\u6280\u672f\uff0c\u5e76\u5229\u7528\u8be5\u7b80\u5316\u65b9\u6cd5\u8bc1\u660e\u4e86\u968f\u673aLOCAL\u6a21\u578b\u4e2d\u6700\u5927b-\u5339\u914d\u548c\u8fb9\u7740\u8272\u95ee\u9898\u7684\u8f6e\u6b21\u4e0b\u754c\u3002", "motivation": "\u539f\u8bc1\u660e\u6280\u672f\u867d\u7136\u4f18\u7f8e\u4f46\u8fc7\u4e8e\u590d\u6742\uff08\u8d85\u8fc725\u9875\uff09\uff0c\u96be\u4ee5\u7406\u89e3\u4e0e\u63a8\u5e7f\u3002\u672c\u6587\u65e8\u5728\u7b80\u5316\u8be5\u6280\u672f\uff0c\u63a8\u52a8\u5bf9\u56fe\u95ee\u9898\u590d\u6742\u6027\u7684\u6df1\u5165\u7406\u89e3\u3002", "challenges": "\u7b80\u5316\u590d\u6742\u7684\u8f6e\u6b21\u4e0b\u754c\u8bc1\u660e\u6280\u672f\uff0c\u5e76\u5c06\u5176\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u95ee\u9898\uff08\u5982b-\u5339\u914d\u548c\u8fb9\u7740\u8272\uff09\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u8bc1\u660e\u7684\u4e25\u8c28\u6027\u548c\u6709\u6548\u6027\u3002", "contributions": "1. \u63d0\u51fa\u4e86\u66f4\u7b80\u6d01\u7684\u8f6e\u6b21\u6d88\u9664\u81ea\u7ea6\u7b80\u6280\u672f\uff1b2. \u7ed9\u51fa\u4e86\u6700\u5927b-\u5339\u914d\u95ee\u9898\u7684\u8f6e\u6b21\u4e0b\u754c\uff1b3. \u8bc1\u660e\u4e86\u4f7f\u7528\u0394+k\u79cd\u989c\u8272\u8fdb\u884c\u8fb9\u7740\u8272\u7684\u968f\u673a\u7b97\u6cd5\u7684\u8f6e\u6b21\u4e0b\u754c\u3002", "results": "1. \u6700\u5927b-\u5339\u914d\u95ee\u9898\u5728\u968f\u673aLOCAL\u6a21\u578b\u4e2d\u9700\u8981\u03a9(min{log_{1+b}\u0394, log_\u0394 n})\u548c\u03a9(\u221a(log_{1+b} n))\u8f6e\uff1b2. \u8fb9\u7740\u8272\u95ee\u9898\u9700\u8981\u03a9(min{log \u0394, log_\u0394 n})\u548c\u03a9(\u221a(log n))\u8f6e\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u7b80\u5316\u4e86\u8f6e\u6b21\u6d88\u9664\u6280\u672f\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u591a\u4e2a\u7ecf\u5178\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u6211\u4eec\u5bf9\u5206\u5e03\u5f0f\u56fe\u7b97\u6cd5\u4e0b\u754c\u7684\u7406\u89e3\u3002", "related_work": "Khoury\u548cSchild\u5728FOCS 2025\u4e2d\u9996\u6b21\u63d0\u51fa\u901a\u8fc7\u81ea\u7ea6\u7b80\u7684\u8f6e\u6b21\u6d88\u9664\u6280\u672f\uff0c\u8bc1\u660e\u4e86\u6700\u5927\u5339\u914d\u95ee\u9898\u7684\u4e0b\u754c\uff0c\u672c\u6587\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u7b80\u5316\u548c\u6269\u5c55\u3002"}}
{"id": "2510.20400", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.20400", "abs": "https://arxiv.org/abs/2510.20400", "authors": ["Rub\u00e9n Langarita", "Jes\u00fas Alastruey-Bened\u00e9", "Pablo Ib\u00e1\u00f1ez-Mar\u00edn", "Santiago Marco-Sola", "Miquel Moret\u00f3", "Adri\u00e0 Armejach"], "title": "Squire: A General-Purpose Accelerator to Exploit Fine-Grain Parallelism on Dependency-Bound Kernels", "comment": "11 pages, 10 figures, 5 tables, 4 algorithms, accepted on PACT25", "summary": "Multiple HPC applications are often bottlenecked by compute-intensive kernels\nimplementing complex dependency patterns (data-dependency bound). Traditional\ngeneral-purpose accelerators struggle to effectively exploit fine-grain\nparallelism due to limitations in implementing convoluted data-dependency\npatterns (like SIMD) and overheads due to synchronization and data transfers\n(like GPGPUs). In contrast, custom FPGA and ASIC designs offer improved\nperformance and energy efficiency at a high cost in hardware design and\nprogramming complexity and often lack the flexibility to process different\nworkloads. We propose Squire, a general-purpose accelerator designed to exploit\nfine-grain parallelism effectively on dependency-bound kernels. Each Squire\naccelerator has a set of general-purpose low-power in-order cores that can\nrapidly communicate among themselves and directly access data from the L2\ncache. Our proposal integrates one Squire accelerator per core in a typical\nmulticore system, allowing the acceleration of dependency-bound kernels within\nparallel tasks with minimal software changes. As a case study, we evaluate\nSquire's effectiveness by accelerating five kernels that implement complex\ndependency patterns. We use three of these kernels to build an end-to-end\nread-mapping tool that will be used to evaluate Squire. Squire obtains speedups\nup to 7.64$\\times$ in dynamic programming kernels. Overall, Squire provides an\nacceleration for an end-to-end application of 3.66$\\times$. In addition, Squire\nreduces energy consumption by up to 56% with a minimal area overhead of 10.5%\ncompared to a Neoverse-N1 baseline.", "AI": {"tldr": "Squire\u662f\u4e00\u79cd\u901a\u7528\u52a0\u901f\u5668\uff0c\u65e8\u5728\u6709\u6548\u5229\u7528\u6570\u636e\u4f9d\u8d56\u6027\u53d7\u9650\u5185\u6838\u4e2d\u7684\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\uff0c\u901a\u8fc7\u6bcf\u4e2a\u6838\u5fc3\u96c6\u6210\u4e00\u4e2a\u4f4e\u529f\u8017\u3001\u987a\u5e8f\u6267\u884c\u7684\u6838\u5fc3\u7ec4\uff0c\u5b9e\u73b0\u5feb\u901f\u901a\u4fe1\u548c\u76f4\u63a5L2\u7f13\u5b58\u8bbf\u95ee\uff0c\u5728\u52a8\u6001\u89c4\u5212\u5185\u6838\u4e2d\u8fbe\u5230\u6700\u9ad87.64\u500d\u7684\u52a0\u901f\u6bd4\uff0c\u6574\u4f53\u7aef\u5230\u7aef\u5e94\u7528\u52a0\u901f3.66\u500d\uff0c\u5e76\u964d\u4f4e\u6700\u591a56%\u7684\u80fd\u8017\uff0c\u4ec5\u589e\u52a010.5%\u7684\u9762\u79ef\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u901a\u7528\u52a0\u901f\u5668\uff08\u5982SIMD\u548cGPGPU\uff09\u5728\u5904\u7406\u590d\u6742\u6570\u636e\u4f9d\u8d56\u6a21\u5f0f\u65f6\u96be\u4ee5\u9ad8\u6548\u5229\u7528\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\uff0c\u800cFPGA\u548cASIC\u867d\u6027\u80fd\u9ad8\u4f46\u8bbe\u8ba1\u590d\u6742\u4e14\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u517c\u987e\u6027\u80fd\u3001\u80fd\u6548\u4e0e\u53ef\u7f16\u7a0b\u6027\u7684\u901a\u7528\u52a0\u901f\u65b9\u6848\u3002", "challenges": "\u5982\u4f55\u5728\u4fdd\u6301\u4f4e\u786c\u4ef6\u548c\u7f16\u7a0b\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u6709\u6548\u652f\u6301\u5177\u6709\u590d\u6742\u6570\u636e\u4f9d\u8d56\u5173\u7cfb\u7684\u8ba1\u7b97\u5bc6\u96c6\u578b\u5185\u6838\uff0c\u5e76\u5b9e\u73b0\u9ad8\u6548\u7684\u7ec6\u7c92\u5ea6\u5e76\u884c\u6267\u884c\u4e0e\u4f4e\u5f00\u9500\u7684\u6570\u636e\u5171\u4eab\u548c\u540c\u6b65\u3002", "contributions": "\u63d0\u51faSquire\u67b6\u6784\uff0c\u5176\u521b\u65b0\u5305\u62ec\uff1a\u6bcf\u4e2a\u591a\u6838\u7cfb\u7edf\u6838\u5fc3\u914d\u5907\u4e00\u4e2a\u4e13\u7528Squire\u52a0\u901f\u5668\uff0c\u5305\u542b\u591a\u4e2a\u4f4e\u529f\u8017\u987a\u5e8f\u6838\u5fc3\uff0c\u652f\u6301\u5feb\u901f\u4e92\u8fde\u548c\u76f4\u63a5L2\u7f13\u5b58\u8bbf\u95ee\uff1b\u53ef\u5728\u6700\u5c0f\u8f6f\u4ef6\u6539\u52a8\u4e0b\u52a0\u901f\u4f9d\u8d56\u53d7\u9650\u5185\u6838\uff1b\u5728\u4e94\u4e2a\u590d\u6742\u4f9d\u8d56\u5185\u6838\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u6784\u5efa\u4e86\u7aef\u5230\u7aef\u8bfb\u6620\u5c04\u5de5\u5177\u8fdb\u884c\u8bc4\u4f30\u3002", "results": "\u5728\u52a8\u6001\u89c4\u5212\u5185\u6838\u4e0a\u5b9e\u73b0\u6700\u9ad87.64\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff1b\u7aef\u5230\u7aef\u5e94\u7528\u52a0\u901f\u8fbe3.66\u500d\uff1b\u80fd\u8017\u964d\u4f4e\u6700\u591a56%\uff1b\u786c\u4ef6\u9762\u79ef\u4ec5\u589e\u52a010.5%\uff08\u76f8\u5bf9\u4e8eNeoverse-N1\u57fa\u7ebf\uff09\u3002", "conclusion": "Squire\u5728\u6027\u80fd\u3001\u80fd\u6548\u548c\u9762\u79ef\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u80fd\u591f\u6709\u6548\u52a0\u901f\u5177\u6709\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u7684HPC\u5e94\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u53ef\u7f16\u7a0b\u6027\u548c\u7cfb\u7edf\u96c6\u6210\u4fbf\u5229\u6027\uff0c\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u901a\u7528\u52a0\u901f\u5668\u8bbe\u8ba1\u65b9\u6848\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u57fa\u4e8eSIMD\u548cGPGPU\u7684\u901a\u7528\u52a0\u901f\u5668\uff0c\u4ee5\u53ca\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u5b9a\u5236\u7684FPGA\u548cASIC\u89e3\u51b3\u65b9\u6848\uff1bSquire\u7ed3\u5408\u4e86\u4e24\u8005\u7684\u4f18\u70b9\uff0c\u65e2\u907f\u514d\u4e86\u524d\u8005\u7684\u5e76\u884c\u6027\u5229\u7528\u4e0d\u8db3\uff0c\u53c8\u514b\u670d\u4e86\u540e\u8005\u7684\u9ad8\u8bbe\u8ba1\u6210\u672c\u548c\u4f4e\u7075\u6d3b\u6027\u95ee\u9898\u3002"}}
{"id": "2510.20111", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20111", "abs": "https://arxiv.org/abs/2510.20111", "authors": ["Huawei Bai", "Yifan Huang", "Wenqi Shi", "Ansheng You", "Feifan Shao", "Tengfei Han", "Minghui Yu"], "title": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training", "comment": "14 pages, 5 figures, tech report", "summary": "The training efficiency and scalability of language models on massive\nclusters currently remain a critical bottleneck. Mainstream approaches like ND\nparallelism are often cumbersome and complex, while flexible alternatives such\nas the Zero Redundancy Optimizer (ZeRO) are frequently hampered by\ncommunication overhead. In this paper, we propose Asynchronous Hierarchical\nZero Parallelism (AsyncHZP), a novel asynchronous variant of ZeRO designed to\nachieve superior performance while maintaining simplicity and memory\nefficiency. Unlike traditional ZeRO, which employs over-fine-grained sharding\nthat can lead to inefficient communication, AsyncHZP adaptively reshards\nparameters, gradients, and optimizer states across different replica groups.\nThis strategy optimizes device memory utilization and significantly reduces\ncommunication overhead. In addition, we also design a multi-stream asynchronous\nscheduling method that executes parameter all-gather and gradient\nreduce-scatter operations in dedicated background threads, effectively\noverlapping communication with computation while incurring negligible memory\nfragmentation. Empirical evaluations on both Dense and Mixture-of-Experts (MoE)\nmodels confirm that AsyncHZP maintains robust stability at scale. It\nconsistently outperforms classic ND parallelism, achieving state-of-the-art\nperformance without complex strategic tuning, thereby simplifying the path to\nefficient large-scale training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AsyncHZP\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u5f02\u6b65ZeRO\u53d8\u4f53\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u5206\u7247\u548c\u591a\u6d41\u5f02\u6b65\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5728\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u4f18\u5316\u5185\u5b58\u5229\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u9762\u4e34\u74f6\u9888\uff0c\u4e3b\u6d41\u5e76\u884c\u5316\u65b9\u6cd5\u5982ND\u5e76\u884c\u590d\u6742\u4e14\u4e0d\u591f\u7075\u6d3b\uff0c\u800cZeRO\u7b49\u65b9\u6cd5\u53d7\u9650\u4e8e\u901a\u4fe1\u5f00\u9500\u3002", "challenges": "\u5982\u4f55\u5728\u4fdd\u6301\u5185\u5b58\u6548\u7387\u548c\u7cfb\u7edf\u7b80\u6d01\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u5e76\u6709\u6548\u91cd\u53e0\u901a\u4fe1\u4e0e\u8ba1\u7b97\u3002", "contributions": "1) \u63d0\u51faAsyncHZP\uff0c\u4e00\u79cd\u81ea\u9002\u5e94\u91cd\u5206\u7247\u7684\u5f02\u6b65ZeRO\u53d8\u4f53\uff1b2) \u8bbe\u8ba1\u591a\u6d41\u5f02\u6b65\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5b9e\u73b0\u901a\u4fe1\u4e0e\u8ba1\u7b97\u7684\u6709\u6548\u91cd\u53e0\uff1b3) \u5728Dense\u548cMoE\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "results": "\u5b9e\u9a8c\u8868\u660e\uff0cAsyncHZP\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u4f18\u4e8e\u7ecf\u5178ND\u5e76\u884c\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u590d\u6742\u8c03\u53c2\uff0c\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "AsyncHZP\u901a\u8fc7\u7b80\u5316\u7cfb\u7edf\u8bbe\u8ba1\u548c\u4f18\u5316\u901a\u4fe1\u6548\u7387\uff0c\u4e3a\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u6761\u7b80\u6d01\u6709\u6548\u7684\u8def\u5f84\u3002", "related_work": "\u672c\u6587\u57fa\u4e8eZeRO\u548c\u6570\u636e\u5e76\u884c\u3001\u6a21\u578b\u5e76\u884c\u7b49\u76f8\u5173\u5de5\u4f5c\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\uff0c\u4e0e\u4f20\u7edfZeRO\u53caND\u5e76\u884c\u65b9\u6cd5\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2510.20171", "categories": ["cs.DC", "cs.AI", "cs.NI", "C.2.4; I.2"], "pdf": "https://arxiv.org/pdf/2510.20171", "abs": "https://arxiv.org/abs/2510.20171", "authors": ["Min Si", "Pavan Balaji", "Yongzhou Chen", "Ching-Hsiang Chu", "Adi Gangidi", "Saif Hasan", "Subodh Iyengar", "Dan Johnson", "Bingzhe Liu", "Jingliang Ren", "Ashmitha Jeevaraj Shetty", "Greg Steinbrecher", "Xinfeng Xie", "Yulun Wang", "Bruce Wu", "Jingyi Yang", "Mingran Yang", "Minlan Yu", "Cen Zhao", "Wes Bland", "Denis Boyda", "Suman Gumudavelli", "Cristian Lumezanu", "Rui Miao", "Zhe Qu", "Venkat Ramesh", "Maxim Samoylov", "Jan Seidel", "Feng Tian", "Qiye Tan", "Shuqiang Zhang", "Yimeng Zhao", "Shengbao Zheng", "Art Zhu", "Hongyi Zeng"], "title": "Collective Communication for 100k+ GPUs", "comment": null, "summary": "The increasing scale of large language models (LLMs) necessitates highly\nefficient collective communication frameworks, particularly as training\nworkloads extend to hundreds of thousands of GPUs. Traditional communication\nmethods face significant throughput and latency limitations at this scale,\nhindering both the development and deployment of state-of-the-art models. This\npaper presents the NCCLX collective communication framework, developed at Meta,\nengineered to optimize performance across the full LLM lifecycle, from the\nsynchronous demands of large-scale training to the low-latency requirements of\ninference. The framework is designed to support complex workloads on clusters\nexceeding 100,000 GPUs, ensuring reliable, high-throughput, and low-latency\ndata exchange. Empirical evaluation on the Llama4 model demonstrates\nsubstantial improvements in communication efficiency. This research contributes\na robust solution for enabling the next generation of LLMs to operate at\nunprecedented scales.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NCCLX\uff0c\u4e00\u4e2a\u7531Meta\u5f00\u53d1\u7684\u9ad8\u6548\u96c6\u4f53\u901a\u4fe1\u6846\u67b6\uff0c\u65e8\u5728\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5168\u751f\u547d\u5468\u671f\u7684\u6027\u80fd\uff0c\u652f\u6301\u8d85\u8fc710\u4e07GPU\u7684\u96c6\u7fa4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u7684\u6269\u5927\uff0c\u4f20\u7edf\u901a\u4fe1\u65b9\u6cd5\u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u65b9\u9762\u9762\u4e34\u4e25\u91cd\u9650\u5236\uff0c\u96be\u4ee5\u6ee1\u8db3\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u4f4e\u5ef6\u8fdf\u63a8\u7406\u7684\u9700\u6c42\u3002", "challenges": "\u5728\u6570\u5341\u4e07GPU\u89c4\u6a21\u4e0b\uff0c\u5b9e\u73b0\u9ad8\u541e\u5410\u3001\u4f4e\u5ef6\u8fdf\u4e14\u53ef\u9760\u7684\u901a\u4fe1\u6781\u5177\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u540c\u6b65\u8bad\u7ec3\u548c\u5b9e\u65f6\u63a8\u7406\u7684\u4e0d\u540c\u9700\u6c42\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "contributions": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86NCCLX\u6846\u67b6\uff0c\u4e13\u4e3a\u8d85\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u548c\u63a8\u7406\u4f18\u5316\uff0c\u652f\u6301\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u9ad8\u6548\u6570\u636e\u4ea4\u6362\u3002", "results": "\u5728Llama4\u6a21\u578b\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cNCCLX\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6548\u7387\uff0c\u6709\u6548\u652f\u6301\u4e86\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684\u8fd0\u884c\u3002", "conclusion": "NCCLX\u4e3a\u4e0b\u4e00\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u524d\u6240\u672a\u6709\u7684\u89c4\u6a21\u4e0a\u8fd0\u884c\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ecNCCL\u3001MPI\u7b49\u4f20\u7edf\u96c6\u4f53\u901a\u4fe1\u5e93\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5728\u8d85\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u672a\u80fd\u5145\u5206\u6ee1\u8db3LLM\u8bad\u7ec3\u4e0e\u63a8\u7406\u7684\u53cc\u91cd\u9700\u6c42\u3002"}}
{"id": "2510.20128", "categories": ["cs.DC", "quant-ph", "D.2.6"], "pdf": "https://arxiv.org/pdf/2510.20128", "abs": "https://arxiv.org/abs/2510.20128", "authors": ["Xin Zhan", "K. Grace Johnson", "Aniello Esposito", "Barbara Chapman", "Marco Fiorentino", "Kirk M. Bresniker", "Raymond G. Beausoleil", "Masoud Mohseni"], "title": "A Full Stack Framework for High Performance Quantum-Classical Computing", "comment": "9 pages, 8 figures, presented at Cray User Group Meeting 2025, May\n  04-09, 2025, New York, NY", "summary": "To address the growing needs for scalable High Performance Computing (HPC)\nand Quantum Computing (QC) integration, we present our HPC-QC full stack\nframework and its hybrid workload development capability with modular\nhardware/device-agnostic software integration approach. The latest development\nin extensible interfaces for quantum programming, dispatching, and compilation\nwithin existing mature HPC programming environment are demonstrated. Our HPC-QC\nfull stack enables high-level, portable invocation of quantum kernels from\ncommercial quantum SDKs within HPC meta-program in compiled languages (C/C++\nand Fortran) as well as Python through a quantum programming interface library\nextension. An adaptive circuit knitting hypervisor is being developed to\npartition large quantum circuits into sub-circuits that fit on smaller noisy\nquantum devices and classical simulators. At the lower-level, we leverage Cray\nLLVM-based compilation framework to transform and consume LLVM IR and Quantum\nIR (QIR) from commercial quantum software frontends in a retargetable fashion\nto different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU\nand GPU workloads (including solving linear system of equations, quantum\noptimization, and simulating quantum phase transitions) have been demonstrated\non HPE EX supercomputers to illustrate functionality and execution viability\nfor all three components developed so far. This work provides the framework for\na unified quantum-classical programming environment built upon classical HPC\nsoftware stack (compilers, libraries, parallel runtime and process scheduling).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdHPC-QC\u5168\u6808\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e0e\u91cf\u5b50\u8ba1\u7b97\u7684\u96c6\u6210\uff0c\u652f\u6301\u5728\u4f20\u7edfHPC\u73af\u5883\u4e2d\u8c03\u7528\u91cf\u5b50\u5185\u6838\uff0c\u5e76\u5c55\u793a\u4e86\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u4e0e\u91cf\u5b50\u8ba1\u7b97\uff08QC\uff09\u65e5\u76ca\u589e\u957f\u7684\u878d\u5408\u9700\u6c42\uff0c\u9700\u8981\u6784\u5efa\u53ef\u6269\u5c55\u7684\u7edf\u4e00\u8ba1\u7b97\u6846\u67b6\u3002", "challenges": "\u5982\u4f55\u5b9e\u73b0HPC\u4e0eQC\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u652f\u6301\u8de8\u5e73\u53f0\u3001\u8bbe\u5907\u65e0\u5173\u7684\u91cf\u5b50\u7a0b\u5e8f\u5f00\u53d1\uff0c\u5e76\u6709\u6548\u8c03\u5ea6\u548c\u6267\u884c\u6df7\u5408\u5de5\u4f5c\u8d1f\u8f7d\u3002", "contributions": "\u63d0\u51fa\u4e86HPC-QC\u5168\u6808\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u91cf\u5b50\u7f16\u7a0b\u63a5\u53e3\u5e93\u6269\u5c55\u3001\u81ea\u9002\u5e94\u7535\u8def\u62fc\u63a5\u865a\u62df\u5316\u5c42\uff0c\u4ee5\u53ca\u57fa\u4e8eCray LLVM\u7684\u53ef\u91cd\u5b9a\u5411\u7f16\u8bd1\u67b6\u6784\u3002", "results": "\u5728HPE EX\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u6210\u529f\u6f14\u793a\u4e86\u591a\u4e2a\u591a\u8282\u70b9\u3001\u591aCPU/GPU\u7684\u6df7\u5408HPC-QC\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5305\u62ec\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u3001\u91cf\u5b50\u4f18\u5316\u548c\u91cf\u5b50\u76f8\u53d8\u6a21\u62df\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u7edf\u4e00\u7684\u91cf\u5b50-\u7ecf\u5178\u7f16\u7a0b\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u57fa\u4e8e\u73b0\u6709HPC\u8f6f\u4ef6\u6808\u5b9e\u73b0\u4e86\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u79fb\u690d\u548c\u9ad8\u6548\u8c03\u7528\u3002", "related_work": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u72ec\u7acb\u7684\u91cf\u5b50\u7f16\u7a0b\u6846\u67b6\u6216\u7b80\u5355HPC-QC\u63a5\u53e3\uff0c\u7f3a\u4e4f\u5b8c\u6574\u7684\u5168\u6808\u96c6\u6210\u4e0e\u8de8\u5e73\u53f0\u652f\u6301\u3002"}}
{"id": "2510.20388", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20388", "abs": "https://arxiv.org/abs/2510.20388", "authors": ["V\u00edctor Ramp\u00e9rez", "Javier Soriano", "David Lizcano", "Juan A. Lara"], "title": "FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services", "comment": null, "summary": "Cloud computing has established itself as the support for the vast majority\nof emerging technologies, mainly due to the characteristic of elasticity it\noffers. Auto-scalers are the systems that enable this elasticity by acquiring\nand releasing resources on demand to ensure an agreed service level. In this\narticle we present FLAS (Forecasted Load Auto-Scaling), an auto-scaler for\ndistributed services that combines the advantages of proactive and reactive\napproaches according to the situation to decide the optimal scaling actions in\nevery moment. The main novelties introduced by FLAS are (i) a predictive model\nof the high-level metrics trend which allows to anticipate changes in the\nrelevant SLA parameters (e.g. performance metrics such as response time or\nthroughput) and (ii) a reactive contingency system based on the estimation of\nhigh-level metrics from resource use metrics, reducing the necessary\ninstrumentation (less invasive) and allowing it to be adapted agnostically to\ndifferent applications. We provide a FLAS implementation for the use case of a\ncontent-based publish-subscribe middleware (E-SilboPS) that is the cornerstone\nof an event-driven architecture. To the best of our knowledge, this is the\nfirst auto-scaling system for content-based publish-subscribe distributed\nsystems (although it is generic enough to fit any distributed service). Through\nan evaluation based on several test cases recreating not only the expected\ncontexts of use, but also the worst possible scenarios (following the\nBoundary-Value Analysis or BVA test methodology), we have validated our\napproach and demonstrated the effectiveness of our solution by ensuring\ncompliance with performance requirements over 99% of the time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFLAS\u7684\u81ea\u9002\u5e94\u81ea\u52a8\u4f38\u7f29\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u9884\u6d4b\u6027\u548c\u53cd\u5e94\u6027\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u7528\u4e8e\u5206\u5e03\u5f0f\u670d\u52a1\u7684\u5f39\u6027\u8d44\u6e90\u7ba1\u7406\uff0c\u7279\u522b\u9002\u7528\u4e8e\u57fa\u4e8e\u5185\u5bb9\u7684\u53d1\u5e03-\u8ba2\u9605\u4e2d\u95f4\u4ef6\uff0c\u5e76\u5728\u591a\u79cd\u6d4b\u8bd5\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5176\u572899%\u4ee5\u4e0a\u7684\u65f6\u95f4\u5185\u6ee1\u8db3\u6027\u80fd\u9700\u6c42\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u4e91\u8ba1\u7b97\u7684\u5f39\u6027\u7279\u6027\u652f\u6491\u4e86\u5927\u591a\u6570\u65b0\u5174\u6280\u672f\u7684\u53d1\u5c55\uff0c\u81ea\u52a8\u4f38\u7f29\u7cfb\u7edf\u6210\u4e3a\u4fdd\u969c\u670d\u52a1\u8d28\u91cf\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5e94\u5bf9\u52a8\u6001\u8d1f\u8f7d\u53d8\u5316\u65f6\u5b58\u5728\u54cd\u5e94\u6ede\u540e\u6216\u8fc7\u5ea6\u914d\u7f6e\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u3001\u81ea\u9002\u5e94\u7684\u4f38\u7f29\u673a\u5236\u3002", "challenges": "\u4e3b\u8981\u6311\u6218\u5305\u62ec\u5982\u4f55\u51c6\u786e\u9884\u6d4b\u9ad8\u5c42\u6027\u80fd\u6307\u6807\uff08\u5982\u54cd\u5e94\u65f6\u95f4\u3001\u541e\u5410\u91cf\uff09\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u51cf\u5c11\u7cfb\u7edf\u4fb5\u5165\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u5bf9\u4e0d\u540c\u5e94\u7528\u7684\u901a\u7528\u9002\u5e94\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5728\u6781\u7aef\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u4ecd\u9700\u4fdd\u8bc1SLA\u5408\u89c4\u6027\u3002", "contributions": "\u672c\u6587\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a(1) \u63d0\u51faFLAS\u81ea\u52a8\u4f38\u7f29\u6846\u67b6\uff0c\u878d\u5408\u9884\u6d4b\u4e0e\u53cd\u5e94\u673a\u5236\uff1b(2) \u8bbe\u8ba1\u57fa\u4e8e\u8d44\u6e90\u4f7f\u7528\u6307\u6807\u4f30\u7b97\u9ad8\u5c42\u6027\u80fd\u6307\u6807\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u964d\u4f4e\u76d1\u63a7\u5f00\u9500\uff1b(3) \u5b9e\u73b0\u5bf9\u5185\u5bb9\u53d1\u5e03-\u8ba2\u9605\u7cfb\u7edf\u7684\u9996\u4e2a\u4e13\u7528\u81ea\u52a8\u4f38\u7f29\u65b9\u6848\uff0c\u4e14\u5177\u5907\u901a\u7528\u6027\uff1b(4) \u91c7\u7528\u8fb9\u754c\u503c\u5206\u6790\u6cd5\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "results": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFLAS\u5728\u591a\u79cd\u6d4b\u8bd5\u573a\u666f\u4e0b\uff08\u5305\u62ec\u9884\u671f\u4f7f\u7528\u73af\u5883\u548c\u6700\u574f\u60c5\u51b5\uff09\u5747\u80fd\u6709\u6548\u7ef4\u6301\u6027\u80fd\u8981\u6c42\uff0c\u572899%\u4ee5\u4e0a\u7684\u65f6\u95f4\u5185\u6ee1\u8db3SLA\u6307\u6807\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "FLAS\u901a\u8fc7\u7ed3\u5408\u9884\u6d4b\u4e0e\u53cd\u5e94\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u4f4e\u4fb5\u5165\u3001\u81ea\u9002\u5e94\u7684\u81ea\u52a8\u4f38\u7f29\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\u4e2d\u7684\u5206\u5e03\u5f0f\u670d\u52a1\uff0c\u5728\u4fdd\u969c\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u7387\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u57fa\u4e8e\u9608\u503c\u7684\u53cd\u5e94\u5f0f\u4f38\u7f29\u548c\u57fa\u4e8e\u8d1f\u8f7d\u9884\u6d4b\u7684\u4e3b\u52a8\u5f0f\u4f38\u7f29\u65b9\u6cd5\u3002\u5df2\u6709\u7814\u7a76\u591a\u5355\u72ec\u91c7\u7528\u5176\u4e2d\u4e00\u79cd\u7b56\u7565\uff0c\u7f3a\u4e4f\u6839\u636e\u8fd0\u884c\u65f6\u60c5\u51b5\u52a8\u6001\u5207\u6362\u6216\u878d\u5408\u4e24\u8005\u4f18\u52bf\u7684\u673a\u5236\uff0c\u800cFLAS\u6b63\u662f\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u81ea\u9002\u5e94\u65b9\u6848\u3002"}}
{"id": "2510.20495", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20495", "abs": "https://arxiv.org/abs/2510.20495", "authors": ["Panagiotis Giannakopoulos", "Bart van Knippenberg", "Kishor Chandra Joshi", "Nicola Calabretta", "George Exarchakos"], "title": "Accurate Performance Predictors for Edge Computing Applications", "comment": null, "summary": "Accurate prediction of application performance is critical for enabling\neffective scheduling and resource management in resource-constrained dynamic\nedge environments. However, achieving predictable performance in such\nenvironments remains challenging due to the co-location of multiple\napplications and the node heterogeneity. To address this, we propose a\nmethodology that automatically builds and assesses various performance\npredictors. This approach prioritizes both accuracy and inference time to\nidentify the most efficient model. Our predictors achieve up to 90% accuracy\nwhile maintaining an inference time of less than 1% of the Round Trip Time.\nThese predictors are trained on the historical state of the most correlated\nmonitoring metrics to application performance and evaluated across multiple\nservers in dynamic co-location scenarios. As usecase we consider electron\nmicroscopy (EM) workflows, which have stringent real-time demands and diverse\nresource requirements. Our findings emphasize the need for a systematic\nmethodology that selects server-specific predictors by jointly optimizing\naccuracy and inference latency in dynamic co-location scenarios. Integrating\nsuch predictors into edge environments can improve resource utilization and\nresult in predictable performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u6784\u5efa\u548c\u8bc4\u4f30\u591a\u79cd\u6027\u80fd\u9884\u6d4b\u5668\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4e14\u4f4e\u63a8\u7406\u5ef6\u8fdf\u7684\u5e94\u7528\u6027\u80fd\u9884\u6d4b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7535\u5b50\u663e\u5fae\u955c\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5728\u52a8\u6001\u8fb9\u7f18\u73af\u5883\u4e2d\uff0c\u7531\u4e8e\u5e94\u7528\u5171\u7f6e\u548c\u8282\u70b9\u5f02\u6784\u6027\uff0c\u5e94\u7528\u6027\u80fd\u9884\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u800c\u51c6\u786e\u7684\u9884\u6d4b\u5bf9\u8d44\u6e90\u8c03\u5ea6\u548c\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "challenges": "\u5e94\u7528\u4e4b\u95f4\u7684\u8d44\u6e90\u7ade\u4e89\u3001\u8282\u70b9\u5f02\u6784\u6027\u4ee5\u53ca\u52a8\u6001\u5171\u7f6e\u73af\u5883\u5bfc\u81f4\u6027\u80fd\u9884\u6d4b\u56f0\u96be\uff0c\u540c\u65f6\u9700\u8981\u517c\u987e\u9884\u6d4b\u51c6\u786e\u6027\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "contributions": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4e3a\u4e0d\u540c\u670d\u52a1\u5668\u9009\u62e9\u6700\u4f18\u7684\u6027\u80fd\u9884\u6d4b\u5668\uff0c\u517c\u987e\u51c6\u786e\u7387\u548c\u63a8\u7406\u65f6\u95f4\uff0c\u5e76\u5728\u771f\u5b9e\u7535\u5b50\u663e\u5fae\u955c\u5de5\u4f5c\u6d41\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "results": "\u9884\u6d4b\u5668\u6700\u9ad8\u8fbe\u523090%\u7684\u51c6\u786e\u7387\uff0c\u63a8\u7406\u65f6\u95f4\u4f4e\u4e8e\u5f80\u8fd4\u65f6\u95f4\uff08RTT\uff09\u76841%\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u51c6\u786e\u6027\u548c\u63a8\u7406\u5ef6\u8fdf\uff0c\u6240\u63d0\u51fa\u7684\u9884\u6d4b\u5668\u80fd\u6709\u6548\u63d0\u5347\u8fb9\u7f18\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u5229\u7528\u7387\u548c\u6027\u80fd\u53ef\u9884\u6d4b\u6027\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u57fa\u4e8e\u76d1\u63a7\u6307\u6807\u7684\u6027\u80fd\u9884\u6d4b\u3001\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u8c03\u5ea6\u4ee5\u53ca\u673a\u5668\u5b66\u4e60\u5728\u7cfb\u7edf\u6027\u80fd\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2510.20506", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20506", "abs": "https://arxiv.org/abs/2510.20506", "authors": ["Panagiotis Giannakopoulos", "Bart van Knippenberg", "Kishor Chandra Joshi", "Nicola Calabretta", "George Exarchakos"], "title": "Morpheus: Lightweight RTT Prediction for Performance-Aware Load Balancing", "comment": null, "summary": "Distributed applications increasingly demand low end-to-end latency,\nespecially in edge and cloud environments where co-located workloads contend\nfor limited resources. Traditional load-balancing strategies are typically\nreactive and rely on outdated or coarse-grained metrics, often leading to\nsuboptimal routing decisions and increased tail latencies. This paper\ninvestigates the use of round-trip time (RTT) predictors to enhance request\nrouting by anticipating application latency. We develop lightweight and\naccurate RTT predictors that are trained on time-series monitoring data\ncollected from a Kubernetes-managed GPU cluster. By leveraging a reduced set of\nhighly correlated monitoring metrics, our approach maintains low overhead while\nremaining adaptable to diverse co-location scenarios and heterogeneous\nhardware. The predictors achieve up to 95% accuracy while keeping the\nprediction delay within 10% of the application RTT. In addition, we identify\nthe minimum prediction accuracy threshold and key system-level factors required\nto ensure effective predictor deployment in resource-constrained clusters.\nSimulation-based evaluation demonstrates that performance-aware load balancing\ncan significantly reduce application RTT and minimize resource waste. These\nresults highlight the feasibility of integrating predictive load balancing into\nfuture production systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5229\u7528\u5f80\u8fd4\u65f6\u95f4\uff08RTT\uff09\u9884\u6d4b\u5668\u6765\u6539\u8fdb\u5206\u5e03\u5f0f\u5e94\u7528\u4e2d\u7684\u8bf7\u6c42\u8def\u7531\uff0c\u901a\u8fc7\u5728Kubernetes\u7ba1\u7406\u7684GPU\u96c6\u7fa4\u4e0a\u6536\u96c6\u7684\u65f6\u95f4\u5e8f\u5217\u76d1\u63a7\u6570\u636e\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4e14\u51c6\u786e\u7684RTT\u9884\u6d4b\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe95%\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5c06\u9884\u6d4b\u5ef6\u8fdf\u63a7\u5236\u5728\u5e94\u7528RTT\u768410%\u4ee5\u5185\u3002", "motivation": "\u4f20\u7edf\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u901a\u5e38\u662f\u53cd\u5e94\u5f0f\u7684\uff0c\u4f9d\u8d56\u8fc7\u65f6\u6216\u7c97\u7c92\u5ea6\u7684\u6307\u6807\uff0c\u5bfc\u81f4\u8def\u7531\u51b3\u7b56\u6b21\u4f18\u548c\u5c3e\u90e8\u5ef6\u8fdf\u589e\u52a0\u3002\u4e3a\u4e86\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u548c\u4e91\u73af\u5883\u4e2d\uff0c\u9700\u8981\u66f4\u4e3b\u52a8\u3001\u7cbe\u51c6\u7684\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u3002", "challenges": "\u5982\u4f55\u5728\u4fdd\u6301\u4f4e\u5f00\u9500\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684RTT\u9884\u6d4b\uff1b\u5982\u4f55\u9002\u5e94\u4e0d\u540c\u5171\u7f6e\u573a\u666f\u548c\u5f02\u6784\u786c\u4ef6\u73af\u5883\uff1b\u786e\u5b9a\u6709\u6548\u90e8\u7f72\u9884\u6d4b\u5668\u6240\u9700\u7684\u6700\u4f4e\u9884\u6d4b\u7cbe\u5ea6\u9608\u503c\u548c\u5173\u952e\u7cfb\u7edf\u56e0\u7d20\u3002", "contributions": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u76d1\u63a7\u6570\u636e\u7684\u8f7b\u91cf\u7ea7RTT\u9884\u6d4b\u5668\uff0c\u4f7f\u7528\u9ad8\u5ea6\u76f8\u5173\u7684\u5c11\u91cf\u6307\u6807\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\uff1b\u786e\u5b9a\u4e86\u786e\u4fdd\u9884\u6d4b\u5668\u6709\u6548\u90e8\u7f72\u7684\u5173\u952e\u7cfb\u7edf\u7ea7\u56e0\u7d20\u548c\u6700\u4f4e\u7cbe\u5ea6\u8981\u6c42\uff1b\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u6027\u80fd\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u53ef\u663e\u8457\u964d\u4f4e\u5e94\u7528RTT\u5e76\u51cf\u5c11\u8d44\u6e90\u6d6a\u8d39\u3002", "results": "\u9884\u6d4b\u5668\u8fbe\u5230\u9ad8\u8fbe95%\u7684\u51c6\u786e\u6027\uff0c\u9884\u6d4b\u5ef6\u8fdf\u63a7\u5236\u5728\u5e94\u7528RTT\u768410%\u4ee5\u5185\uff1b\u4eff\u771f\u8868\u660e\u6027\u80fd\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u80fd\u663e\u8457\u964d\u4f4e\u5e94\u7528\u5f80\u8fd4\u65f6\u95f4\u5e76\u51cf\u5c11\u8d44\u6e90\u6d6a\u8d39\u3002", "conclusion": "\u5c06\u9884\u6d4b\u6027\u8d1f\u8f7d\u5747\u8861\u96c6\u6210\u5230\u672a\u6765\u751f\u4ea7\u7cfb\u7edf\u4e2d\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5206\u5e03\u5f0f\u5e94\u7528\u7684\u6027\u80fd\u8868\u73b0\u3002", "related_work": "\u76f8\u5173\u5de5\u4f5c\u5305\u62ec\u4f20\u7edf\u7684\u57fa\u4e8e\u8d1f\u8f7d\u7684\u8def\u7531\u7b97\u6cd5\u3001\u53cd\u5e94\u5f0f\u4e0e\u4e3b\u52a8\u5f0f\u8d1f\u8f7d\u5747\u8861\u673a\u5236\u3001\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6027\u80fd\u9884\u6d4b\u6a21\u578b\u4ee5\u53ca\u5728\u5bb9\u5668\u5316\u548cGPU\u96c6\u7fa4\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u8c03\u5ea6\u4f18\u5316\u7814\u7a76\u3002"}}
