{"id": "2601.22461", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22461", "abs": "https://arxiv.org/abs/2601.22461", "authors": ["Mingrui Zhang", "Hamid Bagheri", "Lisong Xu"], "title": "Toward Non-Expert Customized Congestion Control", "comment": "Accepted manuscript (AAM) of IEEE ICC 2025 paper. DOI: 10.1109/ICC52391.2025.11160790", "summary": "General-purpose congestion control algorithms (CCAs) are designed to achieve general congestion control goals, but they may not meet the specific requirements of certain users. Customized CCAs can meet certain users' specific requirements; however, non-expert users often lack the expertise to implement them. In this paper, we present an exploratory non-expert customized CCA framework, named NECC, which enables non-expert users to easily model, implement, and deploy their customized CCAs by leveraging Large Language Models and the Berkeley Packet Filter (BPF) interface. To the best of our knowledge, we are the first to address the customized CCA implementation problem. Our evaluations using real-world CCAs show that the performance of NECC is very promising, and we discuss the insights that we find and possible future research directions."}
{"id": "2601.22476", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22476", "abs": "https://arxiv.org/abs/2601.22476", "authors": ["Ruizhe Zhong", "Xingbo Du", "Junchi Yan"], "title": "RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning", "comment": null, "summary": "Floorplanning determines the coordinate and shape of each module in Integrated Circuits. With the scaling of technology nodes, in floorplanning stage especially 3D scenarios with multiple stacked layers, it has become increasingly challenging to adhere to complex hardware design rules. Current methods are only capable of handling specific and limited design rules, while violations of other rules require manual and meticulous adjustment. This leads to labor-intensive and time-consuming post-processing for expert engineers. In this paper, we propose an all-in-one deep reinforcement learning-based approach to tackle these challenges, and design novel representations for real-world IC design rules that have not been addressed by previous approaches. Specifically, the processing of various hardware design rules is unified into a single framework with three key components: 1) novel matrix representations to model the design rules, 2) constraints on the action space to filter out invalid actions that cause rule violations, and 3) quantitative analysis of constraint satisfaction as reward signals. Experiments on public benchmarks demonstrate the effectiveness and validity of our approach. Furthermore, transferability is well demonstrated on unseen circuits. Our framework is extensible to accommodate new design rules, thus providing flexibility to address emerging challenges in future chip design. Code will be available at: https://github.com/Thinklab-SJTU/EDA-AI"}
{"id": "2601.22494", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.22494", "abs": "https://arxiv.org/abs/2601.22494", "authors": ["Chungang Lin", "Weiyao Zhang", "Haitong Luo", "Xuying Meng", "Yujun Zhang"], "title": "Nethira: A Heterogeneity-aware Hierarchical Pre-trained Model for Network Traffic Classification", "comment": "Accepted for publication at International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Network traffic classification is vital for network security and management. The pre-training technology has shown promise by learning general traffic representations from raw byte sequences, thereby reducing reliance on labeled data. However, existing pre-trained models struggle with the gap between traffic heterogeneity (i.e., hierarchical traffic structures) and input homogeneity (i.e., flattened byte sequences). To address this gap, we propose Nethira, a heterogeneity-aware pre-trained model based on hierarchical reconstruction and augmentation. In pre-training, Nethira introduces hierarchical reconstruction at multiple levels-byte, protocol, and packet-capturing comprehensive traffic structural information. During fine-tuning, Nethira proposes a consistency-regularized strategy with hierarchical traffic augmentation to reduce label dependence. Experiments on four public datasets demonstrate that Nethira outperforms seven existing pre-trained models, achieving an average F1-score improvement of 9.11%, and reaching comparable performance with only 1% labeled data on high-heterogeneity network tasks."}
{"id": "2601.22862", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.22862", "abs": "https://arxiv.org/abs/2601.22862", "authors": ["Aurora Tomás", "Juan Luis Aragón", "Joan Manuel Parcerisa", "Antonio González"], "title": "Design of a GPU with Heterogeneous Cores for Graphics", "comment": null, "summary": "Heterogeneous architectures can deliver higher performance and energy efficiency than symmetric counterparts by using multiple architectures tuned to different types of workloads. While previous works focused on CPUs, this work extends the concept of heterogeneity to GPUs by proposing KHEPRI, a heterogeneous GPU architecture for graphics applications. Scenes in graphics applications showcase diversity, as they consist of many objects with varying levels of complexity. As a result, computational intensity and memory bandwidth requirements differ significantly across different regions of each scene. To address this variability, our proposal includes two types of cores: cores optimized for high ILP (compute-specialized) and cores that tolerate a higher number of simultaneously outstanding cache misses (memory-specialized). A key component of the proposed architecture is a novel work scheduler that dynamically assigns each part of a frame (i.e., a tile) to the most suitable core. Designing this scheduler is particularly challenging, as it must preserve data locality; otherwise, the benefits of heterogeneity may be offset by the penalty of additional cache misses. Additionally, the scheduler requires knowledge of each tile's characteristics before rendering it. For this purpose, KHEPRI leverages frame-to-frame coherence to predict the behavior of each tile based on that of the corresponding tile in the previous frame. Evaluations across a wide range of commercial animated graphics applications show that, compared to a traditional homogeneous GPU, KHEPRI achieves an average performance improvement of 9.2%, a throughput increase (frames per second) of 7.3%, and a total GPU energy reduction of 4.8%. Importantly, these benefits are achieved without any hardware overhead."}
{"id": "2601.22499", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.22499", "abs": "https://arxiv.org/abs/2601.22499", "authors": ["Elhadj Moustapha Diallo", "Mamadou Aliou Diallo", "Abusaeed B. M. Adam", "Muhammad Naeem Shah"], "title": "Chance-Constrained Secrecy Optimization in Hybrid RIS-Empowered and UAV-Assisted Networks", "comment": "12 pages, 4 figures", "summary": "This paper considers a hybrid reconfigurable environment comprising a UAV-mounted reflecting RIS, an outdoor STAR-RIS enabling simultaneous transmission and reflection, and an indoor holographic RIS (H-RIS), jointly enhancing secure downlink communication for indoor and outdoor users. The system operates under user mobility, dynamic blockages, colluding idle and active eavesdroppers, and transceiver and surface hardware impairments. A 3GPP and ITU-compliant stochastic channel model is developed, capturing mobility-induced covariance evolution, outdoor-indoor penetration losses, and distortion-aware noise due to practical EVM-based impairments. We aim to minimize the aggregate secrecy-outage probability subject to secrecy-rate constraints, QoS requirements, power limitations, and statistical CSI uncertainty. The resulting problem contains coupled secrecy and QoS chance constraints and nonlinear interactions among the BS beamforming vectors, multi-surface phase coefficients, and UAV position. To handle these difficulties, we derive rigorous Bernstein-type deterministic approximations for all chance constraints, yielding a distributionally robust reformulation. Building on this, we propose an alternating optimization framework that employs successive convex approximation (SCA) to convexify each block and solve the BS beamforming, RIS, STAR-RIS, H-RIS configuration, and UAV placement subproblems efficiently. The proposed algorithm is shown to monotonically decrease a smooth surrogate of the secrecy-outage cost and converge to a stationary point of the robustified problem. Simulations based on 3GPP TR 38.901, TR 36.873, and ITU-R P.2109 demonstrate that integrating UAV-RIS, STAR-RIS, and H-RIS significantly reduces secrecy-outage probability compared with benchmark schemes and provides strong robustness to channel uncertainty, blockages, colluding eavesdroppers, and hardware impairments."}
{"id": "2601.23134", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.23134", "abs": "https://arxiv.org/abs/2601.23134", "authors": ["Zheyuan Hu", "Yifei Shi"], "title": "Machine Learning for Energy-Performance-aware Scheduling", "comment": "Zheyuan Hu and Yifei Shi contributed equally to this work", "summary": "In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose a Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multi-core architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis (fANOVA) and comparing different covariance kernels (e.g., Matérn vs. RBF), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance."}
{"id": "2601.22438", "categories": ["cs.DC", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22438", "abs": "https://arxiv.org/abs/2601.22438", "authors": ["Shangshu Qian", "Kipling Liu", "P. C. Sruthi", "Lin Tan", "Yongle Zhang"], "title": "Towards Resiliency in Large Language Model Serving with KevlarFlow", "comment": null, "summary": "Large Language Model (LLM) serving systems remain fundamentally fragile, where frequent hardware faults in hyperscale clusters trigger disproportionate service outages in the software stack. Current recovery mechanisms are prohibitively slow, often requiring up to 10 minutes to reinitialize resources and reload massive model weights. We introduce KevlarFlow, a fault tolerant serving architecture designed to bridge the gap between hardware unreliability and service availability. KevlarFlow leverages 1) decoupled model parallelism initialization, 2) dynamic traffic rerouting, and 3) background KV cache replication to maintain high throughput during partial failures. Our evaluation demonstrates that KevlarFlow reduces mean-time-to-recovery (MTTR) by 20x and, under failure conditions, improves average latency by 3.1x, 99th percentile (p99) latency by 2.8x, average time-to-first-token (TTFT) by 378.9x, and p99 TTFT by 574.6x with negligible runtime overhead in comparison to state-of-the-art LLM serving systems."}
{"id": "2601.22633", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22633", "abs": "https://arxiv.org/abs/2601.22633", "authors": ["Devansh Lodha", "Mohit Panchal", "Sameer G. Kulkarni"], "title": "MCP-Diag: A Deterministic, Protocol-Driven Architecture for AI-Native Network Diagnostics", "comment": "Accepted at COMSNETS 2026 Graduate Forum. Best Paper Award (Runner Up). 5 pages, 3 figures", "summary": "The integration of Large Language Models (LLMs) into network operations (AIOps) is hindered by two fundamental challenges: the stochastic grounding problem, where LLMs struggle to reliably parse unstructured, vendor-specific CLI output, and the security gap of granting autonomous agents shell access. This paper introduces MCP-Diag, a hybrid neuro-symbolic architecture built upon the Model Context Protocol (MCP). We propose a deterministic translation layer that converts raw stdout from canonical utilities (dig, ping, traceroute) into rigorous JSON schemas before AI ingestion. We further introduce a mandatory \"Elicitation Loop\" that enforces Human-in-the-Loop (HITL) authorization at the protocol level. Our preliminary evaluation demonstrates that MCP-Diag achieving 100% entity extraction accuracy with less than 0.9% execution latency overhead and 3.7x increase in context token usage."}
{"id": "2601.23226", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.23226", "abs": "https://arxiv.org/abs/2601.23226", "authors": ["Gourab Datta", "Sarah Safura Sharif", "Yaser Mike Banad"], "title": "Toward Digital Twins in 3D IC Packaging: A Critical Review of Physics, Data, and Hybrid Architectures", "comment": null, "summary": "Three-dimensional integrated circuit (3D IC) pack-aging and heterogeneous integration have emerged as central pillars of contemporary semiconductor scaling. Yet, the multi-physics coupling inherent to stacked architectures manifesting as thermal hot spots, warpage-induced stresses, and interconnect aging demands monitoring and control capabilities that surpass traditional offline metrology. Although Digital Twin (DT) technology provides a principled route to real-time reliability management, the existing literature remains fragmented and frequently blurs the distinction between static multiphysics simulation workflows and truly dynamic, closed-loop twins. This critical review distinguishes itself by addressing these deficiencies through three specific contributions. First, we clarify the Digital Twin hierarchy to resolve terminological ambiguity between digital models, shadows, and twins. Second, we synthesize three foundational enabling technologies: (1) physics-based modeling, emphasizing the shift from computationally intensive finite-element analysis (FEA) to real-time surrogate models; (2) data-driven paradigms, highlighting virtual metrology (VM) for inferring latent metrics; and (3) in-situ sensing, the nervous system coupling the physical stack to its virtual counterpart. Third, beyond a descriptive survey, we propose a unified hybrid DT architecture that leverages physics-informed machine learning (e.g., PINNs) to reconcile data scarcity with latency constraints. Finally, we outline a standards-aligned roadmap incorporating IEEE 1451 and UCIe protocols to accelerate the transition from passive digital shadows to autonomous, self-optimizing Digital Twins for 3D IC manufacturing and field operation."}
{"id": "2601.22487", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22487", "abs": "https://arxiv.org/abs/2601.22487", "authors": ["Ali Jahanshahi", "Sara Rashidi Golrouye", "Osten Anderson", "Nanpeng Yu", "Daniel Wong"], "title": "Coordinating Power Grid Frequency Regulation Service with Data Center Load Flexibility", "comment": null, "summary": "AI/ML data center growth have led to higher energy consumption and carbon emissions. The shift to renewable energy and growing data center energy demands can destabilize the power grid. Power grids rely on frequency regulation reserves, typically fossil-fueled power plants, to stabilize and balance the supply and demand of electricity. This paper sheds light on the hidden carbon emissions of frequency regulation service. Our work explores how modern GPU data centers can coordinate with power grids to reduce the need for fossil-fueled frequency regulation reserves. We first introduce a novel metric, Exogenous Carbon, to quantify grid-side carbon emission reductions resulting from data center participation in regulation service. We additionally introduce EcoCenter, a framework to maximize the amount of frequency regulation provision that GPU data centers can provide, and thus, reduce the amount of frequency regulation reserves necessary. We demonstrate that data center participation in frequency regulation can result in Exogenous carbon savings that oftentimes outweigh Operational carbon emissions."}
{"id": "2601.23051", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.23051", "abs": "https://arxiv.org/abs/2601.23051", "authors": ["Eduardo Freitas", "Assis T. de Oliveira Filho", "Pedro R. X. do Carmo", "Djamel Sadok", "Judith Kelner"], "title": "Digital Twin Synchronization: towards a data-centric architecture", "comment": null, "summary": "Digital Twin (DT) technology revolutionizes industrial processes by enabling the representation of physical entities and their dynamics to enhance productivity and operational efficiency. It has emerged as a vital enabling technology in the Industry 4.0 context. The present article examines the particular issue of synchronizing a digital twin while ensuring an accurate reflection of its physical counterpart. Despite the reported recent advances in the design of middleware and low delay communication technologies, effective synchronization between both worlds remains challenging. This paper reviews currently adopted synchronization technologies and architectures, identifies vital outstanding technical challenges, and proposes a unified synchronization architecture for use by various industrial applications while addressing security and interoperability requirements. As such, this study aims to bridges gaps and advance robust synchronization in DT environments, emphasizing the need for a standardized architecture to ensure seamless operation and continuous improvement of industrial systems."}
{"id": "2601.22585", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22585", "abs": "https://arxiv.org/abs/2601.22585", "authors": ["Heehoon Kim", "Jaehwan Lee", "Taejeoung Kim", "Jongwon Park", "Jinpyo Kim", "Pyongwon Suh", "Ryan H. Choi", "Sangwoo Lee", "Jaejin Lee"], "title": "HetCCL: Accelerating LLM Training with Heterogeneous GPUs", "comment": null, "summary": "The rapid growth of large language models is driving organizations to expand their GPU clusters, often with GPUs from multiple vendors. However, current deep learning frameworks lack support for collective communication across heterogeneous GPUs, leading to inefficiency and higher costs. We present HetCCL, a collective communication library that unifies vendor-specific backends and enables RDMA-based communication across GPUs without requiring driver modifications. HetCCL introduces two novel mechanisms that enable cross-vendor communication while leveraging optimized vendor libraries, NVIDIA NCCL and AMD RCCL. Evaluations on a multi-vendor GPU cluster show that HetCCL matches NCCL and RCCL performance in homogeneous setups while uniquely scaling in heterogeneous environments, enabling practical, high-performance training with both NVIDIA and AMD GPUs without changes to existing deep learning applications."}
{"id": "2601.23105", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.23105", "abs": "https://arxiv.org/abs/2601.23105", "authors": ["Andrea Pimpinella", "Fabio Palmese", "Alessandro E. C. Redondi"], "title": "Lossy Compression of Cellular Network KPIs", "comment": "Paper submitted for publication in IEEE Communication Letter on February 2026", "summary": "Network Key Performance Indicators (KPIs) are a fundamental component of mobile cellular network monitoring and optimization. Their massive volume, resulting from fine-grained measurements collected across many cells over long time horizons, poses significant challenges for storage, transport, and large-scale analysis. In this letter, we show that common cellular KPIs can be efficiently compressed using standard lossy compression schemes based on prediction, quantization, and entropy coding, achieving substantial reductions in reporting overhead. Focusing on traffic volume KPIs, we first characterize their intrinsic compressibility through a rate-distortion analysis, showing that signal-to-noise ratios around 30 dB can be achieved using only 3-4 bits per sample, corresponding to an 8-10x reduction with respect to 32-bit floating-point representations. We then assess the impact of KPI compression on representative downstream analytics tasks. Our results show that aggregation across cells mitigates quantization errors and that prediction accuracy is unaffected beyond a moderate reporting rate. These findings indicate that KPI compression is feasible and transparent to network-level analytics in cellular systems."}
{"id": "2601.22705", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22705", "abs": "https://arxiv.org/abs/2601.22705", "authors": ["Qiaoling Chen", "Zhisheng Ye", "Tian Tang", "Peng Sun", "Boyu Tian", "Guoteng Wang", "Shenggui Li", "Yonggang Wen", "Zhenhua Han", "Tianwei Zhang"], "title": "CONCUR: High-Throughput Agentic Batch Inference of LLM via Congestion-Based Concurrency Control", "comment": null, "summary": "Batch inference for agentic workloads stresses the GPU key-value (KV) cache in a sustained and cumulative manner, often causing severe throughput degradation well before memory capacity is exhausted. We identify this phenomenon as middle-phase thrashing, a previously under-characterized pathology in which cache efficiency collapses as long-lived agents accumulate state over time.\n  We argue that mitigating this pathology requires moving beyond reactive, request-level cache management to proactive, agent-level admission control. Drawing inspiration from congestion control in distributed systems, we view the KV cache as a shared resource whose efficient utilization depends on feedback-driven regulation. Based on this insight, we present CONCUR, a lightweight control layer that regulates agent admission to bound aggregate cache pressure while preserving execution continuity. CONCUR adapts a cache-aware control algorithm to dynamically adjust the number of active agents using runtime cache signals.\n  Across large models and real-world agent workloads, CONCUR prevents middle-phase thrashing and improves batch inference throughput by up to 4.09x on Qwen3-32B and 1.9x on DeepSeek-V3, while remaining compatible with existing LLM serving systems."}
{"id": "2601.22760", "categories": ["cs.DC", "cs.LG", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.22760", "abs": "https://arxiv.org/abs/2601.22760", "authors": ["Zhongzhen Wen", "Shudi Shao", "Zhong Li", "Yu Ge", "Tongtong Xu", "Yuanyi Lin", "Tian Zhang"], "title": "AscendCraft: Automatic Ascend NPU Kernel Generation via DSL-Guided Transcompilation", "comment": null, "summary": "The performance of deep learning models critically depends on efficient kernel implementations, yet developing high-performance kernels for specialized accelerators remains time-consuming and expertise-intensive. While recent work demonstrates that large language models (LLMs) can generate correct and performant GPU kernels, kernel generation for neural processing units (NPUs) remains largely underexplored due to domain-specific programming models, limited public examples, and sparse documentation. Consequently, directly generating AscendC kernels with LLMs yields extremely low correctness, highlighting a substantial gap between GPU and NPU kernel generation.\n  We present AscendCraft, a DSL-guided approach for automatic AscendC kernel generation. AscendCraft introduces a lightweight DSL that abstracts non-essential complexity while explicitly modeling Ascend-specific execution semantics. Kernels are first generated in the DSL using category-specific expert examples and then transcompiled into AscendC through structured, constraint-driven LLM lowering passes. Evaluated on MultiKernelBench across seven operator categories, AscendCraft achieves 98.1% compilation success and 90.4% functional correctness. Moreover, 46.2% of generated kernels match or exceed PyTorch eager execution performance, demonstrating that DSL-guided transcompilation can enable LLMs to generate both correct and competitive NPU kernels. Beyond benchmarks, AscendCraft further demonstrates its generality by successfully generating two correct kernels for newly proposed mHC architecture, achieving performance that substantially surpasses PyTorch eager execution."}
{"id": "2601.22963", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.22963", "abs": "https://arxiv.org/abs/2601.22963", "authors": ["Kegan Dougal"], "title": "ERA: Epoch-Resolved Arbitration for Duelling Admins in Group Management CRDTs", "comment": "7 pages, 8 figures, submitted to the 13th Workshop on Principles and Practice of Consistency for Distributed Data", "summary": "Conflict-Free Replicated Data Types (CRDTs) are used in a range of fields for their coordination-free replication with strong eventual consistency. By prioritising availability over consistency under partition, nodes accumulate events in different orders, and rely on an associative, commutative and idempotent merge function to present a materialised view of the CRDT. Under some circumstances, the state of the materialised view over time can appear to ''roll back'' previously applied events. When the materialised view is used to manage group permissions such as ones found in instant messaging applications, this can lead to surprising behaviour. This can occur when there are multiple concurrent events, such as in the Duelling Admins problem where two equally permissioned admins concurrently revoke each other's permissions. Who wins? This article argues that a Byzantine admin can exploit concurrency to win the duel. As a result, an external arbiter is required to arbitrate an immutable happens-before relation between concurrent events. Arbitration occurs asynchronously in batches via optional ''epoch events'', preserving availability. This introduces a bounded total order within epochs, and the resulting ''finality'' improves on the level of consistency CRDTs can provide."}
