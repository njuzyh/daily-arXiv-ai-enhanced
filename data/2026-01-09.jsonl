{"id": "2601.03593", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.03593", "abs": "https://arxiv.org/abs/2601.03593", "authors": ["Kevin Zhao", "Chenning Li", "Anton A. Zabreyko", "Arash Nasr-Esfahany", "Anna Goncharenko", "David Dai", "Sidharth Lakshmanan", "Claire Li", "Mohammad Alizadeh", "Thomas E. Anderson"], "title": "Prediction-Guided Control in Data Center Networks", "comment": null, "summary": "In this paper, we design, implement, and evaluate Polyphony, a system to give network operators a new way to control and reduce the frequency of poor tail latency events in multi-class data center networks, on the time scale of minutes. Polyphony is designed to be complementary to other adaptive mechanisms like congestion control and traffic engineering, but targets different aspects of network operation that have previously been considered static. By contrast to Polyphony, prior model-free optimization methods work best when there are only a few relevant degrees of freedom and where workloads and measurements are stable, assumptions not present in modern data center networks.\n  Polyphony develops novel methods for measuring, predicting, and controlling network quality of service metrics for a dynamically changing workload. First, we monitor and aggregate workloads on a network-wide basis; we use the result as input to an approximate counterfactual prediction engine that estimates the effect of potential network configuration changes on network quality of service; we apply the best candidate and repeat in a closed-loop manner aimed at rapidly and stably converging to a configuration that meets operator goals. Using CloudLab on a simple topology, we observe that Polyphony converges to tight SLOs within ten minutes, and re-stabilizes after large workload shifts within fifteen minutes, while the prior state of the art fails to adapt."}
{"id": "2601.03757", "categories": ["cs.NI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.03757", "abs": "https://arxiv.org/abs/2601.03757", "authors": ["Nguyen Cong Luong", "Zeping Sui", "Duc Van Le", "Jie Cao", "Bo Ma", "Nguyen Duc Hai", "Ruichen Zhang", "Vu Van Quang", "Dusit Niyato", "Shaohan Feng"], "title": "Incentive Mechanism Design for Resource Management in Satellite Networks: A Comprehensive Survey", "comment": "28 pages, 8 figures, accepted by IEEE IoTJ", "summary": "Resource management is one of the challenges in satellite networks due to their high mobility, wide coverage, long propagation distances, and stringent constraints on energy, communication, and computation resources. Traditional resource allocation approaches rely only on hard and rigid system performance metrics. Meanwhile, incentive mechanisms, which are based on game theory and auction theory, investigate systems from the \"economic\" perspective in addition to the \"system\" perspective. Particularly, incentive mechanisms are able to take into account rationality and other behavior of human users into account, which guarantees benefits/utility of all system entities, thereby improving the scalability, adaptability, and fairness in resource allocation. This paper presents a comprehensive survey of incentive mechanism design for resource management in satellite networks. The paper covers key issues in the satellite networks, such as communication resource allocation, computation offloading, privacy and security, and coordination. We conclude with future research directions including learning-based mechanism design for satellite networks."}
{"id": "2601.03917", "categories": ["cs.NI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.03917", "abs": "https://arxiv.org/abs/2601.03917", "authors": ["Jinting Liu", "Jingwei Li", "Tengfei Chang"], "title": "Monaas: Mobile Node as a Service for TSCH-based Industrial IoT Networks", "comment": null, "summary": "The Time-Slotted Channel Hopping (TSCH) mode of IEEE802.15.4 standard provides ultra high end-to-end reliability and low-power consumption for application in field of Industrial Internet of Things (IIoT). With the evolving of Industrial 4.0, dynamic and bursty tasks with varied Quality of Service (QoS); effective management and utilization of growing number of mobile equipments become two major challenges for network solutions. The existing TSCH-based networks lack of a system framework design to handle these challenges. In this paper, we propose a novel, service-oriented, and hierarchical IoT network architecture named Mobile Node as a Service (Monaas). Monaas aims to systematically manage and schedule mobile nodes as on-demand, elastic resources through a new architectural design and protocol mechanisms. Its core features include a hierarchical architecture to balance global coordination with local autonomy, task-driven scheduling for proactive resource allocation, and an on-demand mobile resource integration mechanism. The feasibility and potential of the Monaas link layer mechanisms are validated through implementation and performance evaluation on an nRF52840 hardware testbed, demonstrating its potential advantages in specific scenarios. On a physical nRF52840 testbed, Monaas consistently achieved a Task Completion Rate (TCR) above 98% for high-priority tasks under bursty traffic and link degradation, whereas all representative baselines (Static TSCH, 6TiSCH Minimal, OST, FTS-SDN) remained below 40%.Moreover, its on-demand mobile resource integration activated services in 1.2 s, at least 65% faster than SDN (3.5 s) and OST/6TiSCH (> 5.8 s)."}
{"id": "2601.03958", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.03958", "abs": "https://arxiv.org/abs/2601.03958", "authors": ["Mattia Figaro", "Francesco Rossato", "Alexander Bonora", "Marco Giordani", "Giovanni Schembra", "Michele Zorzi"], "title": "Experimental Evaluation of a UAV-Mounted LEO Satellite Backhaul for Emergency Connectivity", "comment": "6 pages, 7 figures. This paper has been accepted for presentation at the 2026 International Conference on Computing, Networking and Communications (ICNC)", "summary": "Reliable connectivity is critical for Public Protection and Disaster Relief operations, especially in rural or compromised environments where terrestrial infrastructure is unavailable. In such scenarios, NTNs, and specifically UAVs, are promising candidates to provide on-demand and rapid connectivity on the ground, serving as aerial base stations. In this paper, we implement a setup in which a rotary-wing UAV, equipped with a Starlink Mini terminal, provides Internet connectivity to an emergency ground user in the absence of cellular coverage via LEO satellites. The UAV functions as a Wi-Fi access point, while backhauling the ground traffic through the Starlink constellation. We evaluate the system via both network simulations in ns-3 and real-world flight experiments in a rural environment, in terms of throughput, latency, coverage, and energy consumption under static and dynamic flight conditions. Our results demonstrate that the system can maintain a stable uplink throughput of approximately 30 Mbps up to approximately 200 meters, and with minimal impact on the UAV battery lifetime. These findings demonstrate the feasibility of deploying commercial LEO satellite terminals on UAVs as a practical solution for emergency connectivity."}
{"id": "2601.03390", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.03390", "abs": "https://arxiv.org/abs/2601.03390", "authors": ["Daniel Qian", "Xiyu Hao", "Jinkun Geng", "Yuncheng Yao", "Aurojit Panda", "Jinyang Li", "Anirudh Sivaraman"], "title": "Revisiting Speculative Leaderless Protocols for Low-Latency BFT Replication", "comment": null, "summary": "As Byzantine Fault Tolerant (BFT) protocols begin to be used in permissioned blockchains for user-facing applications such as payments, it is crucial that they provide low latency. In pursuit of low latency, some recently proposed BFT consensus protocols employ a leaderless optimistic fast path, in which clients broadcast their requests directly to replicas without first serializing requests at a leader, resulting in an end-to-end commit latency of 2 message delays ($2Δ$) during fault-free, synchronous periods. However, such a fast path only works if there is no contention: concurrent contending requests can cause replicas to diverge if they receive conflicting requests in different orders, triggering costly recovery procedures.\n  In this work, we present Aspen, a leaderless BFT protocol that achieves a near-optimal latency of $2Δ+ \\varepsilon$, where $\\varepsilon$ indicates a short waiting delay. Aspen removes the no-contention condition by utilizing a best-effort sequencing layer based on loosely synchronized clocks and network delay estimates. Aspen requires $n = 3f + 2p + 1$ replicas to cope with up to $f$ Byzantine nodes. The $2p$ extra nodes allow Aspen's fast path to proceed even if up to $p$ replicas diverge due to unpredictable network delays. When its optimistic conditions do not hold, Aspen falls back to PBFT-style protocol, guaranteeing safety and liveness under partial synchrony. In experiments with wide-area distributed replicas, Aspen commits requests in less than 75 ms, a 1.2 to 3.3$\\times$ improvement compared to previous protocols, while supporting 19,000 requests per second."}
{"id": "2601.04042", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04042", "abs": "https://arxiv.org/abs/2601.04042", "authors": ["Marcin Hoffmann"], "title": "Badanie Sieci Massive MIMO o Architekturze Zorientowanej na Uzytkownika", "comment": "in Polish language", "summary": "The future 6G networks are expected to utilize large antenna arrays and follow the user-centric architecture, where the user is being served by all base stations. This work evaluates such a system within an advanced system-level simulator, which utilizes an accurate 3D Ray-Tracing radio channel model. Results show that the novel user-centric network architecture can increase the cell-edge users throughput by a fold of 3."}
{"id": "2601.03862", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.03862", "abs": "https://arxiv.org/abs/2601.03862", "authors": ["Francesco D'Amato", "Roberto Saltini", "Thanh-Hai Tran", "Yann Vonlanthen", "Luca Zanolini"], "title": "Majorum: Ebb-and-Flow Consensus with Dynamic Quorums", "comment": null, "summary": "Dynamic availability is the ability of a consensus protocol to remain live despite honest participants going offline and later rejoining. A well-known limitation is that dynamically available protocols, on their own, cannot provide strong safety guarantees during network partitions or extended asynchrony. Ebb-and-flow protocols [SP21] address this by combining a dynamically available protocol with a partially synchronous finality protocol that irrevocably finalizes a prefix.\n  We present Majorum, an ebb-and-flow construction whose dynamically available component builds on a quorum-based protocol (TOB-SVD). Under optimistic conditions, Majorum finalizes blocks in as few as three slots while requiring only a single voting phase per slot. In particular, when conditions remain favourable, each slot finalizes the next block extending the previously finalized one."}
{"id": "2601.04083", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04083", "abs": "https://arxiv.org/abs/2601.04083", "authors": ["Marvin Illian", "Ramin Khalili", "Antonio A. de A. Rocha", "Lin Wang"], "title": "Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning", "comment": "11 pages, 12 figures", "summary": "The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance."}
{"id": "2601.03992", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.03992", "abs": "https://arxiv.org/abs/2601.03992", "authors": ["Qi Wu", "Chao Fang", "Jiayuan Chen", "Ye Lin", "Yueqi Zhang", "Yichuan Bai", "Yuan Du", "Li Du"], "title": "A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems", "comment": "To appear in 2026 Design, Automation and Test in Europe Conference (DATE 2026)", "summary": "Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments."}
{"id": "2601.04089", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04089", "abs": "https://arxiv.org/abs/2601.04089", "authors": ["Adrian Pekar", "Richard Plny", "Karel Hynek"], "title": "Tutorial on Flow-Based Network Traffic Classification Using Machine Learning", "comment": "under review", "summary": "Modern networks carry increasingly diverse and encrypted traffic types that demand classification techniques beyond traditional port-based and payload-based methods. This tutorial provides a practical, end-to-end guide to building machine-learning-based network traffic flow classification systems. We cover the workflow from flow metering and dataset creation, through ground-truth labeling and feature engineering, to leakage-resistant experimental design, model training and evaluation, explainability, and deployment considerations. The tutorial focuses on supervised flow-based classification that remains effective under encryption and provides actionable guidance on algorithm selection, performance metrics, and realistic partitioning strategies, with emphasis on common real-world measurement artifacts and methodological pitfalls. A companion set of five Jupyter notebooks on GitHub implements the data-to-model workflow on real traffic captures, enabling readers to reproduce key steps. The intended audience includes researchers and practitioners with foundational networking knowledge who aim to design and deploy robust traffic classification systems in operational environments."}
{"id": "2601.04071", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04071", "abs": "https://arxiv.org/abs/2601.04071", "authors": ["Tiancheng Hu", "Chenxi Wang", "Ting Cao", "Jin Qin", "Lei Chen", "Xinyu Xiao", "Junhao Hu", "Hongliang Tian", "Shoumeng Yan", "Huimin Cui", "Quan Chen", "Tao Xie"], "title": "Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale", "comment": null, "summary": "Existing GPU-sharing techniques, including spatial and temporal sharing, aim to improve utilization but face challenges in simultaneously ensuring SLO adherence and maximizing efficiency due to the lack of fine-grained task scheduling on closed-source GPUs. This paper presents Hummingbird, an SLO-oriented GPU scheduling system that overcomes these challenges by enabling microsecond-scale preemption on closed-source GPUs while effectively harvesting idle GPU time slices. Comprehensive evaluations across diverse GPU architectures reveal that Hummingbird improves the SLO attainment of high-priority tasks by 9.7x and 3.5x compared to the state-of-the-art spatial and temporal-sharing approaches. When compared to executing exclusively, the SLO attainment of the high-priority task, collocating with low-priority tasks on Hummingbird, only drops by less than 1%. Meanwhile, the throughput of the low-priority task outperforms the state-of-the-art temporal-sharing approaches by 2.4x. Hummingbird demonstrates significant effectiveness in ensuring the SLO while enhancing GPU utilization."}
{"id": "2601.04123", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04123", "abs": "https://arxiv.org/abs/2601.04123", "authors": ["Francisco Ponce", "Simone Gazza", "Andrea D'Iapico", "Roberto Amadini", "Antonio Brogi", "Stefano Forti", "Saverio Giallorenzo", "Pierluigi Plebani", "Davide Usai", "Monica Vitali", "Gianluigi Zavattaro", "Jacopo Soldani"], "title": "Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum", "comment": "Submitted to Cluster Computing", "summary": "Deploying microservice-based applications (MSAs) on heterogeneous and dynamic Cloud-Edge infrastructures requires balancing conflicting objectives, such as failure resilience, performance, and environmental sustainability. In this article, we introduce the FREEDA toolchain, designed to automate the failure-resilient and carbon-efficient deployment of MSAs over the Cloud-Edge Continuum.\n  The FREEDA toolchain continuously adapts deployment configurations to changing operational conditions, resource availability, and sustainability constraints, aiming to maintain the MSA quality and service continuity while reducing carbon emissions. We also introduce an experimental suite using diverse simulated and emulated scenarios to validate the effectiveness of the toolchain against real-world challenges, including resource exhaustion, node failures, and carbon intensity fluctuations. The results demonstrate FREEDA's capability to autonomously reconfigure deployments by migrating services, adjusting flavour selections, or rebalancing workloads, successfully achieving an optimal balance among resilience, efficiency, and environmental impact."}
