{"id": "2510.18525", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.18525", "abs": "https://arxiv.org/abs/2510.18525", "authors": ["Yushu Zhao", "Yubin Qin", "Yang Wang", "Xiaolong Yang", "Huiming Han", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "From Quarter to All: Accelerating Speculative LLM Decoding via Floating-Point Exponent Remapping and Parameter Sharing", "comment": null, "summary": "Large language models achieve impressive performance across diverse tasks but\nexhibit high inference latency due to their large parameter sizes. While\nquantization reduces model size, it often leads to performance degradation\ncompared to the full model. Speculative decoding remains lossless but typically\nincurs extra overheads. We propose SPEQ, an algorithm-hardware co-designed\nspeculative decoding method that uses part of the full-model weight bits to\nform a quantized draft model, thereby eliminating additional training or\nstorage overhead. A reconfigurable processing element array enables efficient\nexecution of both the draft and verification passes. Experimental results\nacross 15 LLMs and tasks demonstrate that SPEQ achieves speedups of 2.07x,\n1.53x, and 1.45x compared over FP16, Olive, and Tender, respectively."}
{"id": "2510.18058", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18058", "abs": "https://arxiv.org/abs/2510.18058", "authors": ["Hongbo Lu", "Junsung Hwang", "Bernard Tenreiro", "Nabila Jaman Tripti", "Darren Hamilton", "Yuefan Deng"], "title": "A New Broadcast Model for Several Network Topologies", "comment": "19 pages, 11 figures", "summary": "We present Broadcast by Balanced Saturation (BBS), a general broadcast\nalgorithm designed to optimize communication efficiency across diverse network\ntopologies. BBS maximizes node utilization, addressing challenges in broadcast\noperations such as topology constraints, bandwidth limitations, and\nsynchronization overhead, particularly in large-scale systems like\nsupercomputers. The algorithm ensures sustained activity with nodes throughout\nthe broadcast, thereby enhancing data propagation and significantly reducing\nlatency. Through a precise communication cycle, BBS provides a repeatable,\nstreamlined, stepwise broadcasting framework. Simulation results across various\ntopologies demonstrate that the BBS algorithm consistently outperforms common\ngeneral broadcast algorithms, often by a substantial margin. These findings\nsuggest that BBS is a versatile and robust framework with the potential to\nredefine broadcast strategies across network topologies."}
{"id": "2510.17852", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17852", "abs": "https://arxiv.org/abs/2510.17852", "authors": ["Yuze Sun", "Wentao Luo", "Yanfei Xiang", "Jiancheng Pan", "Jiahao Li", "Quan Zhang", "Xiaomeng Huang"], "title": "Deploying Atmospheric and Oceanic AI Models on Chinese Hardware and Framework: Migration Strategies, Performance Optimization and Analysis", "comment": null, "summary": "With the growing role of artificial intelligence in climate and weather\nresearch, efficient model training and inference are in high demand. Current\nmodels like FourCastNet and AI-GOMS depend heavily on GPUs, limiting hardware\nindependence, especially for Chinese domestic hardware and frameworks. To\naddress this issue, we present a framework for migrating large-scale\natmospheric and oceanic models from PyTorch to MindSpore and optimizing for\nChinese chips, and evaluating their performance against GPUs. The framework\nfocuses on software-hardware adaptation, memory optimization, and parallelism.\nFurthermore, the model's performance is evaluated across multiple metrics,\nincluding training speed, inference speed, model accuracy, and energy\nefficiency, with comparisons against GPU-based implementations. Experimental\nresults demonstrate that the migration and optimization process preserves the\nmodels' original accuracy while significantly reducing system dependencies and\nimproving operational efficiency by leveraging Chinese chips as a viable\nalternative for scientific computing. This work provides valuable insights and\npractical guidance for leveraging Chinese domestic chips and frameworks in\natmospheric and oceanic AI model development, offering a pathway toward greater\ntechnological independence."}
{"id": "2510.18285", "categories": ["cs.NI", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.18285", "abs": "https://arxiv.org/abs/2510.18285", "authors": ["Kanghuai Liu", "Lin Chen", "Jihong Yu", "Junyi Huang", "Shiyuan Liu"], "title": "Revisiting RFID Missing Tag Identification", "comment": null, "summary": "We revisit the problem of missing tag identification in RFID networks by\nmaking three contributions. Firstly, we quantitatively compare and gauge the\nexisting propositions spanning over a decade on missing tag identification. We\nshow that the expected execution time of the best solution in the literature is\n$\\Theta \\left(N+\\frac{(1-\\alpha)^2(1-\\delta)^2}{ \\epsilon^2}\\right)$, where\n$\\delta$ and $\\epsilon$ are parameters quantifying the required identification\naccuracy, $N$ denotes the number of tags in the system, among which $\\alpha N$\ntags are missing. Secondly, we analytically establish the expected execution\ntime lower-bound for any missing tag identification algorithm as\n$\\Theta\\left(\\frac{N}{\\log N}+\\frac{(1-\\delta)^2(1-\\alpha)^2}{\\epsilon^2 \\log\n\\frac{(1-\\delta)(1-\\alpha)}{\\epsilon}}\\right)$, thus giving the theoretical\nperformance limit. Thirdly, we develop a novel missing tag identification\nalgorithm by leveraging a tree structure with the expected execution time of\n$\\Theta \\left(\\frac{\\log\\log N}{\\log N}N+\\frac{(1-\\alpha)^2(1-\\delta)^2}{\n\\epsilon^2}\\right)$, reducing the time overhead by a factor of up to $\\log N$\nover the best algorithm in the literature. The key technicality in our design\nis a novel data structure termed as collision-partition tree (CPT), built on a\nsubset of bits in tag pseudo-IDs, leading to more balanced tree structure and\nreducing the time complexity in parsing the entire tree."}
{"id": "2510.18152", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18152", "abs": "https://arxiv.org/abs/2510.18152", "authors": ["Zhuoyu Yao", "Yue Wang", "Songyang Zhang", "Yingshu Li", "Zhipeng Cai", "Zhi Tian"], "title": "Efficient Multi-Worker Selection based Distributed Swarm Learning via Analog Aggregation", "comment": "5 pages, 4 figures, conference", "summary": "Recent advances in distributed learning systems have introduced effective\nsolutions for implementing collaborative artificial intelligence techniques in\nwireless communication networks. Federated learning approaches provide a\nmodel-aggregation mechanism among edge devices to achieve collaborative\ntraining, while ensuring data security, communication efficiency, and sharing\ncomputational overheads. On the other hand, limited transmission resources and\ncomplex communication environments remain significant bottlenecks to the\nefficient collaborations among edge devices, particularly within large-scale\nnetworks. To address such issues, this paper proposes an over-the-air (OTA)\nanalog aggregation method designed for the distributed swarm learning (DSL),\ntermed DSL-OTA, aiming to enhance communication efficiency, enable effective\ncooperation, and ensure privacy preserving. Incorporating multi-worker\nselection strategy with over-the-air aggregation not only makes the standard\nDSL based on single best worker contributing to global model update to become\nmore federated, but also secures the aggregation from potential risks of data\nleakage. Our theoretical analyses verify the advantages of the proposed DSL-OTA\nalgorithm in terms of fast convergence rate and low communication costs.\nSimulation results reveal that our DSL-OTA outperforms the other existing\nmethods by achieving better learning performance under both homogeneous and\nheterogeneous dataset settings."}
{"id": "2510.18417", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18417", "abs": "https://arxiv.org/abs/2510.18417", "authors": ["Rahul Soundrarajan", "Claudio Fiandrino", "Michele Polese", "Salvatore D'Oro", "Leonardo Bonati", "Tommaso Melodia"], "title": "On AI Verification in Open RAN", "comment": null, "summary": "Open RAN introduces a flexible, cloud-based architecture for the Radio Access\nNetwork (RAN), enabling Artificial Intelligence (AI)/Machine Learning\n(ML)-driven automation across heterogeneous, multi-vendor deployments. While\nEXplainable Artificial Intelligence (XAI) helps mitigate the opacity of AI\nmodels, explainability alone does not guarantee reliable network operations. In\nthis article, we propose a lightweight verification approach based on\ninterpretable models to validate the behavior of Deep Reinforcement Learning\n(DRL) agents for RAN slicing and scheduling in Open RAN. Specifically, we use\nDecision Tree (DT)-based verifiers to perform near-real-time consistency checks\nat runtime, which would be otherwise unfeasible with computationally expensive\nstate-of-the-art verifiers. We analyze the landscape of XAI and AI\nverification, propose a scalable architectural integration, and demonstrate\nfeasibility with a DT-based slice-verifier. We also outline future challenges\nto ensure trustworthy AI adoption in Open RAN."}
{"id": "2510.18300", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18300", "abs": "https://arxiv.org/abs/2510.18300", "authors": ["Ankur Lahiry", "Ayush Pokharel", "Banooqa Banday", "Seth Ockerman", "Amal Gueroudji", "Mohammad Zaeed", "Tanzima Z. Islam", "Line Pouchard"], "title": "A Distributed Framework for Causal Modeling of Performance Variability in GPU Traces", "comment": null, "summary": "Large-scale GPU traces play a critical role in identifying performance\nbottlenecks within heterogeneous High-Performance Computing (HPC)\narchitectures. However, the sheer volume and complexity of a single trace of\ndata make performance analysis both computationally expensive and\ntime-consuming. To address this challenge, we present an end-to-end parallel\nperformance analysis framework designed to handle multiple large-scale GPU\ntraces efficiently. Our proposed framework partitions and processes trace data\nconcurrently and employs causal graph methods and parallel coordinating chart\nto expose performance variability and dependencies across execution flows.\nExperimental results demonstrate a 67% improvement in terms of scalability,\nhighlighting the effectiveness of our pipeline for analyzing multiple traces\nindependently."}
{"id": "2510.18550", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.18550", "abs": "https://arxiv.org/abs/2510.18550", "authors": ["Enhan Li", "Hongyang Du"], "title": "JAUNT: Joint Alignment of User Intent and Network State for QoE-centric LLM Tool Routing", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on emerging protocols such as\nthe Model Context Protocol (MCP) to invoke external tools and services.\nHowever, current tool routing mechanisms remain fragile because they only\nconsider functional matching between users' queries and tools. In practice,\nuser intent expressed through queries can be vague or underspecified, and the\nactual Quality of Experience (QoE) also depends on external factors such as\nlink latency and server availability that are not captured by semantics alone.\nTo address this challenge, we propose JAUNT, a framework for Joint Alignment of\nUser intent and Network state in QoE-centric Tool routing. JAUNT introduces a\ndual-view alignment strategy that interprets user intent while employing LLM\nagents to construct network profiles, mapping numerical performance indicators\ninto the semantic space to guide routing. We further design a benchmark that\nintegrates diverse user request patterns with heterogeneous network states,\nenabling systematic evaluation of QoE outcomes. Experimental results show that\nJAUNT significantly improves QoE compared with several baselines, demonstrating\nthe importance of aligning both intent and network state for scalable LLM\nservice orchestration."}
{"id": "2510.18544", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18544", "abs": "https://arxiv.org/abs/2510.18544", "authors": ["Pan Zhou", "Yiming Lei", "Ling Liu", "Xiaoqiong Xu", "Ying Cai", "Daji Ergu", "Hongfang Yu", "Yueyue Dai"], "title": "SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices", "comment": null, "summary": "Large Language Models (LLMs), as the foundational architecture for\nnext-generation interactive AI applications, not only power intelligent\ndialogue systems but also drive the evolution of embodied intelligence on edge\ndevices, including humanoid robots, smart vehicles, and other scenarios. The\napplications running on these edge devices impose differentiated Service Level\nObjectives (SLO) requirements on LLM services, specifically manifested as\ndistinct constraints on Time to First Token (TTFT) and Time Per Output Token\n(TPOT) as well as end-to-end latency. Notably, edge devices typically handle\nreal-time tasks that are extremely sensitive to latency, such as machine\ncontrol and navigation planning. However, existing scheduling service systems\nstill prioritize maximizing output token throughput as the sole optimization\nobjective, failing to adequately address the diversity of SLO requirements.\nThis ultimately results in persistently high violation rates for end-to-end\nlatency or TPOT related SLOs.\n  This paper proposes SLICE, an innovative scheduling solution designed for\nedge computing scenarios with differentiated SLO requirements. By combining a\nutility-maximizing request scheduling algorithm with a dynamic iterative\ncontrol mechanism for generation rates, SLICE significantly improves LLM\ninference service SLO attainment. Experimental results demonstrate that\ncompared to state-of-the-art solutions Orca and FastServe, SLICE achieves up to\n35x higher SLO attainment and 3.4x advantage in task completion time than the\nother two solutions."}
{"id": "2510.18730", "categories": ["cs.NI", "cs.LO", "C.2.2; D.2.4; F.3.1"], "pdf": "https://arxiv.org/pdf/2510.18730", "abs": "https://arxiv.org/abs/2510.18730", "authors": ["Wan Fokkink", "Rob van Glabbeek"], "title": "Formal Methods for Mobile Ad Hoc Networks: A Survey", "comment": null, "summary": "In a mobile ad hoc network (MANET), communication is wireless and nodes can\nmove independently. Properly analyzing the functional correctness, performance,\nand security of MANET protocols is a challenging task. A wide range of formal\nspecification and analysis techniques have been employed in the analysis of\nMANET protocols. This survey presents an overview of rigorous formal analysis\ntechniques and their applications, with a focus on MANET routing protocols.\nNext to functional correctness, also real-time properties and security are\nconsidered. Moreover, an overview is given of formal frameworks that target\nMANETs specifically, as well as mobility models that underlie performance\nanalyses of MANET protocols. The aim is to give a comprehensive and coherent\noverview of this rather scattered field, in which a variety of rigorous formal\nmethods have been applied to analyze different aspects of a wide range of MANET\nprotocols."}
{"id": "2510.18586", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18586", "abs": "https://arxiv.org/abs/2510.18586", "authors": ["Zhuohang Bian", "Feiyang Wu", "Teng Ma", "Youwei Zhuo"], "title": "Tokencake: A KV-Cache-centric Serving Framework for LLM-based Multi-Agent Applications", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in complex multi-agent\napplications that use external function calls. This workload creates severe\nperformance challenges for the KV Cache: space contention leads to the eviction\nof critical agents' caches and time underutilization leaves the cache of agents\nstalled on long-running tool calls idling in GPU memory. We present Tokencake,\na KV-Cache-centric serving framework that co-optimizes scheduling and memory\nmanagement with an agent-aware design. Tokencake's Space Scheduler uses dynamic\nmemory partitioning to shield critical agents from contention, while its Time\nScheduler employs a proactive offload and predictive upload mechanism to\nrepurpose GPU memory during function call stalls. Our evaluation on\nrepresentative multi-agent benchmarks shows that Tokencake can reduce\nend-to-end latency by over 47.06%, improve effective GPU memory utilization by\nup to 16.9% compared to vLLM."}
{"id": "2510.18592", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.18592", "abs": "https://arxiv.org/abs/2510.18592", "authors": ["Yuval Gil", "Merav Parter"], "title": "Distributed Interactive Proofs for Planarity with Log-Star Communication", "comment": "To appear in SODA 26", "summary": "We provide new communication-efficient distributed interactive proofs for\nplanarity. The notion of a \\emph{distributed interactive proof (DIP)} was\nintroduced by Kol, Oshman, and Saxena (PODC 2018). In a DIP, the \\emph{prover}\nis a single centralized entity whose goal is to prove a certain claim regarding\nan input graph $G$. To do so, the prover communicates with a distributed\n\\emph{verifier} that operates concurrently on all $n$ nodes of $G$. A DIP is\nmeasured by the amount of prover-verifier communication it requires. Namely,\nthe goal is to design a DIP with a small number of interaction rounds and a\nsmall \\emph{proof size}, i.e., a small amount of communication per round. Our\nmain result is an $O(\\log ^{*}n)$-round DIP protocol for embedded planarity and\nplanarity with a proof size of $O(1)$ and $O(\\lceil\\log \\Delta/\\log\n^{*}n\\rceil)$, respectively. In fact, this result can be generalized as\nfollows. For any $1\\leq r\\leq \\log^{*}n$, there exists an $O(r)$-round protocol\nfor embedded planarity and planarity with a proof size of $O(\\log ^{(r)}n)$ and\n$O(\\log ^{(r)}n+\\log \\Delta /r)$, respectively."}
{"id": "2510.18640", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18640", "abs": "https://arxiv.org/abs/2510.18640", "authors": ["Nils Japke", "Sebastian Koch", "Helmut Lukasczyk", "David Bermbach"], "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "comment": "Published in 2025 IEEE International Conference on Cloud Engineering\n  (IC2E)", "summary": "Performance regressions in large-scale software systems can lead to\nsubstantial resource inefficiencies, making their early detection critical.\nFrequent benchmarking is essential for identifying these regressions and\nmaintaining service-level agreements (SLAs). Performance benchmarks, however,\nare resource-intensive and time-consuming, which is a major challenge for\nintegration into Continuous Integration / Continuous Deployment (CI/CD)\npipelines. Although numerous benchmark optimization techniques have been\nproposed to accelerate benchmark execution, there is currently no practical\nsystem that integrates these optimizations seamlessly into real-world CI/CD\npipelines. In this vision paper, we argue that the field of benchmark\noptimization remains under-explored in key areas that hinder its broader\nadoption. We identify three central challenges to enabling frequent and\nefficient benchmarking: (a) the composability of benchmark optimization\nstrategies, (b) automated evaluation of benchmarking results, and (c) the\nusability and complexity of applying these strategies as part of CI/CD systems\nin practice. We also introduce a conceptual cloud-based benchmarking framework\nhandling these challenges transparently. By presenting these open problems, we\naim to stimulate research toward making performance regression detection in\nCI/CD systems more practical and effective."}
{"id": "2510.18838", "categories": ["cs.DC", "physics.comp-ph", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.18838", "abs": "https://arxiv.org/abs/2510.18838", "authors": ["Jacob S. Merson", "Cameron W. Smith", "Mark S. Shephard", "Fuad Hasan", "Abhiyan Paudel", "Angel Castillo-Crooke", "Joyal Mathew", "Mohammad Elahi"], "title": "PCMS: Parallel Coupler For Multimodel Simulations", "comment": null, "summary": "This paper presents the Parallel Coupler for Multimodel Simulations (PCMS), a\nnew GPU accelerated generalized coupling framework for coupling simulation\ncodes on leadership class supercomputers. PCMS includes distributed control and\nfield mapping methods for up to five dimensions. For field mapping PCMS can\nutilize discretization and field information to accommodate physics\nconstraints. PCMS is demonstrated with a coupling of the gyrokinetic\nmicroturbulence code XGC with a Monte Carlo neutral transport code DEGAS2 and\nwith a 5D distribution function coupling of an energetic particle transport\ncode (GNET) to a gyrokinetic microturbulence code (GTC). Weak scaling is also\ndemonstrated on up to 2,080 GPUs of Frontier with a weak scaling efficiency of\n85%."}
{"id": "2510.18058", "categories": ["cs.NI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.18058", "abs": "https://arxiv.org/abs/2510.18058", "authors": ["Hongbo Lu", "Junsung Hwang", "Bernard Tenreiro", "Nabila Jaman Tripti", "Darren Hamilton", "Yuefan Deng"], "title": "A New Broadcast Model for Several Network Topologies", "comment": "19 pages, 11 figures", "summary": "We present Broadcast by Balanced Saturation (BBS), a general broadcast\nalgorithm designed to optimize communication efficiency across diverse network\ntopologies. BBS maximizes node utilization, addressing challenges in broadcast\noperations such as topology constraints, bandwidth limitations, and\nsynchronization overhead, particularly in large-scale systems like\nsupercomputers. The algorithm ensures sustained activity with nodes throughout\nthe broadcast, thereby enhancing data propagation and significantly reducing\nlatency. Through a precise communication cycle, BBS provides a repeatable,\nstreamlined, stepwise broadcasting framework. Simulation results across various\ntopologies demonstrate that the BBS algorithm consistently outperforms common\ngeneral broadcast algorithms, often by a substantial margin. These findings\nsuggest that BBS is a versatile and robust framework with the potential to\nredefine broadcast strategies across network topologies."}
