{"id": "2602.05017", "categories": ["cs.DC", "q-bio.CB"], "pdf": "https://arxiv.org/pdf/2602.05017", "abs": "https://arxiv.org/abs/2602.05017", "authors": ["Jose-Luis Estragues-Mu\u00f1oz", "Carlos Alvarez", "Arnau Montagud", "Daniel Jimenez-Gonzalez", "Alfonso Valencia"], "title": "A novel scalable high performance diffusion solver for multiscale cell simulations", "comment": "14 pages, 9 figures", "summary": "Agent-based cellular models simulate tissue evolution by capturing the behavior of individual cells, their interactions with neighboring cells, and their responses to the surrounding microenvironment. An important challenge in the field is scaling cellular resolution models to real-scale tumor simulations, which is critical for the development of digital twin models of diseases and requires the use of High-Performance Computing (HPC) since every time step involves trillions of operations. We hereby present a scalable HPC solution for the molecular diffusion modeling using an efficient implementation of state-of-the-art Finite Volume Method (FVM) frameworks. The paper systematically evaluates a novel scalable Biological Finite Volume Method (BioFVM) library and presents an extensive performance analysis of the available solutions. Results shows that our HPC proposal reach almost 200x speedup and up to 36% reduction in memory usage over the current state-of-the-art solutions, paving the way to efficiently compute the next generation of biological problems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05292", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05292", "abs": "https://arxiv.org/abs/2602.05292", "authors": ["Haoyu Bai", "Muhammed Tawfiqul Islam", "Minxian Xu", "Rajkumar Buyya"], "title": "ORACL: Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices", "comment": null, "summary": "Applications are moving away from monolithic designs to microservice and serverless architectures, where fleets of lightweight and independently deployable components run on public clouds. Autoscaling serves as the primary control mechanism for balancing resource utilization and quality of service, yet existing policies are either opaque learned models that require substantial per-deployment training or brittle hand-tuned rules that fail to generalize. We investigate whether large language models can act as universal few-shot resource allocators that adapt across rapidly evolving microservice deployments.\n  We propose ORACL, Optimized Reasoning for Autoscaling via Chain of Thought with LLMs for Microservices, a framework that leverages prior knowledge and chain-of-thought reasoning to diagnose performance regressions and recommend resource allocations. ORACL transforms runtime telemetry, including pods, replicas, CPU and memory usage, latency, service-level objectives, and fault signals, into semantic natural-language state descriptions and invokes an LLM to produce an interpretable intermediate reasoning trace. This reasoning identifies likely root causes, prunes the action space, and issues safe allocation decisions under policy constraints. Experiments on representative open-source microservice workloads show that ORACL improves root-cause identification accuracy by 15 percent, accelerates training by up to 24x, and improves quality of service by 6 percent in short-term scenarios, without deployment-specific retraining.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05346", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05346", "abs": "https://arxiv.org/abs/2602.05346", "authors": ["Shubham Mishra", "Jo\u00e3o Gon\u00e7alves", "Chawinphat Tankuranand", "Neil Giridharan", "Natacha Crooks", "Heidi Howard", "Chris Jensen"], "title": "Proteus: Append-Only Ledgers for (Mostly) Trusted Execution Environments", "comment": null, "summary": "Distributed ledgers are increasingly relied upon by industry to provide trustworthy accountability, strong integrity protection, and high availability for critical data without centralizing trust. Recently, distributed append-only logs are opting for a layered approach, combining crash-fault-tolerant (CFT) consensus with hardware-based Trusted Execution Environments (TEEs) for greater resiliency. Unfortunately, hardware TEEs can be subject to (rare) attacks, undermining the very guarantees that distributed ledgers are carefully designed to achieve. In response, we present Proteus, a new distributed consensus protocol that cautiously trusts the guarantees of TEEs. Proteus carefully embeds a Byzantine fault-tolerant (BFT) protocol inside of a CFT protocol with no additional messages. This is made possible through careful refactoring of both the CFT and BFT protocols such that their structure aligns. Proteus achieves performance in line with regular TEE-enabled consensus protocols, while guaranteeing integrity in the face of TEE platform compromises.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.04991", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.04991", "abs": "https://arxiv.org/abs/2602.04991", "authors": ["Simone Manoni", "Emanuele Parisi", "Riccardo Tedeschi", "Davide Rossi", "Andrea Acquaviva", "Andrea Bartolini"], "title": "CVA6-CFI: A First Glance at RISC-V Control-Flow Integrity Extensions", "comment": "Accepted as a lecture at the 2026 IEEE International Symposium on Circuits and Systems. Preprint version", "summary": "This work presents the first design, integration, and evaluation of the standard RISC-V extensions for Control-Flow Integrity (CFI). The Zicfiss and Zicfilp extensions aim at protecting the execution of a vulnerable program from control-flow hijacking attacks through the implementation of security mechanisms based on shadow stack and landing pad primitives. We introduce two independent and configurable hardware units implementing forward-edge and backward-edge control-flow protection, fully integrated into the open-source CVA6 core. Our design incurs in only 1.0% area overhead when synthesized in 22 nm FDX technology, and up to 15.6% performance overhead based on evaluation with the MiBench automotive benchmark subset. We release the complete implementation as open source.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05280", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.05280", "abs": "https://arxiv.org/abs/2602.05280", "authors": ["Kim Hammar", "Tansu Alpcan", "Emil Lupu"], "title": "Causal Online Learning of Safe Regions in Cloud Radio Access Networks", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Cloud radio access networks (RANs) enable cost-effective management of mobile networks by dynamically scaling their capacity on demand. However, deploying adaptive controllers to implement such dynamic scaling in operational networks is challenging due to the risk of breaching service agreements and operational constraints. To mitigate this challenge, we present a novel method for learning the safe operating region of the RAN, i.e., the set of resource allocations and network configurations for which its specification is fulfilled. The method, which we call (C)ausal (O)nline (L)earning, operates in two online phases: an inference phase and an intervention phase. In the first phase, we passively observe the RAN to infer an initial safe region via causal inference and Gaussian process regression. In the second phase, we gradually expand this region through interventional Bayesian learning. We prove that COL ensures that the learned region is safe with a specified probability and that it converges to the full safe region under standard conditions. We experimentally validate COL on a 5G testbed. The results show that COL quickly learns the safe region while incurring low operational cost and being up to 10x more sample-efficient than current state-of-the-art methods for safe learning.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05356", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.05356", "abs": "https://arxiv.org/abs/2602.05356", "authors": ["Andrew Lewis-Pye"], "title": "Reaching Univalency with Subquadratic Communication", "comment": null, "summary": "The Dolev-Reischuk lower bound establishes that any deterministic Byzantine Agreement (BA) protocol for $n$ processors tolerating $f$ faults requires $\u03a9(f^2+n)$ messages. But what exactly does this quadratic cost pay for? Even the minimal requirement that every correct processor \\emph{receive at least one message} already necessitates $\u03a9(f^2 + n)$ messages. This raises a fundamental question: is the Dolev-Reischuk bound about the difficulty of \\emph{reaching univalency} -- the point at which the protocol's outcome is determined -- or merely about \\emph{disseminating} the outcome to all processors afterward?\n  We resolve this question by showing that reaching univalency does \\emph{not} require quadratic communication. Specifically, we introduce $\u03b5$-BA, a relaxation allowing an $\u03b5$-fraction of correct processors to output incorrectly, and prove it can be solved deterministically with $O(n \\log n)$ communication complexity when $f < n(1/3 - \u03b5)$. Crucially, any $\u03b5$-BA protocol can serve as the first phase of a full BA protocol: after $\u03b5$-BA, a single all-to-all exchange and majority vote completes BA. Since the outcome is already determined after $\u03b5$-BA, this demonstrates that the quadratic cost in Dolev-Reischuk stems entirely from dissemination, rather than from reaching univalency. We also define Extractable BA for authenticated settings, capturing when processors collectively hold enough signed messages to determine the agreed value, and show it can be solved with communication complexity $O(f \\log f)$.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05018", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.05018", "abs": "https://arxiv.org/abs/2602.05018", "authors": ["Hongbang Wu", "Xuesi Chen", "Shubham Jadhav", "Amit Lal", "Lillian Pentecost", "Udit Gupta"], "title": "COFFEE: A Carbon-Modeling and Optimization Framework for HZO-based FeFET eNVMs", "comment": null, "summary": "Information and communication technologies account for a growing portion of global environmental impacts. While emerging technologies, such as emerging non-volatile memories (eNVM), offer a promising solution to energy efficient computing, their end-to-end footprint is not well understood. Understanding the environmental impact of hardware systems over their life cycle is the first step to realizing sustainable computing. This work conducts a detailed study of one example eNVM device: hafnium-zirconium-oxide (HZO)-based ferroelectric field-effect transistors (FeFETs). We present COFFEE, the first carbon modeling framework for HZO-based FeFET eNVMs across life cycle, from hardware manufacturing (embodied carbon) to use (operational carbon). COFFEE builds on data gathered from a real semiconductor fab and device fabrication recipes to estimate embodied carbon, and architecture level eNVM design space exploration tools to quantify use-phase performance and energy. Our evaluation shows that, at 2 MB capacity, the embodied carbon per unit area overhead of HZO-FeFETs can be up to 11% higher than the CMOS baseline, while the embodied carbon per MB remains consistently about 4.3x lower than SRAM across different memory capacity. A further case study applies COFFEE to an edge ML accelerator, showing that replacing the SRAM-based weight buffer with HZO-based FeFET eNVMs reduces embodied carbon by 42.3% and operational carbon by up to 70%.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05344", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.05344", "abs": "https://arxiv.org/abs/2602.05344", "authors": ["Koji Yamamoto"], "title": "Wi-Fi Radar via Over-the-Air Referencing: Bridging Wi-Fi Sensing and Bistatic Radar", "comment": "This manuscript is currently under review at IEEE Transactions on Vehicular Technology", "summary": "Wi-Fi sensing has attracted significant attention for human sensing and related applications. However, unsynchronized transmitters and receivers fundamentally preclude phase-coherent radar-like delay--Doppler analysis. By exploiting the line-of-sight (LoS) path, i.e., the earliest-arriving direct path, as an over-the-air (OTA) reference for delay and phase, we propose an OTA LoS-path referencing scheme, termed LoSRef, that enables delay calibration and phase alignment in unsynchronized Wi-Fi systems. Unlike conventional Wi-Fi bistatic radar systems that rely on wired reference signals or dedicated reference antennas, the proposed LoSRef-based framework bridges the long-standing gap between conventional Wi-Fi sensing and Wi-Fi radar, enabling phase-coherent bistatic radar-like operation in a drop-in Wi-Fi sensing configuration. Through human gait and respiration experiments in indoor environments, we demonstrate that phase-coherent channel impulse responses and corresponding delay--Doppler responses are obtained using only commodity Wi-Fi devices. This enables physically interpretable human motion sensing, including gait-induced range variation and respiration-induced sub-wavelength displacement, as well as the extraction of target-induced dynamics up to 20 dB weaker than dominant static multipath components.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05754", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05754", "abs": "https://arxiv.org/abs/2602.05754", "authors": ["Seonghye Cho", "Jaemin Han", "Hyunjin Kim", "Euisoo Jung", "Jae-Gil Lee"], "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism", "comment": null, "summary": "Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulting in unnecessary accuracy degradation. To address this issue, we propose TimelyFreeze, which models the pipeline schedule as a directed acyclic graph and solves a linear program to compute optimal freeze ratios that minimize batch execution time under accuracy constraints. Experiments show that TimelyFreeze achieves up to 40% training throughput improvement on LLaMA-8B with comparable accuracy. Overall, it enables faster large-scale model training without compromising convergence and generalizes across diverse pipeline-parallel settings.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05743", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.05743", "abs": "https://arxiv.org/abs/2602.05743", "authors": ["Liang Zhao", "Kunming Shao", "Zhipeng Liao", "Xijie Huang", "Tim Kwang-Ting Cheng", "Chi-Ying Tsui", "Yi Zou"], "title": "Balancing FP8 Computation Accuracy and Efficiency on Digital CIM via Shift-Aware On-the-fly Aligned-Mantissa Bitwidth Prediction", "comment": "This paper is under review by IEEE Transactions On Very Large Scale Integration Systems (TVLSI-00144-2026)", "summary": "FP8 low-precision formats have gained significant adoption in Transformer inference and training. However, existing digital compute-in-memory (DCIM) architectures face challenges in supporting variable FP8 aligned-mantissa bitwidths, as unified alignment strategies and fixed-precision multiply-accumulate (MAC) units struggle to handle input data with diverse distributions. This work presents a flexible FP8 DCIM accelerator with three innovations: (1) a dynamic shift-aware bitwidth prediction (DSBP) with on-the-fly input prediction that adaptively adjusts weight (2/4/6/8b) and input (2$\\sim$12b) aligned-mantissa precision; (2) a FIFO-based input alignment unit (FIAU) replacing complex barrel shifters with pointer-based control; and (3) a precision-scalable INT MAC array achieving flexible weight precision with minimal overhead. Implemented in 28nm CMOS with a 64$\\times$96 CIM array, the design achieves 20.4 TFLOPS/W for fixed E5M7, demonstrating 2.8$\\times$ higher FP8 efficiency than previous work while supporting all FP8 formats. Results on Llama-7b show that the DSBP achieves higher efficiency than fixed bitwidth mode at the same accuracy level on both BoolQ and Winogrande datasets, with configurable parameters enabling flexible accuracy-efficiency trade-offs.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05948", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.05948", "abs": "https://arxiv.org/abs/2602.05948", "authors": ["Himani", "Supantha Pandit", "Gokarna Sharma"], "title": "Location-Aware Dispersion on Anonymous Graphs", "comment": "3 tables, 2 figures, 6 pseudo-codes", "summary": "The well-studied DISPERSION problem is a fundamental coordination problem in distributed robotics, where a set of mobile robots must relocate so that each occupies a distinct node of a network. DISPERSION assumes that a robot can settle at any node as long as no other robot settles on that node. In this work, we introduce LOCATION-AWARE DISPERSION, a novel generalization of DISPERSION that incorporates location awareness: Let $G = (V, E)$ be an anonymous, connected, undirected graph with $n = |V|$ nodes, each labeled with a color $\\sf{col}(v) \\in C = \\{c_1, \\dots, c_t\\}, t\\leq n$. A set $R = \\{r_1, \\dots, r_k\\}$ of $k \\leq n$ mobile robots is given, where each robot $r_i$ has an associated color $\\mathsf{col}(r_i) \\in C$. Initially placed arbitrarily on the graph, the goal is to relocate the robots so that each occupies a distinct node of the same color. When $|C|=1$, LOCATION-AWARE DISPERSION reduces to DISPERSION. There is a solution to DISPERSION in graphs with any $k\\leq n$ without knowing $k,n$.\n  Like DISPERSION, the goal is to solve LOCATION-AWARE DISPERSION minimizing both time and memory requirement at each agent. We develop several deterministic algorithms with guaranteed bounds on both time and memory requirement. We also give an impossibility and a lower bound for any deterministic algorithm for LOCATION-AWARE DISPERSION. To the best of our knowledge, the presented results collectively establish the algorithmic feasibility of LOCATION-AWARE DISPERSION in anonymous networks and also highlight the challenges on getting an efficient solution compared to the solutions for DISPERSION.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
{"id": "2602.05792", "categories": ["cs.NI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.05792", "abs": "https://arxiv.org/abs/2602.05792", "authors": ["Pedro R. X. do Carmo", "Eduardo Freitas", "Assis T. de Oliveira Filho", "Judith Kelner", "Djamel Sadok"], "title": "Data analysis of cloud virtualization experiments", "comment": null, "summary": "The cloud computing paradigm underlines data center and telecommunication infrastructure design. Heavily leveraging virtualization, it slices hardware and software resources into smaller software units for greater flexibility of manipulation. Given the considerable benefits, several virtualization forms, with varying processing and communication overheads, emerged, including Full Virtualization and OS Virtualization. As a result, predicting packet throughput at the data plane turns out to be more challenging due to the additional virtualization overhead located at CPU, I/O, and network resources. This research presents a dataset of active network measurements data collected while varying various network parameters, including CPU affinity, frequency of echo packet injection, type of virtual network driver, use of CPU, I/O, or network load, and the number of concurrent VMs. The virtualization technologies used in the study include KVM, LXC, and Docker. The work examines their impact on a key network metric, namely, end-to-end latency. Also, it builds data models to evaluate the impact of a cloud computing environment on packet round-trip time. To explore data visualization, the dataset was submitted to pre-processing, correlation analysis, dimensionality reduction, and clustering. In addition, this paper provides a brief analysis of the dataset, demonstrating its use in developing machine learning-based systems for administrator decision-making.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "challenges": "Challenges extraction failed", "contributions": "Contributions extraction failed", "results": "Results analysis unavailable", "conclusion": "Conclusion extraction failed", "related_work": "Related work extraction failed"}}
